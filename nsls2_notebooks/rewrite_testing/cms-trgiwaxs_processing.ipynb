{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c13da0-ce45-4653-9fb2-5f71078d5a36",
   "metadata": {},
   "source": [
    "# CMS GIWAXS raw data processing & exporting notebook - time resolved GIWAXS series measurements\n",
    "In this notebook you output xr.DataSets stored as .zarr stores containing all your raw,\n",
    "remeshed (reciprocal space), and caked CMS GIWAXS data. Saving as a zarr automatically converts the array to a dask array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890da6d6-cd22-4687-a4e8-1166e36cb22d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ### Kernel updates if needed, remember to restart kernel after running this cell!:\n",
    "# !pip install -e /nsls2/users/alevin/repos/PyHyperScattering  # to use pip to install via directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96625ca6-7ec2-4690-bf01-72b422801f76",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd667c0e-baba-4a5d-857a-ca8bd5ce1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports:\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import xarray as xr\n",
    "import PyHyperScattering as phs\n",
    "import pygix\n",
    "import gc\n",
    "from tqdm.auto import tqdm  # progress bar loader!\n",
    "\n",
    "print(f'Using PyHyperScattering Version: {phs.__version__}')\n",
    "\n",
    "# Set colormap\n",
    "cmap = plt.cm.turbo.copy()\n",
    "cmap.set_bad('black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dffa6de-0360-4fcb-b0bf-f320927837d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Defining some objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b6f6c-4643-46b3-9784-9a6071c754ba",
   "metadata": {},
   "source": [
    "### Define & check paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db0fc93-6739-457a-a7fe-ba695bb41716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I like pathlib for its readability & checkability, it's also necessary for the loadSeries function later on\n",
    "# Replace the paths with the ones relevant to your data, you can use the \".exists()\" method to make sure you defined a path correctly\n",
    "userPath = pathlib.Path('/nsls2/users/alevin')  # Your users path is great for small items that are personal to you (100 GB limit)\n",
    "propPath = pathlib.Path('/nsls2/data/cms/proposals/2023-2/pass-311415')  # The proposals path is a good place to store large data (>1 TB space?)\n",
    "dataPath = propPath.joinpath('KWhite5')\n",
    "maskponiPath = userPath.joinpath('giwaxs_suite/beamline_data/maskponi')\n",
    "outPath = propPath.joinpath('AL_processed_data')\n",
    "\n",
    "# Select poni & mask filepaths\n",
    "poniFile = maskponiPath.joinpath('LaB6_fixed_rot_x517.2.poni')\n",
    "maskFile = maskponiPath.joinpath('LaB6.json')\n",
    "\n",
    "# Creat pg Transform objects with the above information:\n",
    "# qpara_transformer = phs.GIWAXS.Transform(poniPath=poniFile, maskPath=maskFile, inplane_config='q_para')  # I did not specify an energy, because the poni energy is correct\n",
    "# qperp_transformer = phs.GIWAXS.Transform(poniPath=poniFile, maskPath=maskFile, inplane_config='q_perp')  # I did not specify an energy, because the poni energy is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fdac03-46b0-4814-8fed-6b0b3de72404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List the files inside the dataPath folder\n",
    "sorted([f.name for f in dataPath.iterdir()])  # a way to list all filenames inside a path\n",
    "\n",
    "# Misc sample notes:\n",
    "# pm7_S1_95tol5cpme_14_100_18_85_75_009 is the first sample that I did with the different exposure series\n",
    "# all previous samples are just 900 frames of 0.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161af719-785d-4555-b715-b5c60d0330a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = 'pybtz_CBCNp5_15_200_40_60_60_014'\n",
    "samplePath = dataPath.joinpath(sample, 'maxs/raw')\n",
    "sorted([f.name for f in samplePath.iterdir()])  # a way to list all filenames inside a path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd16e39-5527-4aec-939d-9098cb04795a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Generate sets for samples with single scan id per series scan\n",
    "# # Customize as per your data, in this example for my above selected blade coated sample, I have 3 sets I am interested in:\n",
    "# # 1) The series set, here all with the same scan id and same exposure time\n",
    "# # 2) qpara set, what I named my single image scans post-series measurement\n",
    "# # 3) qperp set, what I named my single image scans after rotating 90 degrees in plane \n",
    "\n",
    "# # Choose series scan id(s)\n",
    "# series_ids = ['1117471']\n",
    "\n",
    "# # Create separate sets for single vs series measurements, customize per your data:\n",
    "# qperp_set = set(samplePath.glob('*qperp*'))  # only my qperp samples have qperp in the name\n",
    "# series_set = set(samplePath.glob(f'*{series_ids[0]}*'))  # all my series scans have the same id\n",
    "# singles_set = set(samplePath.iterdir()).difference(series_set)  # the total single image scans is just the difference between all the scans and then series set\n",
    "# qpara_set = singles_set.difference(qperp_set)  # qpara set is the singles set minus the qperp set\n",
    "\n",
    "# # # Check content of sets\n",
    "# # print('qperp images:')\n",
    "# # display(sorted([f.name for f in qperp_set]))\n",
    "\n",
    "# # print('\\nqpara images:')\n",
    "# # display(sorted([f.name for f in qpara_set]))\n",
    "\n",
    "# # print('\\nimage series:')\n",
    "# # display(sorted([f.name for f in series_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9871d3d3-4133-4d26-8474-3b7f9580509d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate sets for samples with multiple scan ids per series scan\n",
    "# Some of my series are broken into different scan ids because I changed the exposure time\n",
    "\n",
    "# Choose series scan id(s)\n",
    "series_ids = ['1118329', '1118330', '1118331']\n",
    "\n",
    "# Create separate sets for single vs series measurements, customize per your data:\n",
    "# I had 3 different scan ids in one series measurement, so I combine them all first \n",
    "# before substracting them from the total file list\n",
    "exp0p1_set = set(samplePath.glob(f'*{series_ids[0]}*')) \n",
    "exp0p5_set = set(samplePath.glob(f'*{series_ids[1]}*'))\n",
    "exp2p0_set = set(samplePath.glob(f'*{series_ids[2]}*'))\n",
    "qperp_set = set(samplePath.glob('*qperp*'))\n",
    "\n",
    "series_set = exp0p1_set.union(exp0p5_set, exp2p0_set)\n",
    "singles_set = set(samplePath.iterdir()).difference(series_set)\n",
    "qpara_set = singles_set.difference(qperp_set)\n",
    "\n",
    "# Check content of sets\n",
    "print('qperp images:')\n",
    "display(sorted([f.name for f in qperp_set]))\n",
    "\n",
    "print('\\nqpara images:')\n",
    "display(sorted([f.name for f in qpara_set]))\n",
    "\n",
    "print('\\nimage series:')\n",
    "display(sorted([f.name for f in series_set]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1840638-1577-4dea-8819-ffb69d6f80b8",
   "metadata": {},
   "source": [
    "### Define metadata naming schemes & initialize loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd31494-d2e4-43d7-adce-d31098c55edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My example metadata filename naming schemes:\n",
    "# Make sure the length of this list lines up with your filenames split by underscore (or however you split them)!\n",
    "\n",
    "# Metadata naming schemes for the pybtz samples\n",
    "# For nonrotated, qpara images:\n",
    "qpara_md_naming_scheme = ['material', 'solvent', 'concentration', 'gap_height', 'blade_speed',\n",
    "                    'solution_temperature', 'stage_temperature', 'sample_number', 'time_start',\n",
    "                    'x_position_offset', 'incident_angle', 'exposure_time', 'scan_id', 'detector']\n",
    "\n",
    "# For rotated, qperp images:\n",
    "qperp_md_naming_scheme = ['material', 'solvent', 'concentration', 'gap_height', 'blade_speed',\n",
    "                    'solution_temperature', 'stage_temperature', 'sample_number', 'in-plane_orientation',\n",
    "                    'time_start', 'x_position_offset', 'incident_angle', 'exposure_time', 'scan_id', 'detector']\n",
    "\n",
    "# For in situ series images:\n",
    "in_situ_md_naming_scheme = ['material', 'solvent', 'concentration', 'gap_height', 'blade_speed',\n",
    "                    'solution_temperature', 'stage_temperature', 'sample_number', 'time_start',\n",
    "                    'x_position_offset', 'incident_angle', 'exposure_time', 'scan_id', \n",
    "                    'series_number', 'detector']\n",
    "\n",
    "# # Metadata naming schemes for the pm6 & pm7 S1 samples\n",
    "# # For nonrotated, qpara images:\n",
    "# qpara_md_naming_scheme = ['material', 'material description', 'solvent', 'concentration', 'gap_height', 'blade_speed',\n",
    "#                     'solution_temperature', 'stage_temperature', 'sample_number', 'time_start',\n",
    "#                     'x_position_offset', 'incident_angle', 'exposure_time', 'scan_id', 'detector']\n",
    "\n",
    "# # For rotated, qperp images:\n",
    "# qperp_md_naming_scheme = ['material', 'material description', 'solvent', 'concentration', 'gap_height', 'blade_speed',\n",
    "#                     'solution_temperature', 'stage_temperature', 'sample_number', 'in-plane_orientation',\n",
    "#                     'time_start', 'x_position_offset', 'incident_angle', 'exposure_time', 'scan_id', 'detector']\n",
    "\n",
    "# # For in situ series images:\n",
    "# in_situ_md_naming_scheme = ['material', 'material description', 'solvent', 'concentration', 'gap_height', 'blade_speed',\n",
    "#                     'solution_temperature', 'stage_temperature', 'sample_number', 'time_start',\n",
    "#                     'x_position_offset', 'incident_angle', 'exposure_time', 'scan_id', \n",
    "#                     'series_number', 'detector']\n",
    "\n",
    "# Initalize CMSGIWAXSLoader objects with the above naming schemes\n",
    "qpara_loader = phs.load.CMSGIWAXSLoader(md_naming_scheme=qpara_md_naming_scheme)\n",
    "qperp_loader = phs.load.CMSGIWAXSLoader(md_naming_scheme=qperp_md_naming_scheme)\n",
    "series_loader = phs.load.CMSGIWAXSLoader(md_naming_scheme=in_situ_md_naming_scheme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d72a19-8729-4ebd-914a-9cba20016a72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64998ce1-20eb-4a28-95d0-ef506b91166f",
   "metadata": {},
   "source": [
    "### Single image scans outside of series measurement\n",
    "Using same single_images_to_dataset function as in the single image processing example notebook\n",
    "Break up sets below according to your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca204fc-4388-4319-a910-10cdffb78934",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### qperp set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f8502-2cb9-4a4c-b31d-7c43db82b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the single_images_to_dataset function to pygix transform all raw files in an indexable list\n",
    "# files must be a pathlib Path and be a raw .tiff detector image\n",
    "# generate raw, recip (cartesian), and caked (polar) datasets containing dataarrays of all samples\n",
    "# optionally save as zarr stores with optional extra function parameters \n",
    "\n",
    "# Set a savename\n",
    "material = sample.split('_')[0]\n",
    "sample_num = sample.split('_')[-1]\n",
    "savename = f'{material}_qperp_{sample_num}'\n",
    "\n",
    "# Run function\n",
    "raw_DS, recip_DS, caked_DS = phs.GIWAXS.single_images_to_dataset(sorted(qperp_set), qperp_loader, qperp_transformer,\n",
    "                                                                 savePath = outPath.joinpath('qperp_zarrs'),\n",
    "                                                                 savename = savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b405bdb9-8282-4c94-9250-ee62087fffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of a quick plot check if desired here:\n",
    "# for DA in tqdm(recip_DS.data_vars.values()):   \n",
    "#     ax = DA.sel(q_perp=slice(-1.1, 2.1), q_z=slice(-0.05, 2.4)).plot.imshow(cmap=cmap, norm=LogNorm(1e1, 1e4), figsize=(8,4))\n",
    "#     ax.axes.set(aspect='equal', title=f'{DA.material}, incident angle: {DA.incident_angle}, scan id: {DA.scan_id}')\n",
    "#     plt.show()\n",
    "#     plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7d4cc9-ccf4-4576-b836-7632fe18bd04",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### qpara set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525907d-09a2-4ad6-9449-a52fba892fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# qpara_recip_integrator = phs.integrate.PGGeneralIntegrator(maskmethod = 'pyhyper',\n",
    "#                                                            maskpath = maskFile,\n",
    "#                                                            geomethod = 'ponifile',\n",
    "#                                                            ponifile = poniFile,\n",
    "#                                                            incident_angle = 0.12,\n",
    "#                                                            output_space = 'recip')\n",
    "\n",
    "raw_DA = qpara_loader.loadSingleImage(sorted(qpara_set)[0])\n",
    "qpara_recip_integrator = phs.integrate.PGGeneralIntegrator(geomethod = 'ponifile',\n",
    "                                                           ponifile = poniFile,\n",
    "                                                           output_space = 'recip',\n",
    "                                                           template_xr = raw_DA)\n",
    "qpara_caked_integrator = phs.integrate.PGGeneralIntegrator(geomethod = 'ponifile',\n",
    "                                                           ponifile = poniFile,\n",
    "                                                           output_space = 'caked',\n",
    "                                                           template_xr = raw_DA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53f68d-7764-4765-8b73-508aa11afedb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_DA = qpara_loader.loadSingleImage(sorted(qpara_set)[-1])\n",
    "\n",
    "\n",
    "qpara_recip_integrator.incident_angle = float(raw_DA.incident_angle[2:])\n",
    "recip_DA = qpara_recip_integrator.integrateSingleImage(raw_DA)\n",
    "recip_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb5a8f1-8f4c-47ad-9ebb-ab689e905cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_DA = qpara_loader.loadSingleImage(sorted(qpara_set)[-1])\n",
    "\n",
    "\n",
    "qpara_caked_integrator.incident_angle = float(raw_DA.incident_angle[2:])\n",
    "caked_DA = qpara_caked_integrator.integrateSingleImage(raw_DA)\n",
    "caked_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f1696-f36f-4a91-9533-aa2746c858f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the single_images_to_dataset function to pygix transform all raw files in an indexable list\n",
    "\n",
    "# # Set a savename\n",
    "# material = sample.split('_')[0]\n",
    "# sample_num = sample.split('_')[-1]\n",
    "# savename = f'{material}_qpara_{sample_num}'\n",
    "\n",
    "# # Run function\n",
    "# raw_DS, recip_DS, caked_DS = phs.GIWAXS.single_images_to_dataset(sorted(qpara_set), qpara_loader, qpara_transformer,\n",
    "#                                                                  savePath = outPath.joinpath('qpara_zarrs'),\n",
    "#                                                                  savename = savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa8a63-bdae-4e8a-b126-23d2a981f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of a quick plot check if desired here:\n",
    "# for DA in tqdm(list(recip_DS.data_vars.values())[0:10]):   \n",
    "#     ax = DA.sel(q_para=slice(-1.1, 2.1), q_z=slice(-0.05, 2.4)).plot.imshow(cmap=cmap, norm=LogNorm(1e1, 1e4), figsize=(8,4))\n",
    "#     ax.axes.set(aspect='equal', title=f'{DA.material}, incident angle: {DA.incident_angle}, scan id: {DA.scan_id}')\n",
    "#     plt.show()\n",
    "#     plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c8af7-0ff8-4e97-baed-7407423c9424",
   "metadata": {},
   "source": [
    "### Series measurement processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0834ff7d-9a80-4df4-9f47-7bdc31470764",
   "metadata": {},
   "source": [
    "#### Save each series as its own DataSet\n",
    "For some samples the series is broken up into different scan ids and exposure times, so I opted to just save each dataarray as its own zarr dataset. Later in the plotting notebook, I load the dataarrays and then will normalize by exposure time and concatenate along the time dimension. This should all be refined into a function like \"series_to_datasets\", but it isn't super urgen IMO as the code is pretty straightforward to do and more flexible this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb893233-15cb-4c51-bb12-79bd1b87fd2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pyFAI.io.ponifile import PoniFile\n",
    "# PoniFile(data=str(poniFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069c4dea-3e57-4211-a4cd-aaa5e8ee4480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_DA = series_loader.loadSeries(sorted(exp0p1_set))\n",
    "s_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543588d-65b2-453e-aee2-92fd09afafa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Choose series scan id(s)\n",
    "# series_ids = ['1118329', '1118330', '1118331']\n",
    "\n",
    "# # Create separate sets for single vs series measurements, customize per your data:\n",
    "# # I had 3 different scan ids in one series measurement, so I combine them all first \n",
    "# # before substracting them from the total file list\n",
    "# exp0p1_set = set(samplePath.glob(f'*{series_ids[0]}*')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52c7df-af22-4784-ab21-d8351841d82e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "updated_DA = series_loader.loadFileSeries(basepath=samplePath, dims=['series_number'], file_filter='0.10s_1118329')\n",
    "# updated_DA\n",
    "\n",
    "time_start = 0\n",
    "exp_time = np.round(float(updated_DA.exposure_time[:-1]), 1)\n",
    "\n",
    "fs_DA = updated_DA.unstack('system')\n",
    "fs_DA = fs_DA.assign_coords({'time': ('series_number', fs_DA.series_number.data.astype('float')*exp_time+exp_time+time_start)})\n",
    "fs_DA = fs_DA.swap_dims({'series_number': 'time'})\n",
    "fs_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af090076-54a5-4a78-b318-66ad7cae977b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Facet plot of selected times\n",
    "# # cmin = float(fs_DA.sel(time=10, method='nearest').compute().quantile(0.01))\n",
    "# # cmax = float(fs_DA.sel(time=10, method='nearest').compute().quantile(0.99))\n",
    "\n",
    "# cmin=1\n",
    "# cmax=10\n",
    "# times = np.linspace(0.1, 10, 8)\n",
    "\n",
    "# sliced_DA = s_DA.sel(time=times, method='nearest')\n",
    "# fg = sliced_DA.plot.imshow(figsize=(18, 6), col='time', col_wrap=4, norm=plt.Normalize(cmin, cmax), cmap=cmap, origin='upper')\n",
    "# fg.cbar.set_label('Intensity [arb. units]', rotation=270, labelpad=15)\n",
    "# for axes in fg.axs.flatten():\n",
    "#     axes.set(aspect='equal')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de988e45-6cee-4158-9f1f-157c47ba5751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Facet plot of selected times\n",
    "# # cmin = float(fs_DA.sel(time=10, method='nearest').compute().quantile(0.01))\n",
    "# # cmax = float(fs_DA.sel(time=10, method='nearest').compute().quantile(0.99))\n",
    "\n",
    "# cmin=1\n",
    "# cmax=10\n",
    "# times = np.linspace(0.1, 10, 8)\n",
    "\n",
    "# sliced_DA = fs_DA.sel(time=times, method='nearest')\n",
    "# fg = sliced_DA.plot.imshow(figsize=(18, 6), col='time', col_wrap=4, norm=plt.Normalize(cmin, cmax), cmap=cmap, origin='upper')\n",
    "# fg.cbar.set_label('Intensity [arb. units]', rotation=270, labelpad=15)\n",
    "# for axes in fg.axs.flatten():\n",
    "#     axes.set(aspect='equal')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0e382-3e65-4d03-ac32-9b84999d3fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for time in fs_DA.time.values[:2]:\n",
    "#     sliced_DA = fs_DA.sel(time=[time], method='nearest')\n",
    "#     display(sliced_DA)\n",
    "#     recip_DA = qpara_recip_integrator.integrateSingleImage(sliced_DA)\n",
    "#     display(recip_DA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dae9f04-ef23-4d3d-b4c5-8d8016ef0777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recip_DA = qpara_recip_integrator.integrateImageStack(fs_DA)\n",
    "recip_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae35fe-68c0-4a63-b377-73654d3517b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "caked_DA = qpara_caked_integrator.integrateImageStack(fs_DA)\n",
    "caked_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b52e805-9d63-49b3-abb6-49e0944d8bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Facet plot of selected times\n",
    "# cmin = float(fs_DA.sel(time=10, method='nearest').compute().quantile(0.01))\n",
    "# cmax = float(fs_DA.sel(time=10, method='nearest').compute().quantile(0.99))\n",
    "\n",
    "cmin=1\n",
    "cmax=10\n",
    "times = np.linspace(0.1, 10, 8)\n",
    "\n",
    "sliced_DA = recip_DA.sel(time=times, method='nearest')\n",
    "fg = sliced_DA.plot.imshow(figsize=(18, 6), col='time', col_wrap=4, norm=plt.Normalize(cmin, cmax), cmap=cmap)\n",
    "fg.cbar.set_label('Intensity [arb. units]', rotation=270, labelpad=15)\n",
    "for axes in fg.axs.flatten():\n",
    "    axes.set(aspect='equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85480b1-f5fe-44c3-ae83-47fe870f7275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Facet plot of selected times\n",
    "# cmin = float(fs_DA.sel(time=10, method='nearest').compute().quantile(0.01))\n",
    "# cmax = float(fs_DA.sel(time=10, method='nearest').compute().quantile(0.99))\n",
    "\n",
    "cmin=1\n",
    "cmax=10\n",
    "times = np.linspace(0.1, 10, 8)\n",
    "\n",
    "sliced_DA = caked_DA.sel(time=times, method='nearest')\n",
    "fg = sliced_DA.plot.imshow(figsize=(18, 6), col='time', col_wrap=4, norm=plt.Normalize(cmin, cmax), cmap=cmap)\n",
    "fg.cbar.set_label('Intensity [arb. units]', rotation=270, labelpad=15)\n",
    "# for axes in fg.axs.flatten():\n",
    "#     axes.set(aspect='equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9b55d9-eff8-4c84-b5d5-07e410a1ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For a series set of just one scan ID\n",
    "\n",
    "# DA = series_loader.loadSeries(sorted(series_set))\n",
    "# recip_DA, caked_DA = qpara_transformer.pg_convert_series(DA)\n",
    "\n",
    "# # Transform DataArrays into DataSets & save as .zarr stores\n",
    "# raw_DS = DA.to_dataset(name='DA')\n",
    "# recip_DS = recip_DA.to_dataset(name='DA')\n",
    "# caked_DS = caked_DA.to_dataset(name='DA')\n",
    "\n",
    "# # Specify a suffix for saving the raw, recip, and caked DataSets. \n",
    "# suffix = f'{DA.scan_id}_{DA.material}_0to90s_qpara_{DA.sample_number}'\n",
    "\n",
    "# raw_DS.to_zarr(savePath.joinpath('series_zarrs', f'raw_{suffix}.zarr'), mode='w')\n",
    "# recip_DS.to_zarr(savePath.joinpath('series_zarrs', f'recip_{suffix}.zarr'), mode='w')\n",
    "# caked_DS.to_zarr(savePath.joinpath('series_zarrs', f'caked_{suffix}.zarr'), mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1999891-7d30-419f-888c-fd110aa9d388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # For a series set for multiple scan IDs / time starts\n",
    "\n",
    "# time_starts = [0, 10, 90]\n",
    "# time_ranges = ['0to10', '10to90', '90to180']\n",
    "# for i, series in enumerate((exp0p1_set, exp0p5_set, exp2p0_set)):\n",
    "#     # Select the first element of the sorted set outside of the for loop to initialize the xr.DataSet\n",
    "#     DA = series_loader.loadSeries(sorted(series), time_start= time_starts[i])\n",
    "#     recip_DA, caked_DA = qpara_transformer.pg_convert_series(DA)\n",
    "\n",
    "#     # Transform DataArrays into DataSets & save as .zarr stores\n",
    "#     raw_DS = DA.to_dataset(name='DA')\n",
    "#     recip_DS = recip_DA.to_dataset(name='DA')\n",
    "#     caked_DS = caked_DA.to_dataset(name='DA')\n",
    "\n",
    "#     # Specify a suffix for saving the raw, recip, and caked DataSets. \n",
    "#     suffix = f'{DA.scan_id}_{DA.material}_{time_ranges[i]}s_qpara_{DA.sample_number}'\n",
    "\n",
    "#     raw_DS.to_zarr(savePath.joinpath('series_zarrs', f'raw_{suffix}.zarr'), mode='w')\n",
    "#     recip_DS.to_zarr(savePath.joinpath('series_zarrs', f'recip_{suffix}.zarr'), mode='w')\n",
    "#     caked_DS.to_zarr(savePath.joinpath('series_zarrs', f'caked_{suffix}.zarr'), mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f0fbab-4884-42b1-b2fe-3cc45d206b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nrss",
   "language": "python",
   "name": "nrss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
