{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data analysis with SciAnalysis\n",
    "\n",
    "last updated: 2023 May\n",
    "\n",
    "In this notebook, we can load the raw tiff, load or extract metedata, analysis the data, save the analysis results and metadata in .H5.\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    "*exp.dict*: The experiment dictionary. 'Experiment' is a series of measurements, e.g. in-situ thermal annealing measurements of a sample.\n",
    "\n",
    "*exp.dict.keys()*: ['analysis', 'corr', 'corrdata', 'data', 'detector', 'exp_protocol', 'expinfo', 'expname', 'folder', 'mdata_list', 'metadata']\n",
    "\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# &#9635; SciAnalysis for Experiment\n",
    "\n",
    "At home insitute, download SciAnalysis at: https://github.com/CFN-softbio/SciAnalysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%matplotlib nbagg\n",
    "# Imports\n",
    "########################################\n",
    "import sys, os, time, glob, imageio, datetime, pprint, math\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from silx.io.dictdump import dicttoh5, h5todict\n",
    "\n",
    "SciAnalysis_PATH='/nsls2/data/cms/legacy/xf11bm/software/SciAnalysis/' ### Specify this\n",
    "SciAnalysis_PATH in sys.path or sys.path.append(SciAnalysis_PATH)\n",
    "\n",
    "from SciAnalysis import tools\n",
    "from SciAnalysis.XSAnalysis.Data import *\n",
    "from SciAnalysis.XSAnalysis import Protocols\n",
    "\n",
    "from SciAnalysis.ExpAnalysis import Experiment\n",
    "from SciAnalysis.ExpAnalysis import Tools\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"{}\\n\".format(dt_string))\n",
    "\n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Direct beam (if available)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calibration: Energy, beam center, SD distance__\n",
    "\n",
    "1. Specify wavelength \n",
    "2. Tweak beam center and SD distance to get the best match for the calibrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convert between q and angle__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for KWhite data in 2023C2\n",
    "\n",
    "### Use scanid to load the series_measure data `exp.defFiles_ScanID_ONLY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exp.defFiles(fn=pattern, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Specify directory, detector, and files of interest\n",
    "\n",
    "    \n",
    "if 1: \n",
    "    # EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/' \n",
    "    # samplefolder_load = 'sam99_1mai1pbi2_1dmf1dmso_1m_5scfh_Si_40uL_011' # sam16_3mai1pbi2_dmf_1m_5scfh_Si_40uL_010\n",
    "    # scanid = 1116248\n",
    "    \n",
    "    samplefolder_load = 'sam98_3mai1pbi2_1dmf1dmso_1m_5scfh_Si_40uL_012' # sam16_3mai1pbi2_dmf_1m_5scfh_Si_40uL_010\n",
    "    scanid = 1116272\n",
    "    \n",
    "    EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/'  + samplefolder_load + '/'\n",
    "    exp = Experiment.experiment(samplefolder_load, folder=EXPR_DIR, det='maxs', series_measure=True, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    exp.dict['expinfo']['fn_patterns'] = [f'{samplefolder_load}*']  \n",
    "\n",
    "\n",
    "### Load files\n",
    "try:\n",
    "    for pattern in exp.dict['expinfo']['fn_patterns']:\n",
    "        #exp.defFiles_query(fn='PBG', folder=EXPR_DIR, scanid = [900000, 1200000], verbose=1) \n",
    "        print(f'pattern = {pattern}')\n",
    "        # exp.defFiles(fn=pattern, verbose=1) \n",
    "        # exp.defFiles(fn=pattern, scanid = [750000, 900000], verbose=1)  \n",
    "        # infiles = exp.defFiles_ScanID_ONLY(fn=pattern, scanid = [1116002], verbose=1)  \n",
    "        infiles = exp.defFiles_ScanID_ONLY(fn=pattern, scanid = [scanid], verbose=1)  \n",
    "    \n",
    "    # infiles = exp.dict['rawinfo']['filename']\n",
    "    Nfiles = len(infiles)\n",
    "    \n",
    "except:\n",
    "    print('\\n!!! Databroker not working, loading files directly.')\n",
    "    #exp.dict['expinfo']['beamline'] = None\n",
    "    for pattern in exp.dict['expinfo']['fn_patterns']:\n",
    "        exp.defFiles_ScanID_ONLY(fn=pattern, scanid = [scanid], verbose=1)  \n",
    "    \n",
    "\n",
    "### Show some info   \n",
    "exp.show()\n",
    "exp.showFileInfo(idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## See metadata for one file\n",
    "import databroker\n",
    "cat = databroker.catalog['cms']\n",
    "scan_id = exp.dict['rawinfo']['scan_id'][0]  #959455\n",
    "# scan_id = 1116295\n",
    "scan_id = 1116317\n",
    "\n",
    "scan_id = 1112650\n",
    "\n",
    "query = {'scan_id': {'$gte': scan_id, '$lte': scan_id}, \n",
    "        }\n",
    "res = cat.search(query)\n",
    "\n",
    "# h = cat[scan_id]\n",
    "# h.metadata['start']\n",
    "for _uid in res:\n",
    "    print(cat[_uid].metadata['start']['scan_id'], cat[_uid].metadata['start']['experiment_group'], cat[_uid].metadata['start']['plan_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat[list(res)[0]].metadata['start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uid = '28aacc73'\n",
    "h = cat[uid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Options: (1) load metadata from databroker at beamline. (2) load md from h5. (3) Extract info from filename\n",
    "md_load_option = 1\n",
    "\n",
    "## Clear all metadata\n",
    "exp.dict['metadata'] = {}\n",
    "\n",
    "\n",
    "## Load metadata\n",
    "if md_load_option==1: # Load md from databroker, this only works at beamline\n",
    "    exp.dict['mdata_list'] = ['scan_id'] # Specify metedata to load\n",
    "    exp.loadMetadata()\n",
    "    print(exp.dict['metadata'].keys())\n",
    "    \n",
    "elif md_load_option==2: # Load md from h5 (previously saved from databroker)\n",
    "    h5_path = EXPR_DIR+\"/data/\"\n",
    "    h5_file = 'B6_N3_metadata.h5'\n",
    "    exp.dict['metadata'] = h5todict(h5_path+h5_file)\n",
    "\n",
    "\n",
    "elif md_load_option==3: ## If databroker md is not available nor saved\n",
    "    infiles = exp.dict['rawinfo']['filename']\n",
    "    print('Number of files: {}'.format(len(infiles)))\n",
    "\n",
    "    Ts = []\n",
    "    sample_x = []\n",
    "    sample_y = []\n",
    "    scan_id = []\n",
    "    frames = []\n",
    "    for ii, infile in enumerate(infiles):\n",
    "        temp = infile.split('_')\n",
    "        if ii==0: print(temp)\n",
    "        \n",
    "        Ts.append(float(infile.split('Linkam')[1].split('C')[0]))\n",
    "        #sample_x.append(float(temp[-4][1:]))\n",
    "        #sample_y.append(float(temp[-3][1:]))\n",
    "        \n",
    "        #Ts.append(float(infile.split('RH')[1].split('_x')[0]))\n",
    "        #scan_id.append(int(temp[-1]))\n",
    "        #frames.append(int(temp[-1]))\n",
    "\n",
    "    exp.dict['metadata']['sample_temperature_D'] = Ts\n",
    "    #exp.dict['metadata']['sample_x'] = np.array(sample_x)\n",
    "    #exp.dict['metadata']['sample_y'] = np.array(sample_y)\n",
    "    #exp.dict['metadata']['frames'] = frames\n",
    "    \n",
    "    print(exp.dict['metadata'].keys())\n",
    "\n",
    "else:\n",
    "    print('No metadata loaded to the exp. dictionary!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Analysis\n",
    "\n",
    "We suspect that loading analysis results is slow, faster if processing raw data. However, going through the protocals is also slow; storing it to the exp.dict also takes a bit time.\n",
    "\n",
    "E.g. 3600 files, 1 protocol, saving to exp.dict: 5min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Specify beamline config (e.g. beam energy, center, det-sample distance)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 1: #WAXS, MAXS\n",
    "    #calibration = Calibration(wavelength_A=0.7293) # 17 keV\n",
    "    calibration = Calibration(wavelength_A=12.4/12.7) #13.5 keV\n",
    "    calibration.set_image_size(981, height=1043) # Pilatus1M\n",
    "    calibration.set_pixel_size(pixel_size_um=172.0)\n",
    "    \n",
    "    calibration.set_beam_position(576, 1043-390) # Pilatus 800k x=450 y=398 works in xi-cam, in scianalysis need y=1043-398=645\n",
    "    calibration.set_distance(0.3)\n",
    "\n",
    "    ## LRichter\n",
    "    if 0:\n",
    "        calibration.set_beam_position(543, 606) #LRichter\n",
    "        calibration.set_distance(0.2815)\n",
    "    \n",
    "    mask_dir = SciAnalysis_PATH + '/SciAnalysis/XSAnalysis/masks/'\n",
    "    mask = Mask(mask_dir+'Dectris/Pilatus800k2_gaps-mask.png')\n",
    "    mask.load('./Pilatus800k2_custom-mask.png')\n",
    "\n",
    "  \n",
    "    \n",
    "load_args = { 'calibration' : calibration, \n",
    "             'mask' : mask,\n",
    "             #'rot180' : False,\n",
    "             #'flip' : True, # PSCCD\n",
    "             }\n",
    "run_args = { 'verbosity' : 3,\n",
    "            #'save_results' : ['xml', 'plots', 'txt', 'hdf5'],\n",
    "            }\n",
    "process = Protocols.ProcessorXS(load_args=load_args, run_args=run_args)\n",
    "\n",
    "\n",
    "### Run analysis \n",
    "protocols = ['circular_average'] #['linecut_angle'] #['circular_average'] #, 'sector_average', 'linecut_qz']\n",
    "\n",
    "exp.dict['analysis']['cali'] = [calibration.wavelength_A, calibration.x0, calibration.y0, calibration.distance_m]\n",
    "#exp.dict['analysis'] = {} \n",
    "#for protocol in protocols:\n",
    "#    exp.dict['analysis'][protocol] = {}\n",
    "\n",
    "t0 = time.time()  \n",
    "    \n",
    "line_y_stack = []\n",
    "for protocol in protocols:\n",
    "    if 'circular_average' in protocol:\n",
    "        for ii, infile in enumerate(infiles):\n",
    "            if np.mod(ii+1, 50)==0: print('[{:.0f}%]'.format(ii/Nfiles*100))\n",
    "\n",
    "            det = exp.dict['expinfo']['det']\n",
    "            folder = exp.dict['expinfo']['folder']\n",
    "\n",
    "            # infile_fullpath = folder+'/'+det+'/raw/'+exp.dict['rawinfo']['filename'][ii]+'_'+det+'.tiff'\n",
    "            infile_fullpath = infile\n",
    "            # print(infile_fullpath)\n",
    "            data = process.load(infile_fullpath, calibration=calibration, mask=mask, run_args=run_args)\n",
    "\n",
    "            ### Run the protocol\n",
    "            line_output = data.circular_average_q_bin(error=False)\n",
    "            line_y_stack.append(line_output.y)\n",
    "\n",
    "            if 0:\n",
    "                exp.dict['analysis'][protocol][str(ii)] = {}\n",
    "                exp.dict['analysis'][protocol][str(ii)]['q'] = line_output.x\n",
    "                exp.dict['analysis'][protocol][str(ii)]['I(q)'] = line_output.y\n",
    "        \n",
    "        ### Save analysis to exp.dict\n",
    "        if 1:\n",
    "            exp.dict['analysis'][protocol] = {}\n",
    "            exp.dict['analysis'][protocol]['q'] = line_output.x\n",
    "            exp.dict['analysis'][protocol]['I_stack'] = line_y_stack   \n",
    "            #x = Protocols.thumbnails(name=None) \n",
    "            #x.run(data, output_dir)\n",
    "            \n",
    "    if 'linecut_qr' in protocol:\n",
    "        for ii, infile in enumerate(infiles):\n",
    "            if np.mod(ii+1, 50)==0: print('[{:.0f}%]'.format(ii/Nfiles*100))\n",
    "\n",
    "            det = exp.dict['expinfo']['det']\n",
    "            folder = exp.dict['expinfo']['folder']\n",
    "\n",
    "            infile_fullpath = folder+'/'+det+'/raw/'+exp.dict['rawinfo']['filename'][ii]+'_'+det+'.tiff'\n",
    "            data = process.load(infile_fullpath, calibration=calibration, mask=mask, run_args=run_args)\n",
    "\n",
    "            ### Run the protocol\n",
    "            line_output = data.linecut_qr(qz=0.03, dq=0.003)\n",
    "            line_y_stack.append(line_output.y)\n",
    "\n",
    "        ### Save analysis to exp.dict\n",
    "        if 1:\n",
    "            exp.dict['analysis'][protocol] = {}\n",
    "            exp.dict['analysis'][protocol]['q'] = line_output.x\n",
    "            exp.dict['analysis'][protocol]['I_stack'] = line_y_stack           \n",
    "        \n",
    "    #elif 'sector_average' in protocol: \n",
    "    #    line_output = data.sector_average_q_bin(angle=60, dangle=5)\n",
    "\n",
    "    #elif 'linecut_qz' in protocol:\n",
    "    #    line_output = data.linecut_qz(qr=0, dq=0.05)\n",
    "\n",
    "    #elif 'linecut_angle' in protocol:\n",
    "    #line_output = data.linecut_angle(q0=2.24, dq=0.01)\n",
    "            \n",
    "        \n",
    "print('Done! (Analysis took {:.0f}s)\\n'.format(time.time()-t0))\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"{}\\n\".format(dt_string))\n",
    "\n",
    "print(exp.dict['analysis'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save \n",
    "\n",
    "Save experiment dictionary (exp.dict) to h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# h5_path = EXPR_DIR+\"/data/\"\n",
    "\n",
    "h5_path = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/'+\"/data/\"\n",
    "\n",
    "\n",
    "h5_file = str(exp.dict['expinfo']['expname']) + '_cms_exp.h5'\n",
    "output_file = h5_path+h5_file\n",
    "\n",
    "\n",
    "## Check if file exist, will not overwrite\n",
    "if False:\n",
    "    file_exist = os.path.isfile(output_file)\n",
    "    count = 1\n",
    "    while file_exist:\n",
    "        print('{} exists, using a new filename'.format(output_file))\n",
    "        h5_file = str(exp.dict['expname']) + '_exp_' + str(count) + '.h5'\n",
    "        output_file = h5_path+h5_file\n",
    "        file_exist = os.path.isfile(output_file)\n",
    "        count = count + 1\n",
    "\n",
    "        \n",
    "## Save\n",
    "dicttoh5(exp.dict, output_file)\n",
    "print('Experiment saved as {}'.format(output_file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Load H5__\n",
    "\n",
    "Load experiment dictionary and recover the object 'exp', allowing for subsequent data visualization/analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%matplotlib nbagg\n",
    "# Imports\n",
    "########################################\n",
    "import sys, os, time, glob, imageio, datetime, pprint\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from silx.io.dictdump import dicttoh5, h5todict\n",
    "SciAnalysis_PATH='/nsls2/data/cms/legacy/xf11bm/software/SciAnalysis/' ### Specify this\n",
    "SciAnalysis_PATH in sys.path or sys.path.append(SciAnalysis_PATH)\n",
    "from SciAnalysis import tools\n",
    "from SciAnalysis.XSAnalysis.Data import *\n",
    "from SciAnalysis.XSAnalysis import Protocols\n",
    "from SciAnalysis.ExpAnalysis import Experiment\n",
    "from SciAnalysis.ExpAnalysis import Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5file_load = 'sam98_3mai1pbi2_1dmf1dmso_1m_5scfh_Si_40uL_012_cms_exp.h5'\n",
    "h5file_load = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Load experiment dict (previuosly analyzed data)\n",
    "if True:\n",
    "    \n",
    "    #exp_dict_h5 = '/nsls2/data/cms/legacy/xf11bm/data/2022_3/RHeadrick3//data/B6_N3_cms_exp.h5'\n",
    "    #exp_dict_h5 = '/nsls2/data/cms/legacy/xf11bm/data/2023_1/beamline/ETsai2//data/PBG_run1_cms_exp.h5'\n",
    "    # exp_dict_h5 = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/data/sam1_pbi2_dmf_cms_exp.h5'\n",
    "    \n",
    "    # h5file_load = 'sam99_1mai1pbi2_1dmf1dmso_1m_5scfh_Si_40uL_011_cms_exp.h5'\n",
    "    \n",
    "    if h5file_load is None:\n",
    "        h5file_load = h5_file # use the one that is just saved\n",
    "    \n",
    "    exp_dict_h5 = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/data/' + h5file_load\n",
    "    \n",
    "    \n",
    "    exp_dict_load = h5todict(exp_dict_h5)\n",
    "    #print(exp_dict_load.keys())\n",
    "    \n",
    "    exp = Experiment.experiment(exp_dict_load['expinfo']['expname'], folder=exp_dict_load['expinfo']['folder'], det=exp_dict_load['expinfo']['det'], beamline=exp_dict_load['expinfo']['beamline']) \n",
    "    exp.dict = exp_dict_load\n",
    "    \n",
    "    print(exp.dict.keys())\n",
    "    print('\\nExperiment loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __Overview of exp__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.show(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __(5.1) Data Trend__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#9642; __Plot curves__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - __Load one curve & find peaks__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Show one curve and find peaks\n",
    "\n",
    "#protocol = 'circular_average'\n",
    "protocol = list(exp.dict['analysis'].keys())[-1]\n",
    "print(protocol)\n",
    "print(exp.dict['rawinfo']['filename'][-1])\n",
    "\n",
    "## Pick a curve\n",
    "file_idx = 250\n",
    "line_plot = DataLine(x = exp.dict['analysis'][protocol]['q'], y = exp.dict['analysis'][protocol]['I_stack'][file_idx])  \n",
    "flag_log = 1\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib ipympl\n",
    "plt.figure(1, figsize=(12,5)); plt.clf()\n",
    "q_peaks = Tools.plot_peaks(line_plot, N_peaks_find = 5, fit_param=[0, 1, 0.001], flag_log=flag_log, line_color='k', label_color='r', verbose=1)  #Tools.rand_color(0.5, 0.8)\n",
    "\n",
    "q_label = [0.1076]\n",
    "for q in q_label:\n",
    "    if flag_log:\n",
    "        y_range = [0, max(np.log(line_plot.y))]\n",
    "    else:\n",
    "        y_range = [min(line_plot.y), max(np.log(line_plot.y))]\n",
    "    plt.plot([q, q], y_range, 'g',  alpha=0.7)\n",
    "    plt.text(q, y_range[1]/2, str(q), color='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - __Plot all curves as 2D image__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_label = q_peaks #[1.278, 1.88, 2.219, 2.564, 2.905]; # Label the lines\n",
    "flag_log = True\n",
    "\n",
    "#protocol = 'circular_average'\n",
    "protocol = list(exp.dict['analysis'].keys())[-1]\n",
    "\n",
    "\n",
    "x_axis = exp.dict['analysis'][protocol]['q'] \n",
    "I_stack = exp.dict['analysis'][protocol]['I_stack']\n",
    "# y_axis = exp.dict['metadata']['scan_id'] - exp.dict['metadata']['scan_id'][0]\n",
    "# y_axis = exp.dict['metadata']['sample_clock'] #- exp.dict['metadata']['sample_clock'][0]\n",
    "\n",
    "y_axis = np.arange(len(infiles))\n",
    "if flag_log:\n",
    "    I_stack = np.log10(I_stack)\n",
    "    \n",
    "%matplotlib inline\n",
    "plt.figure(2, figsize=(12,8)); plt.clf()\n",
    "# plt.imshow(I_stack, origin='lower', cmap='jet', extent = [np.min(x_axis), np.max(x_axis), scan_id[0], scan_id[-1]],  aspect='auto') #aspect='auto' 0.005\n",
    "# # plt.imshow(I_stack, origin='lower', cmap='jet', extent = [np.min(x_axis), np.max(x_axis), 0, I_stack.shape[0]],  aspect='auto') #aspect='auto' 0.005\n",
    "# cbar = plt.colorbar(fraction=0.02, pad=0.02, aspect=40) \n",
    "\n",
    "# y_axis = np.arange(0, I_stack.shape[0])\n",
    "X, Y = np.meshgrid(x_axis, y_axis)\n",
    "#dont know how to change the plotting range in pcolormesh\n",
    "# plt.pcolormesh(X,Y,I_stack,vmin=.3,vmax=2.8, cmap=mpl.cm.jet); plt.colorbar()\n",
    "plt.pcolormesh(X,Y,I_stack, cmap=mpl.cm.jet); plt.colorbar()\n",
    "plt.xlabel(r'$q$ $({\\rm \\AA}^{-1})$', size=20)\n",
    "plt.ylabel('index', size=20)\n",
    "# plt.ylabel('Time (s)')\n",
    "# plt.xlim(-.2, .2)\n",
    "# plt.ylim(0, 2)\n",
    "\n",
    "print('q_label = {}'.format(q_label))\n",
    "#for q in q_label:\n",
    "#    plt.plot([q, q], [0, I_stack.shape[0]], 'k',  alpha=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_label = q_peaks #[1.278, 1.88, 2.219, 2.564, 2.905]; # Label the lines\n",
    "flag_log = True\n",
    "\n",
    "#protocol = 'circular_average'\n",
    "protocol = list(exp.dict['analysis'].keys())[-1]\n",
    "\n",
    "\n",
    "x_axis = exp.dict['analysis'][protocol]['q'] \n",
    "I_stack = exp.dict['analysis'][protocol]['I_stack']\n",
    "# y_axis = exp.dict['metadata']['scan_id'] - exp.dict['metadata']['scan_id'][0]\n",
    "# y_axis = exp.dict['metadata']['sample_clock'] #- exp.dict['metadata']['sample_clock'][0]\n",
    "\n",
    "y_axis = np.arange(len(infiles))\n",
    "if flag_log:\n",
    "    I_stack = np.log10(I_stack)\n",
    "    \n",
    "%matplotlib inline\n",
    "plt.figure(2, figsize=(12,8)); plt.clf()\n",
    "# plt.imshow(I_stack, origin='lower', cmap='jet', extent = [np.min(x_axis), np.max(x_axis), scan_id[0], scan_id[-1]],  aspect='auto') #aspect='auto' 0.005\n",
    "# # plt.imshow(I_stack, origin='lower', cmap='jet', extent = [np.min(x_axis), np.max(x_axis), 0, I_stack.shape[0]],  aspect='auto') #aspect='auto' 0.005\n",
    "# cbar = plt.colorbar(fraction=0.02, pad=0.02, aspect=40) \n",
    "\n",
    "# y_axis = np.arange(0, I_stack.shape[0])\n",
    "X, Y = np.meshgrid( y_axis, x_axis)\n",
    "#dont know how to change the plotting range in pcolormesh\n",
    "# plt.pcolormesh(X,Y,I_stack,vmin=.3,vmax=2.8, cmap=mpl.cm.jet); plt.colorbar()\n",
    "plt.pcolormesh(X,Y,I_stack.T, cmap=mpl.cm.jet) #, vmin=0.2,vmax=2.3); \n",
    "plt.colorbar()\n",
    "plt.ylabel(r'$q$ $({\\rm \\AA}^{-1})$', size=20)\n",
    "plt.xlabel('index', size=20)\n",
    "# plt.ylabel('Time (s)')\n",
    "# plt.xlim(-.2, .2)\n",
    "# plt.ylim(0.3, 3)\n",
    "\n",
    "print('q_label = {}'.format(q_label))\n",
    "#for q in q_label:\n",
    "#    plt.plot([q, q], [0, I_stack.shape[0]], 'k',  alpha=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
