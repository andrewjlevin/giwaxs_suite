{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data analysis with SciAnalysis\n",
    "\n",
    "last updated: 2023 May\n",
    "\n",
    "In this notebook, we can load the raw tiff, load or extract metedata, analysis the data, save the analysis results and metadata in .H5.\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    "*exp.dict*: The experiment dictionary. 'Experiment' is a series of measurements, e.g. in-situ thermal annealing measurements of a sample.\n",
    "\n",
    "*exp.dict.keys()*: ['analysis', 'corr', 'corrdata', 'data', 'detector', 'exp_protocol', 'expinfo', 'expname', 'folder', 'mdata_list', 'metadata']\n",
    "\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# &#9635; SciAnalysis for Experiment\n",
    "\n",
    "At home insitute, download SciAnalysis at: https://github.com/CFN-softbio/SciAnalysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%matplotlib nbagg\n",
    "# Imports\n",
    "########################################\n",
    "import sys, os, time, glob, imageio, datetime, pprint, math\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from silx.io.dictdump import dicttoh5, h5todict\n",
    "\n",
    "SciAnalysis_PATH='/nsls2/data/cms/legacy/xf11bm/software/SciAnalysis/' ### Specify this\n",
    "SciAnalysis_PATH in sys.path or sys.path.append(SciAnalysis_PATH)\n",
    "\n",
    "from SciAnalysis import tools\n",
    "from SciAnalysis.XSAnalysis.Data import *\n",
    "from SciAnalysis.XSAnalysis import Protocols\n",
    "\n",
    "from SciAnalysis.ExpAnalysis import Experiment\n",
    "from SciAnalysis.ExpAnalysis import Tools\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"{}\\n\".format(dt_string))\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Direct beam (if available)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/beamline/CKe/saxs/'  \n",
    "EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_1/LRichter2/AgBH_cali_13.5kev_openarea/maxs/'\n",
    "pattern = '*directbeam*'\n",
    "infiles = glob.glob(os.path.join(EXPR_DIR+'raw/', pattern+'.tiff'))\n",
    "print(infiles)\n",
    "\n",
    "data = Data2DScattering()\n",
    "data.load(infiles[0])\n",
    "#data.blur(sigma=1)\n",
    "img = data.data\n",
    "print('Size = {}'.format(img.shape))\n",
    "\n",
    "## Plot\n",
    "%matplotlib inline\n",
    "plt.figure(1); plt.imshow(np.log(img+3)); plt.colorbar()\n",
    "beam_center = [np.argmax(np.max(img,0)), np.argmax(np.max(img,1))]\n",
    "print('Beam center = {}'.format(beam_center))\n",
    "\n",
    "img[beam_center[1], beam_center[0]] = 0\n",
    "beam_center = [np.argmax(np.max(img,0)), np.argmax(np.max(img,1))]\n",
    "print('Beam center = {}'.format(beam_center))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calibration: Energy, beam center, SD distance__\n",
    "\n",
    "1. Specify wavelength \n",
    "2. Tweak beam center and SD distance to get the best match for the calibrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/beamline/CKe/'\n",
    "EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_1/LRichter2/AgBH_cali_13.5kev_openarea/'\n",
    "exp = Experiment.experiment('Ag', folder=EXPR_DIR, det='maxs', beamline=None) ##Experiment name: rbitrary or related to the sample name\n",
    "pattern = '*Ag*1230*'  \n",
    "\n",
    "\n",
    "EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/beamline/RLi2/' \n",
    "exp = Experiment.experiment('B5', folder=EXPR_DIR, det='saxs', series_measure=False, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "pattern = '*B5-80*26179*'\n",
    "\n",
    "        \n",
    "        \n",
    "exp.defFiles(fn=pattern, verbose=0)     \n",
    "infiles = exp.dict['rawinfo']['filename']\n",
    "Nfiles = len(infiles)\n",
    "    \n",
    "if 0: #WAXS, MAXS\n",
    "    #calibration = Calibration(wavelength_A=0.7293) # 17 keV\n",
    "    calibration = Calibration(wavelength_A=0.9184) #13.5 keV\n",
    "    calibration.set_image_size(981, height=1043) # Pilatus1M\n",
    "    calibration.set_pixel_size(pixel_size_um=172.0)\n",
    "    #calibration.set_beam_position(313.5, 1043-314) #SA, 2023 Apr\n",
    "    calibration.set_beam_position(543, 606) #LRichter\n",
    "\n",
    "    #calibration.set_distance(0.259)\n",
    "    calibration.set_distance(0.2815)\n",
    "    mask_dir = SciAnalysis_PATH + '/SciAnalysis/XSAnalysis/masks/'\n",
    "    mask = Mask(mask_dir+'Dectris/Pilatus800k_gaps-mask.png')\n",
    "    #mask.load(mask_dir+'NSLSII_11BM_CMS/Pilatus800k_CMS_badpixels-mask.png ')\n",
    "\n",
    "else: #SAXS   \n",
    "    calibration = Calibration(wavelength_A=0.9184) # 13.5 keV\n",
    "    calibration.set_image_size(1475, height=1679) # Pilatus2M\n",
    "    calibration.set_pixel_size(pixel_size_um=172.0)\n",
    "\n",
    "    calibration.set_beam_position(757, 1679-600) # SAXSx -65, SAXSy -73    \n",
    "    calibration.set_distance(5.02)    \n",
    "\n",
    "    mask_dir = SciAnalysis_PATH + '/SciAnalysis/XSAnalysis/masks/'\n",
    "    if 1: #flag_stitch\n",
    "        mask = Mask(mask_dir+'Dectris/Pilatus2M_vertical_gaps-mask.png')\n",
    "    else:\n",
    "        mask = Mask(mask_dir+'Dectris/Pilatus2M_gaps-mask.png')\n",
    "    #mask.load(EXPR_DIR+'saxs/analysis/mask_saxs.png')    \n",
    "    \n",
    "    \n",
    "    \n",
    "load_args = { 'calibration' : calibration, \n",
    "             'mask' : mask,\n",
    "             }\n",
    "run_args = { 'verbosity' : 3,\n",
    "             'AgBH': True, \n",
    "             'CeO2': False\n",
    "           }\n",
    "process = Protocols.ProcessorXS(load_args=load_args, run_args=run_args)\n",
    "\n",
    "### Analysis \n",
    "protocols = ['circular_average'] \n",
    "det = exp.dict['expinfo']['det']\n",
    "folder = exp.dict['expinfo']['folder']\n",
    "infile_fullpath = folder+'/'+det+'/raw/'+exp.dict['rawinfo']['filename'][0]+'_'+det+'.tiff'\n",
    "data = process.load(infile_fullpath, calibration=calibration, mask=mask, run_args=run_args)\n",
    "line_plot = data.circular_average_q_bin(error=False)\n",
    "\n",
    "\n",
    "## Plot 2D \n",
    "%matplotlib inline\n",
    "#%matplotlib ipympl\n",
    "\n",
    "if 1:\n",
    "    plt.figure(1, figsize=(8,8)); plt.clf()\n",
    "    plt.imshow(np.log(data.data+3), vmin=2, vmax=5); plt.colorbar() \n",
    "\n",
    "    dq = 0.005\n",
    "    qlist = []\n",
    "    if 'AgBH' in run_args and run_args['AgBH']:\n",
    "        q0 = 0.1076\n",
    "        num_rings = 3\n",
    "        qlist.extend(q0*np.arange(1,num_rings+1))       \n",
    "        \n",
    "    if 'CeO2' in run_args and run_args['CeO2']:\n",
    "        q0 = (2*np.pi/5.411)*np.sqrt(3)          # A^-1, (111)\n",
    "        qlist.extend( ( q0/np.sqrt(3) )*np.array((np.sqrt(3), 2, np.sqrt(8),np.sqrt(11),np.sqrt(12),np.sqrt(16),np.sqrt(19),  np.sqrt(20)))  )\n",
    "    \n",
    "    qlist.sort();     qlist = np.asarray(qlist)\n",
    "    print('\\nCalibration qlist = {}\\n'.format(qlist))    \n",
    "    \n",
    "    for q in qlist:\n",
    "        region = data.calibration.q_map()\n",
    "        region = np.ma.masked_where(abs(region-q)>dq, region)\n",
    "        plt.imshow(region, cmap='plasma')\n",
    "\n",
    "## Plot 1D \n",
    "if 0:\n",
    "    flag_log = 1\n",
    "    plt.figure(2, figsize=(10,5)); plt.clf()\n",
    "    q_peaks = Tools.plot_peaks(line_plot, N_peaks_find = 5, fit_param=[0, 1, 0.001], flag_log=flag_log, line_color='k', label_color='r', roundup=3, verbose=1)  #Tools.rand_color(0.5, 0.8)\n",
    "    \n",
    "    y_range = [np.min(line_plot.y), np.max(line_plot.y)]\n",
    "    qlist[qlist > np.max(line_plot.x)] = None\n",
    "    Tools.label_peaks(qlist, flag_log=flag_log, y_range = y_range, color='g', verbose=0) \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convert between q and angle__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('At {} keV'.format(calibration.get_energy()))\n",
    "print(data.calibration.q_to_angle(1))\n",
    "print(data.calibration.angle_to_q(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Specify directory, detector, and files of interest\n",
    "if 0: #SAXS\n",
    "    EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/beamline/CKe/'\n",
    "    exp = Experiment.experiment('Ag', folder=EXPR_DIR, det='saxs', beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    exp.dict['expinfo']['fn_patterns'] = ['*Ag*1016533*']  \n",
    "\n",
    "if 1: #WAXS, temperature\n",
    "    EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_1/beamline/ETsai2/'  ##SA\n",
    "    exp = Experiment.experiment('PBG_run1', folder=EXPR_DIR, det='waxs', beamline='cms') \n",
    "    exp.dict['expinfo']['fn_patterns'] = ['*_PBG*run1*x0.0*y0.0*10133*']  #*10133\n",
    "\n",
    "if 0: #WAXS mapping\n",
    "    \n",
    "    EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2022_3/RHeadrick3/' \n",
    "    exp = Experiment.experiment('B6_N3', folder=EXPR_DIR, det='waxs', beamline='cms')\n",
    "    exp.dict['expinfo']['fn_patterns'] = ['*B6_N3_Trans3_map_vac_x*']  \n",
    "\n",
    "if 0: #MAXS burstmode (series)\n",
    "    EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_1/LRichter2/MM389_KCl/' \n",
    "    exp = Experiment.experiment('MM389_KCl', folder=EXPR_DIR, det='maxs', series_measure=True, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    exp.dict['expinfo']['fn_patterns'] = ['*MM389*run4*']  \n",
    "      \n",
    "if 0: \n",
    "    EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/beamline/RLi2/' \n",
    "    exp = Experiment.experiment('B5-140-2', folder=EXPR_DIR, det='saxs', series_measure=False, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    exp.dict['expinfo']['fn_patterns'] = ['*B5-140-2*x0.0*']  \n",
    "\n",
    "    exp = Experiment.experiment('B4-170-17', folder=EXPR_DIR, det='saxs', series_measure=False, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    exp.dict['expinfo']['fn_patterns'] = ['*B4-170-17*x0.0*']  \n",
    "\n",
    "    exp = Experiment.experiment('B5-80-5', folder=EXPR_DIR, det='saxs', series_measure=False, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    exp.dict['expinfo']['fn_patterns'] = ['*B5-80-5*x0.0*']  \n",
    "\n",
    "    exp = Experiment.experiment('B5-80-5', folder=EXPR_DIR, det='saxs', series_measure=False, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    exp.dict['expinfo']['fn_patterns'] = ['*B5-80-5*x0.0*']  \n",
    "    # exp = Experiment.experiment('B7', folder=EXPR_DIR, det='saxs', series_measure=False, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    # exp.dict['expinfo']['fn_patterns'] = ['*B7-80-3*x1.0*']  \n",
    "\n",
    "    # exp = Experiment.experiment('B5', folder=EXPR_DIR, det='saxs', series_measure=False, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    # exp.dict['expinfo']['fn_patterns'] = ['*B5-80-4*']  \n",
    "    \n",
    "    # exp = Experiment.experiment('B5', folder=EXPR_DIR, det='saxs', series_measure=False, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    # exp.dict['expinfo']['fn_patterns'] = ['*B5-80-5*']  \n",
    "    # exp = Experiment.experiment('B5', folder=EXPR_DIR, det='saxs', series_measure=False, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    # exp.dict['expinfo']['fn_patterns'] = ['*B5-140-6*']  \n",
    "    \n",
    "if 1: \n",
    "    # EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/test4/' \n",
    "    samplefolder_load = 'test4' # sam16_3mai1pbi2_dmf_1m_5scfh_Si_40uL_010\n",
    "    \n",
    "    EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/'  + samplefolder_load + '/'\n",
    "    exp = Experiment.experiment(samplefolder_load, folder=EXPR_DIR, det='maxs', series_measure=True, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    exp.dict['expinfo']['fn_patterns'] = [f'{samplefolder_load}*']  \n",
    "\n",
    "\n",
    "### Load files\n",
    "try:\n",
    "    for pattern in exp.dict['expinfo']['fn_patterns']:\n",
    "        #exp.defFiles_query(fn='PBG', folder=EXPR_DIR, scanid = [900000, 1200000], verbose=1) \n",
    "        exp.defFiles(fn=pattern, verbose=1) \n",
    "        # exp.defFiles(fn=pattern, scanid = [750000, 900000], verbose=1)  \n",
    "        # infiles = exp.defFiles_ScanID_ONLY(fn=pattern, scanid = [1116002], verbose=1)  \n",
    "        # infiles = exp.defFiles_ScanID_ONLY(fn=pattern, scanid = [1116215], verbose=1)  \n",
    "    \n",
    "    # infiles = exp.dict['rawinfo']['filename']\n",
    "    Nfiles = len(infiles)\n",
    "    \n",
    "except:\n",
    "    print('\\n!!! Databroker not working, loading files directly.')\n",
    "    #exp.dict['expinfo']['beamline'] = None\n",
    "    for pattern in exp.dict['expinfo']['fn_patterns']:\n",
    "        exp.defFiles_ScanID_ONLY(fn=pattern, scanid = [1116215], verbose=1)  \n",
    "    \n",
    "\n",
    "### Show some info   \n",
    "exp.show()\n",
    "exp.showFileInfo(idx=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## See metadata for one file\n",
    "import databroker\n",
    "cat = databroker.catalog['cms']\n",
    "scan_id = exp.dict['rawinfo']['scan_id'][0]  #959455\n",
    "h = cat[scan_id]\n",
    "h.metadata['start']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Check metadata at the beamline, identify md of interest, e.g. sample_temperature_D, sample_x\n",
    "file_idx = 0\n",
    "scan_id = exp.dict['rawinfo']['scan_id'][file_idx]\n",
    "#exp.showMetadata(scanid=scan_id, md_interest=None)\n",
    "exp.showMetadata(scanid=scan_id, md_interest = ['sample_clock', 'scan_id'])\n",
    "#exp.showMetadata(scanid=scan_id, md_interest = ['sample_clock', 'sample_x', 'sample_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Options: (1) load metadata from databroker at beamline. (2) load md from h5. (3) Extract info from filename\n",
    "md_load_option = 1\n",
    "\n",
    "## Clear all metadata\n",
    "exp.dict['metadata'] = {}\n",
    "\n",
    "\n",
    "## Load metadata\n",
    "if md_load_option==1: # Load md from databroker, this only works at beamline\n",
    "    exp.dict['mdata_list'] = ['scan_id'] # Specify metedata to load\n",
    "    exp.loadMetadata()\n",
    "    print(exp.dict['metadata'].keys())\n",
    "    \n",
    "elif md_load_option==2: # Load md from h5 (previously saved from databroker)\n",
    "    h5_path = EXPR_DIR+\"/data/\"\n",
    "    h5_file = 'B6_N3_metadata.h5'\n",
    "    exp.dict['metadata'] = h5todict(h5_path+h5_file)\n",
    "\n",
    "\n",
    "elif md_load_option==3: ## If databroker md is not available nor saved\n",
    "    infiles = exp.dict['rawinfo']['filename']\n",
    "    print('Number of files: {}'.format(len(infiles)))\n",
    "\n",
    "    Ts = []\n",
    "    sample_x = []\n",
    "    sample_y = []\n",
    "    scan_id = []\n",
    "    frames = []\n",
    "    for ii, infile in enumerate(infiles):\n",
    "        temp = infile.split('_')\n",
    "        if ii==0: print(temp)\n",
    "        \n",
    "        Ts.append(float(infile.split('Linkam')[1].split('C')[0]))\n",
    "        #sample_x.append(float(temp[-4][1:]))\n",
    "        #sample_y.append(float(temp[-3][1:]))\n",
    "        \n",
    "        #Ts.append(float(infile.split('RH')[1].split('_x')[0]))\n",
    "        #scan_id.append(int(temp[-1]))\n",
    "        #frames.append(int(temp[-1]))\n",
    "\n",
    "    exp.dict['metadata']['sample_temperature_D'] = Ts\n",
    "    #exp.dict['metadata']['sample_x'] = np.array(sample_x)\n",
    "    #exp.dict['metadata']['sample_y'] = np.array(sample_y)\n",
    "    #exp.dict['metadata']['frames'] = frames\n",
    "    \n",
    "    print(exp.dict['metadata'].keys())\n",
    "\n",
    "else:\n",
    "    print('No metadata loaded to the exp. dictionary!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Save metadata (for offline analysis later on)\n",
    "if 0:\n",
    "    h5_path = EXPR_DIR+\"/data/\"\n",
    "    h5_file = exp.name+'_metadata.h5'\n",
    "    dicttoh5(exp.dict['metadata'], h5_path+h5_file)\n",
    "    print(h5_path+h5_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Analysis\n",
    "\n",
    "We suspect that loading analysis results is slow, faster if processing raw data. However, going through the protocals is also slow; storing it to the exp.dict also takes a bit time.\n",
    "\n",
    "E.g. 3600 files, 1 protocol, saving to exp.dict: 5min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(infiles[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Specify beamline config (e.g. beam energy, center, det-sample distance)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 1: #WAXS, MAXS\n",
    "    #calibration = Calibration(wavelength_A=0.7293) # 17 keV\n",
    "    calibration = Calibration(wavelength_A=12.4/12.7) #13.5 keV\n",
    "    calibration.set_image_size(981, height=1043) # Pilatus1M\n",
    "    calibration.set_pixel_size(pixel_size_um=172.0)\n",
    "    \n",
    "    calibration.set_beam_position(576, 1043-390) # Pilatus 800k x=450 y=398 works in xi-cam, in scianalysis need y=1043-398=645\n",
    "    calibration.set_distance(0.3)\n",
    "\n",
    "    ## LRichter\n",
    "    if 0:\n",
    "        calibration.set_beam_position(543, 606) #LRichter\n",
    "        calibration.set_distance(0.2815)\n",
    "    \n",
    "    mask_dir = SciAnalysis_PATH + '/SciAnalysis/XSAnalysis/masks/'\n",
    "    mask = Mask(mask_dir+'Dectris/Pilatus800k2_gaps-mask.png')\n",
    "    mask.load('./Pilatus800k2_custom-mask.png')\n",
    "\n",
    "  \n",
    "    \n",
    "load_args = { 'calibration' : calibration, \n",
    "             'mask' : mask,\n",
    "             #'rot180' : False,\n",
    "             #'flip' : True, # PSCCD\n",
    "             }\n",
    "run_args = { 'verbosity' : 3,\n",
    "            #'save_results' : ['xml', 'plots', 'txt', 'hdf5'],\n",
    "            }\n",
    "process = Protocols.ProcessorXS(load_args=load_args, run_args=run_args)\n",
    "\n",
    "\n",
    "### Run analysis \n",
    "protocols = ['circular_average'] #['linecut_angle'] #['circular_average'] #, 'sector_average', 'linecut_qz']\n",
    "\n",
    "exp.dict['analysis']['cali'] = [calibration.wavelength_A, calibration.x0, calibration.y0, calibration.distance_m]\n",
    "#exp.dict['analysis'] = {} \n",
    "#for protocol in protocols:\n",
    "#    exp.dict['analysis'][protocol] = {}\n",
    "\n",
    "t0 = time.time()  \n",
    "    \n",
    "line_y_stack = []\n",
    "for protocol in protocols:\n",
    "    if 'circular_average' in protocol:\n",
    "        for ii, infile in enumerate(infiles):\n",
    "            if np.mod(ii+1, 50)==0: print('[{:.0f}%]'.format(ii/Nfiles*100))\n",
    "\n",
    "            det = exp.dict['expinfo']['det']\n",
    "            folder = exp.dict['expinfo']['folder']\n",
    "\n",
    "            # infile_fullpath = folder+'/'+det+'/raw/'+exp.dict['rawinfo']['filename'][ii]+'_'+det+'.tiff'\n",
    "            infile_fullpath = infile\n",
    "            # print(infile_fullpath)\n",
    "            data = process.load(infile_fullpath, calibration=calibration, mask=mask, run_args=run_args)\n",
    "\n",
    "            ### Run the protocol\n",
    "            line_output = data.circular_average_q_bin(error=False)\n",
    "            line_y_stack.append(line_output.y)\n",
    "\n",
    "            if 0:\n",
    "                exp.dict['analysis'][protocol][str(ii)] = {}\n",
    "                exp.dict['analysis'][protocol][str(ii)]['q'] = line_output.x\n",
    "                exp.dict['analysis'][protocol][str(ii)]['I(q)'] = line_output.y\n",
    "        \n",
    "        ### Save analysis to exp.dict\n",
    "        if 1:\n",
    "            exp.dict['analysis'][protocol] = {}\n",
    "            exp.dict['analysis'][protocol]['q'] = line_output.x\n",
    "            exp.dict['analysis'][protocol]['I_stack'] = line_y_stack   \n",
    "            #x = Protocols.thumbnails(name=None) \n",
    "            #x.run(data, output_dir)\n",
    "            \n",
    "    if 'linecut_qr' in protocol:\n",
    "        for ii, infile in enumerate(infiles):\n",
    "            if np.mod(ii+1, 50)==0: print('[{:.0f}%]'.format(ii/Nfiles*100))\n",
    "\n",
    "            det = exp.dict['expinfo']['det']\n",
    "            folder = exp.dict['expinfo']['folder']\n",
    "\n",
    "            infile_fullpath = folder+'/'+det+'/raw/'+exp.dict['rawinfo']['filename'][ii]+'_'+det+'.tiff'\n",
    "            data = process.load(infile_fullpath, calibration=calibration, mask=mask, run_args=run_args)\n",
    "\n",
    "            ### Run the protocol\n",
    "            line_output = data.linecut_qr(qz=0.03, dq=0.003)\n",
    "            line_y_stack.append(line_output.y)\n",
    "\n",
    "        ### Save analysis to exp.dict\n",
    "        if 1:\n",
    "            exp.dict['analysis'][protocol] = {}\n",
    "            exp.dict['analysis'][protocol]['q'] = line_output.x\n",
    "            exp.dict['analysis'][protocol]['I_stack'] = line_y_stack           \n",
    "        \n",
    "    #elif 'sector_average' in protocol: \n",
    "    #    line_output = data.sector_average_q_bin(angle=60, dangle=5)\n",
    "\n",
    "    #elif 'linecut_qz' in protocol:\n",
    "    #    line_output = data.linecut_qz(qr=0, dq=0.05)\n",
    "\n",
    "    #elif 'linecut_angle' in protocol:\n",
    "    #line_output = data.linecut_angle(q0=2.24, dq=0.01)\n",
    "            \n",
    "        \n",
    "print('Done! (Analysis took {:.0f}s)\\n'.format(time.time()-t0))\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"{}\\n\".format(dt_string))\n",
    "\n",
    "print(exp.dict['analysis'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(exp.dict['analysis'][protocol]['I_stack'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(line_output.x, line_output.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Instead of doing analysis, can load previously analyzed data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    exp.loadSciAnalysisData(keys=['circular_average'], analysis_folder=str(exp.dict['folder'])+'waxs/analysis/PBG_run1/', verbose=1)\n",
    "    exp.dict['analysis'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save \n",
    "\n",
    "Save experiment dictionary (exp.dict) to h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# h5_path = EXPR_DIR+\"/data/\"\n",
    "\n",
    "h5_path = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/'+\"/data/\"\n",
    "\n",
    "\n",
    "h5_file = str(exp.dict['expinfo']['expname']) + '_cms_exp.h5'\n",
    "output_file = h5_path+h5_file\n",
    "\n",
    "\n",
    "## Check if file exist, will not overwrite\n",
    "if False:\n",
    "    file_exist = os.path.isfile(output_file)\n",
    "    count = 1\n",
    "    while file_exist:\n",
    "        print('{} exists, using a new filename'.format(output_file))\n",
    "        h5_file = str(exp.dict['expname']) + '_exp_' + str(count) + '.h5'\n",
    "        output_file = h5_path+h5_file\n",
    "        file_exist = os.path.isfile(output_file)\n",
    "        count = count + 1\n",
    "\n",
    "        \n",
    "## Save\n",
    "dicttoh5(exp.dict, output_file)\n",
    "print('Experiment saved as {}'.format(output_file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPR_DIR"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## bash analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#bash analysis \n",
    "\n",
    "\n",
    "samplenames = [ 'B4-170-17', 'B5-80-5', 'B5-80-cut-29', 'B4-80-30', 'B5-140-11','B5-140-2','B7-170-7','B7-170-9','B7-170-16','B7-170-10', 'B7-80-28', 'B7-80-3', 'B7-80-8', \n",
    "               'B5-140-6', 'B5-170-10', 'B5-30-14','B5-30-15', 'B5-50-cut-27', 'B5-80-1', 'B5-80-12', 'B5-80-13', 'B5-80-4', 'B5-80-5', 'S1-140-18', 'S1-170-26', 'S2-140-19', \n",
    "               'S2-170-20', 'S2-170-23', 'S2-170-24', 'S2-170-25', 'S4-140-22', 'S4-170-21', 'S5-170-24']\n",
    "\n",
    "for samplename in samplenames:\n",
    "    exp = Experiment.experiment(samplename, folder=EXPR_DIR, det='saxs', series_measure=False, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    exp.dict['expinfo']['fn_patterns'] = ['*{}*x0.0*'.format(samplename)]  \n",
    "\n",
    "    ### Load files\n",
    "    try:\n",
    "        for pattern in exp.dict['expinfo']['fn_patterns']:\n",
    "            #exp.defFiles_query(fn='PBG', folder=EXPR_DIR, scanid = [900000, 1200000], verbose=1) \n",
    "            exp.defFiles(fn=pattern, verbose=1) \n",
    "            #exp.defFiles(fn=pattern, scanid = [750000, 900000], verbose=1)  \n",
    "\n",
    "        infiles = exp.dict['rawinfo']['filename']\n",
    "        Nfiles = len(infiles)\n",
    "\n",
    "    except:\n",
    "        print('\\n!!! Databroker not working, loading files directly.')\n",
    "        #exp.dict['expinfo']['beamline'] = None\n",
    "        for pattern in exp.dict['expinfo']['fn_patterns']:\n",
    "            exp.defFiles(fn=pattern, verbose=1)      \n",
    "\n",
    "\n",
    "    ### Show some info   \n",
    "    exp.show()\n",
    "    exp.showFileInfo(idx=0)\n",
    "\n",
    "\n",
    "    ## Options: (1) load metadata from databroker at beamline. (2) load md from h5. (3) Extract info from filename\n",
    "    md_load_option = 1\n",
    "\n",
    "    ## Clear all metadata\n",
    "    exp.dict['metadata'] = {}\n",
    "\n",
    "\n",
    "    ## Load metadata\n",
    "    if md_load_option==1: # Load md from databroker, this only works at beamline\n",
    "        exp.dict['mdata_list'] = ['sample_clock', 'scan_id'] # Specify metedata to load\n",
    "        exp.loadMetadata()\n",
    "        print(exp.dict['metadata'].keys())\n",
    "\n",
    "    elif md_load_option==2: # Load md from h5 (previously saved from databroker)\n",
    "        h5_path = EXPR_DIR+\"/data/\"\n",
    "        h5_file = 'B6_N3_metadata.h5'\n",
    "        exp.dict['metadata'] = h5todict(h5_path+h5_file)\n",
    "\n",
    "\n",
    "    elif md_load_option==3: ## If databroker md is not available nor saved\n",
    "        infiles = exp.dict['rawinfo']['filename']\n",
    "        print('Number of files: {}'.format(len(infiles)))\n",
    "\n",
    "        Ts = []\n",
    "        sample_x = []\n",
    "        sample_y = []\n",
    "        scan_id = []\n",
    "        frames = []\n",
    "        for ii, infile in enumerate(infiles):\n",
    "            temp = infile.split('_')\n",
    "            if ii==0: print(temp)\n",
    "\n",
    "            Ts.append(float(infile.split('Linkam')[1].split('C')[0]))\n",
    "            #sample_x.append(float(temp[-4][1:]))\n",
    "            #sample_y.append(float(temp[-3][1:]))\n",
    "\n",
    "            #Ts.append(float(infile.split('RH')[1].split('_x')[0]))\n",
    "            #scan_id.append(int(temp[-1]))\n",
    "            #frames.append(int(temp[-1]))\n",
    "\n",
    "        exp.dict['metadata']['sample_temperature_D'] = Ts\n",
    "        #exp.dict['metadata']['sample_x'] = np.array(sample_x)\n",
    "        #exp.dict['metadata']['sample_y'] = np.array(sample_y)\n",
    "        #exp.dict['metadata']['frames'] = frames\n",
    "\n",
    "        print(exp.dict['metadata'].keys())\n",
    "\n",
    "    else:\n",
    "        print('No metadata loaded to the exp. dictionary!')\n",
    "\n",
    "    t0 = time.time()  \n",
    "\n",
    "    line_y_stack = []\n",
    "    for protocol in protocols:\n",
    "        if 'circular_average' in protocol:\n",
    "            for ii, infile in enumerate(infiles):\n",
    "                if np.mod(ii+1, 50)==0: print('[{:.0f}%]'.format(ii/Nfiles*100))\n",
    "\n",
    "                det = exp.dict['expinfo']['det']\n",
    "                folder = exp.dict['expinfo']['folder']\n",
    "\n",
    "                infile_fullpath = folder+'/'+det+'/raw/'+exp.dict['rawinfo']['filename'][ii]+'_'+det+'.tiff'\n",
    "                data = process.load(infile_fullpath, calibration=calibration, mask=mask, run_args=run_args)\n",
    "\n",
    "                ### Run the protocol\n",
    "                line_output = data.circular_average_q_bin(error=False)\n",
    "                line_y_stack.append(line_output.y)\n",
    "\n",
    "                if 0:\n",
    "                    exp.dict['analysis'][protocol][str(ii)] = {}\n",
    "                    exp.dict['analysis'][protocol][str(ii)]['q'] = line_output.x\n",
    "                    exp.dict['analysis'][protocol][str(ii)]['I(q)'] = line_output.y\n",
    "\n",
    "            ### Save analysis to exp.dict\n",
    "            if 1:\n",
    "                exp.dict['analysis'][protocol] = {}\n",
    "                exp.dict['analysis'][protocol]['q'] = line_output.x\n",
    "                exp.dict['analysis'][protocol]['I_stack'] = line_y_stack   \n",
    "                #x = Protocols.thumbnails(name=None) \n",
    "                #x.run(data, output_dir)\n",
    "\n",
    "        if 'linecut_qr' in protocol:\n",
    "            for ii, infile in enumerate(infiles):\n",
    "                if np.mod(ii+1, 50)==0: print('[{:.0f}%]'.format(ii/Nfiles*100))\n",
    "\n",
    "                det = exp.dict['expinfo']['det']\n",
    "                folder = exp.dict['expinfo']['folder']\n",
    "\n",
    "                infile_fullpath = folder+'/'+det+'/raw/'+exp.dict['rawinfo']['filename'][ii]+'_'+det+'.tiff'\n",
    "                data = process.load(infile_fullpath, calibration=calibration, mask=mask, run_args=run_args)\n",
    "\n",
    "                ### Run the protocol\n",
    "                line_output = data.linecut_qr(qz=0.03, dq=0.003)\n",
    "                line_y_stack.append(line_output.y)\n",
    "\n",
    "            ### Save analysis to exp.dict\n",
    "            if 1:\n",
    "                exp.dict['analysis'][protocol] = {}\n",
    "                exp.dict['analysis'][protocol]['q'] = line_output.x\n",
    "                exp.dict['analysis'][protocol]['I_stack'] = line_y_stack           \n",
    "\n",
    "        #elif 'sector_average' in protocol: \n",
    "        #    line_output = data.sector_average_q_bin(angle=60, dangle=5)\n",
    "\n",
    "        #elif 'linecut_qz' in protocol:\n",
    "        #    line_output = data.linecut_qz(qr=0, dq=0.05)\n",
    "\n",
    "        #elif 'linecut_angle' in protocol:\n",
    "        #line_output = data.linecut_angle(q0=2.24, dq=0.01)\n",
    "\n",
    "\n",
    "    print('Done! (Analysis took {:.0f}s)\\n'.format(time.time()-t0))\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "    dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "    print(\"{}\\n\".format(dt_string))\n",
    "\n",
    "    print(exp.dict['analysis'].keys())    \n",
    "\n",
    "\n",
    "\n",
    "    #########save########################\n",
    "    h5_path = EXPR_DIR+\"/data/\"\n",
    "    h5_file = str(exp.dict['expinfo']['expname']) + '_cms_exp.h5'\n",
    "    output_file = h5_path+h5_file\n",
    "\n",
    "\n",
    "    ## Check if file exist, will not overwrite\n",
    "    if False:\n",
    "        file_exist = os.path.isfile(output_file)\n",
    "        count = 1\n",
    "        while file_exist:\n",
    "            print('{} exists, using a new filename'.format(output_file))\n",
    "            h5_file = str(exp.dict['expname']) + '_exp_' + str(count) + '.h5'\n",
    "            output_file = h5_path+h5_file\n",
    "            file_exist = os.path.isfile(output_file)\n",
    "            count = count + 1\n",
    "\n",
    "\n",
    "    ## Save\n",
    "    dicttoh5(exp.dict, output_file)\n",
    "    print('Experiment saved as {}'.format(output_file))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Load H5__\n",
    "\n",
    "Load experiment dictionary and recover the object 'exp', allowing for subsequent data visualization/analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%matplotlib nbagg\n",
    "# Imports\n",
    "########################################\n",
    "import sys, os, time, glob, imageio, datetime, pprint\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from silx.io.dictdump import dicttoh5, h5todict\n",
    "SciAnalysis_PATH='/nsls2/data/cms/legacy/xf11bm/software/SciAnalysis/' ### Specify this\n",
    "SciAnalysis_PATH in sys.path or sys.path.append(SciAnalysis_PATH)\n",
    "from SciAnalysis import tools\n",
    "from SciAnalysis.XSAnalysis.Data import *\n",
    "from SciAnalysis.XSAnalysis import Protocols\n",
    "from SciAnalysis.ExpAnalysis import Experiment\n",
    "from SciAnalysis.ExpAnalysis import Tools\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Load experiment dict (previuosly analyzed data)\n",
    "if True:\n",
    "    \n",
    "    #exp_dict_h5 = '/nsls2/data/cms/legacy/xf11bm/data/2022_3/RHeadrick3//data/B6_N3_cms_exp.h5'\n",
    "    #exp_dict_h5 = '/nsls2/data/cms/legacy/xf11bm/data/2023_1/beamline/ETsai2//data/PBG_run1_cms_exp.h5'\n",
    "    # exp_dict_h5 = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/data/sam1_pbi2_dmf_cms_exp.h5'\n",
    "    exp_dict_h5 = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/data/sam16_3mai1pbi2_dmf_1m_5scfh_Si_40uL_010_cms_exp.h5'\n",
    "    exp_dict_load = h5todict(exp_dict_h5)\n",
    "    #print(exp_dict_load.keys())\n",
    "    \n",
    "    exp = Experiment.experiment(exp_dict_load['expinfo']['expname'], folder=exp_dict_load['expinfo']['folder'], det=exp_dict_load['expinfo']['det'], beamline=exp_dict_load['expinfo']['beamline']) \n",
    "    exp.dict = exp_dict_load\n",
    "    \n",
    "    print(exp.dict.keys())\n",
    "    print('\\nExperiment loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __Overview of exp__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.show(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __(5.1) Data Trend__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#9642; __Plot curves__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - __Load one curve & find peaks__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Show one curve and find peaks\n",
    "\n",
    "#protocol = 'circular_average'\n",
    "protocol = list(exp.dict['analysis'].keys())[-1]\n",
    "print(protocol)\n",
    "print(exp.dict['rawinfo']['filename'][-1])\n",
    "\n",
    "## Pick a curve\n",
    "file_idx = 250\n",
    "line_plot = DataLine(x = exp.dict['analysis'][protocol]['q'], y = exp.dict['analysis'][protocol]['I_stack'][file_idx])  \n",
    "flag_log = 1\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib ipympl\n",
    "plt.figure(1, figsize=(12,5)); plt.clf()\n",
    "q_peaks = Tools.plot_peaks(line_plot, N_peaks_find = 5, fit_param=[0, 1, 0.001], flag_log=flag_log, line_color='k', label_color='r', verbose=1)  #Tools.rand_color(0.5, 0.8)\n",
    "\n",
    "q_label = [0.1076]\n",
    "for q in q_label:\n",
    "    if flag_log:\n",
    "        y_range = [0, max(np.log(line_plot.y))]\n",
    "    else:\n",
    "        y_range = [min(line_plot.y), max(np.log(line_plot.y))]\n",
    "    plt.plot([q, q], y_range, 'g',  alpha=0.7)\n",
    "    plt.text(q, y_range[1]/2, str(q), color='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - __Plot all curves as 2D image__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "I_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.dict['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_label = q_peaks #[1.278, 1.88, 2.219, 2.564, 2.905]; # Label the lines\n",
    "flag_log = True\n",
    "\n",
    "#protocol = 'circular_average'\n",
    "protocol = list(exp.dict['analysis'].keys())[-1]\n",
    "\n",
    "\n",
    "x_axis = exp.dict['analysis'][protocol]['q'] \n",
    "I_stack = exp.dict['analysis'][protocol]['I_stack']\n",
    "# y_axis = exp.dict['metadata']['scan_id'] - exp.dict['metadata']['scan_id'][0]\n",
    "# y_axis = exp.dict['metadata']['sample_clock'] #- exp.dict['metadata']['sample_clock'][0]\n",
    "\n",
    "y_axis = np.arange(len(infiles))\n",
    "if flag_log:\n",
    "    I_stack = np.log10(I_stack)\n",
    "    \n",
    "%matplotlib inline\n",
    "plt.figure(2, figsize=(12,8)); plt.clf()\n",
    "# plt.imshow(I_stack, origin='lower', cmap='jet', extent = [np.min(x_axis), np.max(x_axis), scan_id[0], scan_id[-1]],  aspect='auto') #aspect='auto' 0.005\n",
    "# # plt.imshow(I_stack, origin='lower', cmap='jet', extent = [np.min(x_axis), np.max(x_axis), 0, I_stack.shape[0]],  aspect='auto') #aspect='auto' 0.005\n",
    "# cbar = plt.colorbar(fraction=0.02, pad=0.02, aspect=40) \n",
    "\n",
    "# y_axis = np.arange(0, I_stack.shape[0])\n",
    "X, Y = np.meshgrid(x_axis, y_axis)\n",
    "#dont know how to change the plotting range in pcolormesh\n",
    "# plt.pcolormesh(X,Y,I_stack,vmin=.3,vmax=2.8, cmap=mpl.cm.jet); plt.colorbar()\n",
    "plt.pcolormesh(X,Y,I_stack, cmap=mpl.cm.jet); plt.colorbar()\n",
    "plt.xlabel('q(A-1)')\n",
    "plt.ylabel('index')\n",
    "# plt.ylabel('Time (s)')\n",
    "# plt.xlim(-.2, .2)\n",
    "# plt.ylim(0, 2)\n",
    "\n",
    "print('q_label = {}'.format(q_label))\n",
    "#for q in q_label:\n",
    "#    plt.plot([q, q], [0, I_stack.shape[0]], 'k',  alpha=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_label = q_peaks #[1.278, 1.88, 2.219, 2.564, 2.905]; # Label the lines\n",
    "flag_log = True\n",
    "\n",
    "#protocol = 'circular_average'\n",
    "protocol = list(exp.dict['analysis'].keys())[-1]\n",
    "\n",
    "\n",
    "x_axis = exp.dict['analysis'][protocol]['q'] \n",
    "I_stack = exp.dict['analysis'][protocol]['I_stack']\n",
    "# y_axis = exp.dict['metadata']['scan_id'] - exp.dict['metadata']['scan_id'][0]\n",
    "# y_axis = exp.dict['metadata']['sample_clock'] #- exp.dict['metadata']['sample_clock'][0]\n",
    "\n",
    "y_axis = np.arange(len(infiles))\n",
    "if flag_log:\n",
    "    I_stack = np.log10(I_stack)\n",
    "    \n",
    "%matplotlib inline\n",
    "plt.figure(2, figsize=(12,8)); plt.clf()\n",
    "# plt.imshow(I_stack, origin='lower', cmap='jet', extent = [np.min(x_axis), np.max(x_axis), scan_id[0], scan_id[-1]],  aspect='auto') #aspect='auto' 0.005\n",
    "# # plt.imshow(I_stack, origin='lower', cmap='jet', extent = [np.min(x_axis), np.max(x_axis), 0, I_stack.shape[0]],  aspect='auto') #aspect='auto' 0.005\n",
    "# cbar = plt.colorbar(fraction=0.02, pad=0.02, aspect=40) \n",
    "\n",
    "# y_axis = np.arange(0, I_stack.shape[0])\n",
    "X, Y = np.meshgrid( y_axis, x_axis)\n",
    "#dont know how to change the plotting range in pcolormesh\n",
    "# plt.pcolormesh(X,Y,I_stack,vmin=.3,vmax=2.8, cmap=mpl.cm.jet); plt.colorbar()\n",
    "plt.pcolormesh(X,Y,I_stack.T, cmap=mpl.cm.jet, vmin=0.2,vmax=1.8); plt.colorbar()\n",
    "plt.ylabel(r'$q$ $({\\rm \\AA}^{-1})$', size=20)\n",
    "plt.xlabel('index', size=20)\n",
    "# plt.ylabel('Time (s)')\n",
    "# plt.xlim(-.2, .2)\n",
    "plt.ylim(0.3, 3)\n",
    "\n",
    "print('q_label = {}'.format(q_label))\n",
    "#for q in q_label:\n",
    "#    plt.plot([q, q], [0, I_stack.shape[0]], 'k',  alpha=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### - __Plot curves__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(1, figsize=(12,10)); plt.clf()\n",
    "Nfiles = len(exp.dict['rawinfo']['filename'])\n",
    "infile = exp.dict['rawinfo']['filename'][0]\n",
    "\n",
    "qrange_plot = [0.1,1] ###\n",
    "q_label = q_peaks #[1.278, 1.88, 2.219, 2.564, 2.905]; # Label the lines\n",
    "\n",
    "cmap = mpl.colormaps['jet'] #viridis, jet, hsv, brg\n",
    "colors = cmap(np.linspace(0.0, 1.0, Nfiles))\n",
    "flag_log = 1\n",
    "\n",
    "#sample_temperature_D = exp.dict['metadata']['sample_temperature_D']\n",
    "sample_x = exp.dict['metadata']['sample_x']\n",
    "\n",
    "\n",
    "### Plot\n",
    "x_axis = exp.dict['analysis'][protocol]['q'] \n",
    "idx_min = int(np.argmin(np.abs(x_axis-qrange_plot[0])))\n",
    "idx_max = int(np.argmin(np.abs(x_axis-qrange_plot[1])))\n",
    "\n",
    "I_stack = exp.dict['analysis'][protocol]['I_stack']\n",
    "spacing_plot = 0.7 #arbitrary\n",
    "\n",
    "if flag_log:\n",
    "    I_stack = np.log(I_stack)\n",
    "    \n",
    "    \n",
    "for ii in np.arange(Nfiles):\n",
    "    if 1: #sample_temperature_D[ii]>349.8:\n",
    "        color = 'r'\n",
    "        linestyle = None #'dashed' #dotted, dashed\n",
    "    else:\n",
    "        color = colors[ii]*0.8\n",
    "        linestyle = None\n",
    "        \n",
    "    plt.plot(x_axis[idx_min:idx_max],I_stack[ii][idx_min:idx_max]+ii*spacing_plot, linestyle=linestyle, color=color, label=sample_temperature_D[ii])\n",
    "    #plt.grid('minor')\n",
    "\n",
    "for q in q_label:\n",
    "    plt.plot([q, q], [min(I_stack[0])*0.8, max(I_stack[0])*1.2+Nfiles*spacing_plot], 'k',  alpha=0.2)\n",
    "\n",
    "    \n",
    "#plt.legend(fontsize=7, ncols=7, bbox_to_anchor=(1.01, 1.01)) \n",
    "plt.title('{}, N={}'.format(infile.split('raw')[-1], Nfiles))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#9642; __Extract 0D feature & Plot 1D__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - __Load one curve for peak fitting__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Show one curve & do fitting\n",
    "protocol = 'circular_average'\n",
    "\n",
    "file_idx = 0\n",
    "line_plot = DataLine(x = exp.dict['analysis'][protocol]['q'], y = exp.dict['analysis'][protocol]['I_stack'][file_idx])  \n",
    "\n",
    "q0 = [2.15] #[2.64964595, 3.07210364] #[1.82, 1.86]\n",
    "fit_range = [2, 2.3] #[2.5, 3.2] #[1.7, 1.95]\n",
    "\n",
    "flag_log = True\n",
    "if flag_log == 1:\n",
    "    line_plot.y = np.log(line_plot.y)\n",
    "\n",
    "## Fitting\n",
    "run_args = { 'verbosity' : 3,\n",
    "             #'fittype': 'voigt',\n",
    "            }\n",
    "results = {}\n",
    "protocol = Protocols.fit_peaks()\n",
    "lines = protocol._fit(line_plot, results, **run_args, q0=q0, num_curves=len(q0), fit_range=fit_range)\n",
    "\n",
    "plt.figure(10); plt.clf()\n",
    "for nn, line in enumerate(lines.lines):\n",
    "        \n",
    "    if nn==0: \n",
    "        plt.plot(line.x, line.y, 'k', linewidth=1, label=line.name)\n",
    "        plt.title(line.name)\n",
    "    elif nn==1:\n",
    "        plt.plot(line.x, line.y, 'm', linewidth=2, label=line.name)\n",
    "    else:\n",
    "        plt.plot(line.x, line.y, 'r', linewidth=1, label=line.name)\n",
    "        \n",
    "    plt.grid()\n",
    "    \n",
    "pprint.pprint(lines.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### - __Apply fitting for all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "protocol = 'circular_average'\n",
    "q0 = [2.16] #[2.64964595, 3.07210364] #[1.82, 1.86]\n",
    "fit_range = [2, 2.28] #[2.5, 3.2] #[1.7, 1.95]\n",
    "\n",
    "\n",
    "## Fitting\n",
    "run_args = { 'verbosity' : 3,\n",
    "             #'fittype': 'voigt',\n",
    "            }\n",
    "p = Protocols.fit_peaks()\n",
    "    \n",
    "\n",
    "## Fitting all curves\n",
    "peak_x1 = []\n",
    "peak_x2 = []\n",
    "peak_pre1 = []\n",
    "t0 = time.time()\n",
    "for ii in np.arange(Nfiles):\n",
    "    line_plot = DataLine(x = exp.dict['analysis'][protocol]['q'], y = exp.dict['analysis'][protocol]['I_stack'][ii])  \n",
    "    \n",
    "    lines = p._fit(line_plot, results={}, **run_args, q0=q0, num_curves=len(q0), fit_range=fit_range)\n",
    "\n",
    "    peak_x1.append(lines.results['fit_peaks_x_center1']['value'])\n",
    "    #peak_x2.append(lines.results['fit_peaks_x_center2']['value'])\n",
    "    peak_pre1.append(lines.results['fit_peaks_prefactor1']['value'])\n",
    "\n",
    "print('Fitting took {:.0f}s\\n'.format(time.time()-t0))\n",
    "\n",
    "#Ts = exp.dict['metadata']['sample_temperature_D']\n",
    "#scan_ids = exp.dict['rawinfo']['scan_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(peak_x1, '.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.dict['analysis']['circular_average']['fit_peaks_x_center1'] = peak_x1\n",
    "#exp.dict['analysis']['circular_average']['fit_peaks_x_center2'] = peak_x2\n",
    "exp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Convert list or dict to dataframe:\n",
    "df_list = pd.DataFrame(peak_x1, columns=['peak_x1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(Alternatively, other feature extration, e.g. q with max intensity)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the q with max intensity within this range\n",
    "\n",
    "protocol = 'circular_average'\n",
    "y = []\n",
    "for ii in np.arange(Nfiles):\n",
    "    line_plot = DataLine(x = exp.dict['data'][protocol][str(ii)]['q'], y = exp.dict['data'][protocol][str(ii)]['I(q)'])  \n",
    "    line_x = line_plot.x\n",
    "    line_y = line_plot.y\n",
    "    y.append(line_y[idx_min:idx_max])\n",
    "    \n",
    "qrange_plot = [1, 1.5] \n",
    "\n",
    "\n",
    "Ts = exp.dict['metadata']['sample_temperature_D']\n",
    "scan_ids = exp.dict['expinfo']['scan_id']\n",
    "\n",
    "idx_min = int(np.argmin(np.abs(x_axis-qrange_plot[0])))\n",
    "idx_max = int(np.argmin(np.abs(x_axis-qrange_plot[1])))\n",
    "\n",
    "x_axis = line_x\n",
    "q_peakmax_list = []\n",
    "data_show = []\n",
    "for ii in np.arange(len(y)):\n",
    "    line_y = y[ii]\n",
    "    line_y_crop = line_y[idx_min:idx_max]\n",
    "    line_x_crop = x_axis[idx_min:idx_max]\n",
    "    q_peakmax = line_x_crop[np.argmax(line_y_crop)]\n",
    "    q_peakmax_list.append(q_peakmax)\n",
    "    data_show.append([Ts[ii], scan_ids[ii], q_peakmax])\n",
    "\n",
    "df_line_s = pd.DataFrame(q_peakmax_list, columns=['I'])\n",
    "df_show = pd.DataFrame(data_show, columns = ['RH', 'scan_id', 'q_peakmax'])\n",
    "\n",
    "print(q_peakmax_list[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - __Compare three 1D curves__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ts = exp.dict['metadata']['sample_temperature_D']\n",
    "scan_ids = exp.dict['rawinfo']['scan_id']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#fig.subplots_adjust(right=0.75)\n",
    "\n",
    "twin1 = ax.twinx()\n",
    "twin2 = ax.twinx()\n",
    "twin2.spines.right.set_position((\"axes\", 1.2))\n",
    "\n",
    "\n",
    "if 1:\n",
    "    labels = [\"peak_x1\", \"peak_x2\", \"temp\"]\n",
    "    p1, = ax.plot(scan_ids, peak_x1, \"b-\", label=labels[0])\n",
    "    p2, = twin1.plot(scan_ids, peak_x2, \"r-\", label=labels[1])\n",
    "    p3, = twin2.plot(scan_ids, Ts, \"g-\", label=labels[2])\n",
    "else:\n",
    "    p1, = ax.plot(scan_ids, q_peakmax_list, \"b-\", label=\"q\")\n",
    "    p2, = twin1.plot(scan_ids, np.array(Ts), \"r-\", label=\"Temperature\")\n",
    "    #p3, = twin2.plot([0, 1, 2], [50, 30, 15], \"g-\", label=\"Humidity\")\n",
    "    \n",
    "\n",
    "#ax.set_xlim(0, 2)\n",
    "#ax.set_ylim(0, 2)\n",
    "#twin1.set_ylim(0, 4)\n",
    "#twin2.set_ylim(1, 65)\n",
    "\n",
    "ax.set_xlabel(\"scan_id\")\n",
    "ax.set_ylabel(labels[0])\n",
    "twin1.set_ylabel(labels[1])\n",
    "twin2.set_ylabel(labels[2])\n",
    "\n",
    "ax.yaxis.label.set_color(p1.get_color())\n",
    "twin1.yaxis.label.set_color(p2.get_color())\n",
    "twin2.yaxis.label.set_color(p3.get_color())\n",
    "\n",
    "tkw = dict(size=4, width=1.5)\n",
    "ax.tick_params(axis='y', colors=p1.get_color(), **tkw)\n",
    "twin1.tick_params(axis='y', colors=p2.get_color(), **tkw)\n",
    "twin2.tick_params(axis='y', colors=p3.get_color(), **tkw)\n",
    "ax.tick_params(axis='x', **tkw)\n",
    "\n",
    "ax.legend(handles=[p1, p2, p3], ncols=3, bbox_to_anchor=(1, 1.15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### &#9642; __Extract 0d feature & Plot 2D map__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROI\n",
    "if 0:\n",
    "    reduced_data = exp.dict['data']['roi']\n",
    "    print('Len(reduced_data) = {}'.format(len(reduced_data)))\n",
    "    print(reduced_data.keys())\n",
    "\n",
    "    feature_list = []\n",
    "    for ii in np.arange(0,len(reduced_data)):\n",
    "        feature_list.append(reduced_data['stats_average'][ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Angle\n",
    "\n",
    "reduced_data = exp.dict['data']['linecut_angle']\n",
    "print('Len(reduced_data) = {}'.format(len(reduced_data)))\n",
    "\n",
    "x_pos = exp.dict['metadata']['sample_x']\n",
    "y_pos = exp.dict['metadata']['sample_y']\n",
    "\n",
    "\n",
    "feature_list = []\n",
    "for ii in np.arange(0,len(reduced_data)):\n",
    "    angle = reduced_data[str(ii)]['q']\n",
    "    I = reduced_data[str(ii)]['I(q)']\n",
    "    chi = angle[np.argmax(I)]\n",
    "    feature_list.append(chi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### - __Plot scalar 2D mage__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(); plt.clf()\n",
    "\n",
    "#plt.tripcolor(x_pos, y_pos, feature_list)  \n",
    "plt.tricontourf(x_pos, y_pos, feature_list, cmap = 'jet') \n",
    "\n",
    "plt.colorbar()\n",
    "plt.xlabel('x'); plt.ylabel('y')\n",
    "plt.title(exp.dict['expname'])\n",
    "plt.axis('equal')\n",
    "plt.axis('tight')\n",
    "\n",
    "#plt.plot(x_pos, y_pos, 'k.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plot scalar image with interpolation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_interp = ['linear', 0.005] \n",
    "x_pos_fine, y_pos_fine, feature = Tools.interp_map(x_pos, y_pos, feature_list, plot_interp) \n",
    "\n",
    "plt.figure(); \n",
    "extent = (np.nanmin(x_pos_fine), np.nanmax(x_pos_fine), np.nanmin(y_pos_fine), np.nanmax(y_pos_fine))\n",
    "\n",
    "plt.imshow(feature, extent=extent, origin='lower', cmap='jet') #, clim=[-180, 180])  \n",
    "plt.colorbar()\n",
    "plt.xlabel('x [mm]'); plt.ylabel('y [mm]')\n",
    "plt.title(exp.dict['expname'])\n",
    "plt.axis('equal')\n",
    "plt.axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - __Plot quiver__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "u_list = []\n",
    "v_list = []\n",
    "chi_list = []\n",
    "for chi in feature_list:\n",
    "    u = np.cos(np.deg2rad(chi)) \n",
    "    v = np.sin(np.deg2rad(chi)) \n",
    "    u_list.append(u)\n",
    "    v_list.append(v)\n",
    "    chi_list.append(chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[10, 6])\n",
    "\n",
    "q = ax.quiver(x_pos, y_pos, u_list, v_list, chi_list, cmap = 'plasma') #,clim=[0,0.3])\n",
    "\n",
    "#ax.set_xlim([-0.2,5])\n",
    "#ax.set_ylim([-0.2,5])\n",
    "ax.axis('equal')\n",
    "ax.set_xlabel('$x$ (mm)'); ax.set_ylabel('$y$ (mm)')\n",
    "\n",
    "cb = plt.colorbar(q)\n",
    "plt.title(exp.dict['expname'])\n",
    "# plt.savefig('SAXS mapping_quiver polt_colorbar.png', dpi = 600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __(5.2) Experiment__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### &#9642; __Fitting for experiment__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "curve_1 = exp.dict['metadata']['sample_temperature_D']\n",
    "curve_2 = exp.dict['analysis']['circular_average']['fit_peaks_x_center1']\n",
    "\n",
    "\n",
    "plt.plot(curve_1, curve_2, '.-')\n",
    "#plt.plot(curve_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from SciAnalysis import tools\n",
    "from SciAnalysis.XSAnalysis.Data import *\n",
    "#from SciAnalysis.XSAnalysis import Protocols\n",
    "from SciAnalysis.CurveAnalysis.Data import *\n",
    "\n",
    "#line_plot = DataLine(x = exp.dict['analysis'][protocol]['q'], y = exp.dict['analysis'][protocol]['I_stack'][file_idx])  \n",
    "line_plot = DataLineStructuredSort(x = np.asarray(curve_1)*0.1, y = curve_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_result, fit_line, fit_line_extended = line_plot.fit_linear(line_plot, **run_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(fit_line.x, fit_line.y, 'b')\n",
    "#plt.plot(fit_line_extended.x, fit_line_extended.y, 'r:')\n",
    "print(fit_line.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### &#9642; Perform correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Analysis data: {}\\n'.format(exp.dict['data'].keys()))\n",
    "exp.doCorr(corrs = [['2Darray']])\n",
    "\n",
    "print(exp.dict['corrdata']['2Darray']['circular_average'].keys())\n",
    "print(exp.dict['data']['circular_average'][str(0)].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#9642; Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "exp.plotWaterfall(key = 'circular_average', y_spacing=0.1, flag_log=[0, 1])\n",
    "#exp.plotWaterfall(key = 'sector_average', y_spacing=1)\n",
    "#exp.plotWaterfall(key = 'linecut_qz', y_spacing=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.plotHeatmap(key = protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Batch Processing (usually done in background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_args = { 'calibration' : calibration, \n",
    "             'mask' : mask,\n",
    "             #'rot180' : False,\n",
    "             #'flip' : True, # PSCCD\n",
    "             }\n",
    "run_args = { 'verbosity' : 3,\n",
    "            'rcParams': {'axes.labelsize': 25,\n",
    "                            'xtick.labelsize': 18,\n",
    "                            'ytick.labelsize': 18,\n",
    "                            'xtick.major.pad': 5,\n",
    "                            'ytick.major.pad': 5,\n",
    "                            },\n",
    "            }\n",
    "\n",
    "process = Protocols.ProcessorXS(load_args=load_args, run_args=run_args)\n",
    "\n",
    "# Examples:\n",
    "#protocols = [ Protocols.circular_average_q2I(plot_range=[0, 0.2, 0, None]) ]\n",
    "#protocols = [ Protocols.linecut_angle(q0=0.01687, dq=0.00455*1.5, show_region=False) ]\n",
    "#protocols = [ Protocols.q_image(blur=1.0, bins_relative=0.5, plot_range=[-0.1, 3.0, 0, 3.0], _xticks=[0, 1.0, 2.0, 3.0], ztrim=[0.2, 0.01]) ]\n",
    "#protocols = [ Protocols.qr_image(blur=1.0, bins_relative=0.5, plot_range=[-0.1, 3.0, 0, 3.0], _xticks=[0, 1.0, 2.0, 3.0], zmin=1010., ztrim=[None, 0.01]) ]\n",
    "#protocols = [ Protocols.qr_image(blur=None, bins_relative=0.8, plot_range=[-0.1, 3.0, 0, 3.0], _xticks=[0, 1.0, 2.0, 3.0], ztrim=[0.38, 0.002], dezing_fill=True) ]\n",
    "#protocols = [ Protocols.q_phi_image(bins_relative=0.25, plot_range=[0, 3.0, 0, +90]) ]\n",
    "# Protocols.sector_average(angle=-70, dangle=25, show_region=False) \n",
    "# Protocols.qr_image(blur=None, colorbar=True, save_data=False, transparent=False, label_filename=True) \n",
    "# Protocols.linecut_q(chi0= 90+70, dq= .5, gridlines=True, label_filename=True, save_results = [ 'hdf5' ] )\n",
    "# Protocols.HDF5(  save_results = [ 'hdf5' ] )\n",
    "# Protocols.metadata_extract()\n",
    "\n",
    "protocols = [\n",
    "    #Protocols.HDF5(save_results=['hdf5'])\n",
    "    #Protocols.calibration_check(show=False, AgBH=True, q0=1.076, dq=0.005, num_rings=10, ztrim=[0.2, 0.01], dpi=300) ,\n",
    "    \n",
    "    Protocols.circular_average(ylog=True, plot_range=[0, 0.18, None, None], dezing=True, gridlines=True, transparent=False, label_filename=True) ,\n",
    "    #Protocols.thumbnails(crop=None, resize=0.5, cmap=cmap_vge, ztrim=[0.06, 0.001], zmin=1000.0) , # PSCCD\n",
    "    \n",
    "    #Protocols.thumbnails(crop=None, resize=0.5, cmap=cmap_vge, ztrim=[0.02, 0.001]) , # Pilatus800k\n",
    "    #Protocols.thumbnails(name='thumbnails_jet', crop=None, ztrim=[0.06, 0.001]) , # Pilatus800k\n",
    "\n",
    "    Protocols.qr_image(blur=None, colorbar=True, save_data=False, transparent=False, label_filename=True, plot_buffers = [0.1, 0.1, 0.1, 0.1]),    \n",
    "    #Protocols.q_image(blur=None, colorbar=True, save_data=False, transparent=False, label_filename=True, plot_buffers = [0.1, 0.1, 0.1, 0.1], dpi=200) \n",
    "\n",
    "    ]\n",
    "    \n",
    "# To stitch files: \n",
    "# 1) run stitch.py to stitch into .TIFF \n",
    "# 2) run runStitched.py to generate thumbnails etc\n",
    "\n",
    "# Run\n",
    "########################################\n",
    "print('Processing {} infiles...'.format(len(infiles)))\n",
    "process.run(infiles, protocols, output_dir=output_dir, force= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &#9635; Supplementary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## S1. Background subtraction \n",
    " \n",
    " Same as Sections 0 and 3, except we specify background in __load_args__:\n",
    " \n",
    " - 'background' can be (1) a raw TIFF, (2) one float value, or (3) an np.ndarray\n",
    " \n",
    " - 'transmission_int' can be (1) the transmission CSV file under ./data/, or (2) one float value\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental parameters\n",
    "########################################\n",
    "calibration = Calibration(wavelength_A=0.9184) # 13.5 keV\n",
    "#calibration = Calibration(wavelength_A=0.9184) # 13.5 keV\n",
    "calibration.set_image_size(1475, height=1679) # Pilatus2M\n",
    "calibration.set_pixel_size(pixel_size_um=172.0)\n",
    "calibration.set_beam_position(738.0, 1679-593 ) # SAXSx -60, SAXSy -73\n",
    "\n",
    "calibration.set_distance(2.0) # 5m\n",
    "\n",
    "mask_dir = SciAnalysis_PATH + '/SciAnalysis/XSAnalysis/masks/'\n",
    "mask = Mask(mask_dir+'Dectris/Pilatus2M_gaps-mask.png')\n",
    "mask.load(EXPR_DIR+'saxs/analysis/Pilatus2M_current-mask_Kap.png')\n",
    "\n",
    "# Files to analyze\n",
    "########################################\n",
    "#EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2020_2/CKe/saxs/'\n",
    "EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2022_2/Exxon3/'\n",
    "\n",
    "source_dir = EXPR_DIR + 'saxs/raw/'\n",
    "output_dir = EXPR_DIR + 'saxs/analysis_test/'\n",
    "\n",
    "pattern = 'MG*492830*'  \n",
    "\n",
    "infiles = glob.glob(os.path.join(source_dir, pattern+'.tiff'))\n",
    "infiles.sort()\n",
    "\n",
    "\n",
    "# Analysis to perform\n",
    "########################################\n",
    "load_args = { 'calibration' : calibration, \n",
    "             'mask' : mask,\n",
    "             #'background' : '/nsls2/data/cms/legacy/xf11bm/data/2020_2/CKe2/saxs/raw/'+'*0130*tiff',\n",
    "             'background' : EXPR_DIR+'/saxs/raw/MG_empty_BKG_x0.000_y0.000_10.00s_492839_saxs.tiff',\n",
    "             #'background' : 100,\n",
    "             'transmission_int': EXPR_DIR+'/data/Transmission_output.csv', # Can also specify an float value, eg 1.4\n",
    "             }\n",
    "\n",
    "run_args = { 'verbosity' : 3,\n",
    "            'rcParams': {'axes.labelsize': 25, \n",
    "                         'xtick.labelsize': 20, 'ytick.labelsize': 20, \n",
    "                         'xtick.major.pad': 10, 'ytick.major.pad': 10, },\n",
    "            }\n",
    "process = Protocols.ProcessorXS(load_args=load_args, run_args=run_args)\n",
    "\n",
    "protocols = [\n",
    "    Protocols.circular_average(name='circular_average', ylog=True, plot_range=[0, 4.0, 5, None], gridlines=True, label_filename=True)  , #'csv'   \n",
    "    Protocols.q_image(blur=None, colorbar=True, save_results=['npz'], plot_buffers = [0.1, 0.1, 0.1, 0.1], transparent=False, label_filename=True) ,     \n",
    "    ]\n",
    "\n",
    "\n",
    "# Run\n",
    "########################################\n",
    "t0 = time.time()\n",
    "\n",
    "infiles = glob.glob(os.path.join(source_dir, pattern+'.tiff')); \n",
    "infiles.sort()    \n",
    "print('Processing {} infiles...'.format(len(infiles)))\n",
    "process.run(infiles, protocols, output_dir=output_dir, force = 1)\n",
    "print('Process Time: {:.1f} min'.format((time.time()-t0)/60))\n",
    "\n",
    "\n",
    "#---------\n",
    "# process.load(infiles[0], **load_args)\n",
    "# data = process.handle_calibration(infile, **load_args)\n",
    "# process.handle_background(data, **load_args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Show before/after__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "## Load images\n",
    "#filename = 'CKe_S5_24k_4vac_x0.100_y-0.200_20.00s_2790326_saxs'\n",
    "filename = 'MG_19-110924-1_virgin_KapCap2mm_x-0.000_y0.000_10.00s_492830_saxs'\n",
    "\n",
    "infile0 = output_dir+'q_image/' + filename + '.png'\n",
    "infile1 = output_dir+'q_image/' + filename + '_rmbkg.png'\n",
    "img0 = imageio.imread(infile0)\n",
    "img1 = imageio.imread(infile1)\n",
    "\n",
    "\n",
    "## Plot\n",
    "plt.figure()\n",
    "plt.rcParams['figure.figsize'] = [10, 10] #[height, width] of the figure\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img0); plt.title('Original')\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(img1); plt.title('Background removed')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Load 1D\n",
    "infile0 = output_dir+'circular_average/' + filename + '.dat'\n",
    "infile1 = output_dir+'circular_average/' + filename + '_rmbkg.dat'\n",
    "line0 = np.loadtxt(infile0)\n",
    "line1 = np.loadtxt(infile1)\n",
    "\n",
    "## Plot\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(line0[:,0], np.log10(line0[:,2])); plt.grid()\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(line1[:,0], np.log10(line1[:,2])); plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, difflib\n",
    "import pandas as pd\n",
    "\n",
    "infile = EXPR_DIR+'/data/Transmission_output.csv'\n",
    "df = pd.read_csv(infile)\n",
    "#print(df)\n",
    "\n",
    "filelist = df['b_scanID']\n",
    "\n",
    "b = filelist.isin([492809])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __S2. Load results and plot__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#9642; __Load NPZ__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/nsls2/data/cms/legacy/xf11bm/data/2022_3/RHeadrick3/waxs/analysis/'\n",
    "infile = output_dir+'q_image/B6_N3_Trans3_map_vac_x-0.006_y-1.050_2.00s_763448_waxs.npz'\n",
    "print(infile)\n",
    "\n",
    "data = np.load(infile)\n",
    "#print(list(data))\n",
    "\n",
    "image = data['image']\n",
    "x_axis = data['x_axis']\n",
    "y_axis = data['y_axis']\n",
    "x_scale = data['x_scale']\n",
    "y_scale = data['y_scale']\n",
    "\n",
    "\n",
    "##### Can plot in log or not; Adjust cmap for colormap, clim for plot range\n",
    "plt.figure(); \n",
    "plt.pcolormesh(x_axis, y_axis, np.log(image), cmap='viridis') #plot in log intensity\n",
    "\n",
    "plt.colorbar()\n",
    "plt.clim([0, 6])\n",
    "\n",
    "[qx, qz] = [0.48, 2.175]\n",
    "[dqx, dqz] = [0.02, 0.02]\n",
    "plt.plot([qx-dqx, qx+dqx], [qz-dqz, qz-dqz], 'r-')\n",
    "plt.plot([qx-dqx, qx+dqx], [qz+dqz, qz+dqz], 'r-')\n",
    "plt.plot([qx-dqx, qx-dqx], [qz-dqz, qz+dqz], 'r-')\n",
    "plt.plot([qx+dqx, qx+dqx], [qz-dqz, qz+dqz], 'r-')\n",
    "\n",
    "print([qx, qz] /x_scale)\n",
    "plt.title(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#9642; __Extract analysis results from .XML to .TXT and .NPY__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions for extracting results from xml files\n",
    "########################################\n",
    "from SciAnalysis.Result import * # Results() object\n",
    "def extract_results(infiles, extractions, outfile, verbosity=3):\n",
    "    if verbosity>=3: print(\"Extracting results for {} infiles...\".format(len(infiles)))   \n",
    "    results = Results().extract_multi_save_txt(outfile, infiles, extractions, verbosity=verbosity)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def load_file(infile, verbosity=3):\n",
    "    if verbosity>=3:\n",
    "        print(\" Loading data from file: {}\".format(infile))\n",
    "    \n",
    "    with open(infile, 'r') as fin:\n",
    "        names = fin.readline().split()\n",
    "        lines = fin.readlines()\n",
    "\n",
    "    if verbosity>=4:\n",
    "        print('  Saved data has {} columns:'.format(len(names)))\n",
    "        print(names)\n",
    "        \n",
    "    return names, lines\n",
    "\n",
    "\n",
    "# Files to analyze\n",
    "########################################\n",
    "EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2021_2/SSenanayak/waxs/'\n",
    "verbosity = 3\n",
    "\n",
    "source_dir = EXPR_DIR + 'stitched_analysis_test/'\n",
    "output_dir = EXPR_DIR + 'stitched_analysis_test/'\n",
    "\n",
    "pattern = 'NT' \n",
    "\n",
    "## Extract results from XML files\n",
    "results_dir = source_dir + 'results/' # Location of xml files\n",
    "infiles = glob.glob(os.path.join(results_dir, '{}*.xml'.format(pattern)))\n",
    "outfile = os.path.join(output_dir, '{}-extracted.txt'.format(pattern))\n",
    "\n",
    "\n",
    "extractions = [ #[ 'metadata_extract', ['x_position', 'y_position', 'sequence_ID', 'anneal_time'] ] ,\n",
    "            ['circular_fit_compare3', ['fit_peaks_prefactor1', 'fit_peaks_x_center1', 'fit_peaks_sigma1', 'fit_peaks_chi_squared', 'fit_peaks_d0', 'fit_peaks_grain_size' ] ],\n",
    "            ]    \n",
    "\n",
    "results = extract_results(infiles, extractions, outfile=outfile, verbosity=verbosity)\n",
    "\n",
    "\n",
    "## Export results of interest to an array\n",
    "names, lines = load_file(outfile, verbosity=verbosity)\n",
    "\n",
    "columns = [\n",
    "    #'metadata_extract__x_position', \n",
    "    #'metadata_extract__y_position', \n",
    "    #'metadata_extract__anneal_time',\n",
    "    'circular_fit_compare3__fit_peaks_chi_squared'\n",
    "    ]\n",
    "\n",
    "indices = [names.index(col) for col in columns]\n",
    "\n",
    "data = []\n",
    "for i, line in enumerate(lines):\n",
    "    line = line.split()\n",
    "    if len(line)>=len(indices):\n",
    "        row = [ float(line[i]) for i in indices ]\n",
    "        data.append(row)\n",
    "\n",
    "print('\\n----- Output array:\\n {}'.format(data))\n",
    "        \n",
    "## Save \n",
    "if 0: \n",
    "    outfile = os.path.join(output_dir, '{}-{:d}.npy'.format(pattern, len(data)))\n",
    "    np.save(outfile, data)\n",
    "    if verbosity>=3:\n",
    "        print('  Saved data as'.format(outfile))\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#9642; __Load ROI__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Get infile\n",
    "pattern = 'B6_N3_Trans3_map_vac_x-0.006_y-1.050_2.00s_763448_waxs'\n",
    "infiles = glob.glob(os.path.join(output_dir+'/roi/', pattern+'*.txt')); \n",
    "print('Plotting {} infiles...'.format(len(infiles)))\n",
    "\n",
    "## Load \n",
    "stats_list = []\n",
    "for nn, infile in enumerate(infiles):\n",
    "    data =  pd.read_table(infile, delimiter = ' ', header=None)\n",
    "    if nn==0: print(data)\n",
    "        \n",
    "    temp = []\n",
    "    for ii in np.arange(3,13):\n",
    "        temp.append(data[2][ii])\n",
    "    stats_list.append(temp)\n",
    "\n",
    "    \n",
    "stats_array = np.asarray(stats_list)\n",
    "\n",
    "\n",
    "## Plot \n",
    "#%matplotlib tk\n",
    "plt.rcParams['figure.figsize'] = [10, 5] #[height, width] of the figure\n",
    "\n",
    "for ii in np.arange(0,stats_array.shape[1]):\n",
    "    plt.plot(stats_array[:,ii])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Backup__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2022_2/LZhu5/PE_120C_fastscan_50V_30V_1mms_500pa_run1'\n",
    "\n",
    "exp = Experiment.experiment('PE_120C_fastscan_50V_30V_1mms_500pa_run1', folder=EXPR_DIR, det='maxs', beamline='cms') #, beamline=None) ### CHANGE THIS, this expriment name can be arbitrary \n",
    "filenames = ['PE_120C_fastscan_50V_30V_1mms_500pa_run1_x-0.002_y0.001_0.10s'] ### Specify the sample\n",
    "\n",
    "for filename in filenames:\n",
    "    exp.defFiles_query(fn=filename, folder=EXPR_DIR, scanid = [600000, 900000], verbose=1) \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify calibration & Load filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%matplotlib nbagg\n",
    "# Imports\n",
    "########################################\n",
    "import sys, os, time, glob, imageio, datetime\n",
    "\n",
    "SciAnalysis_PATH='/nsls2/data/cms/legacy/xf11bm/software/SciAnalysis/' ### Specify this\n",
    "#SciAnalysis_PATH = '/home/etsai/BNL/Users/software/SciAnalysis/'\n",
    "SciAnalysis_PATH in sys.path or sys.path.append(SciAnalysis_PATH)\n",
    "\n",
    "from SciAnalysis import tools\n",
    "from SciAnalysis.XSAnalysis.Data import *\n",
    "from SciAnalysis.XSAnalysis import Protocols\n",
    "\n",
    "if 1: \n",
    "    calibration = Calibration(wavelength_A=0.7293) # 17 keV\n",
    "    calibration.set_image_size(981, height=1043) # Pilatus1M\n",
    "    calibration.set_pixel_size(pixel_size_um=172.0)\n",
    "    calibration.set_beam_position(313.5, 1043-314) #SA, 2023 Apr\n",
    "\n",
    "    calibration.set_distance(0.259)\n",
    "    mask_dir = SciAnalysis_PATH + '/SciAnalysis/XSAnalysis/masks/'\n",
    "    mask = Mask(mask_dir+'Dectris/Pilatus800k_gaps-mask.png')\n",
    "    #mask.load(mask_dir+'NSLSII_11BM_CMS/Pilatus800k_CMS_badpixels-mask.png ')\n",
    "       \n",
    "###--------------------------------------------------------- \n",
    "source_dir = exp.folder+'/'+exp.det+'/raw/'\n",
    "\n",
    "        \n",
    "# for regular scan/snap measurements\n",
    "if not exp.dict['expinfo']['series_measure']:\n",
    "    filenames = exp.dict['expinfo']['filename']\n",
    "\n",
    "# series measurements\n",
    "else: \n",
    "    infile = exp.dict['expinfo']['filename'][0]\n",
    "\n",
    "    # to remove extension\n",
    "    if infile[:-5] == '.tiff':\n",
    "        infile = infile[:-5]\n",
    "\n",
    "    # to remove scanid in the filename for the data before 2023 (incorrect scanid) and add the exposure_period\n",
    "    jan2023 = time.mktime(datetime.datetime.strptime('01/01/2023',\"%m/%d/%Y\").timetuple())\n",
    "    if exp.dict['expinfo']['time'][0] < jan2023:\n",
    "        infile = '_'.join(infile.split('_')[:-1]) \n",
    "        exposure_period = float(infile.split('_')[-1].split('s')[0])\n",
    "        exp.dict['expinfo']['exposure_period'] = exposure_period\n",
    "        scan_id = exp.dict['expinfo']['scan_id'][0]\n",
    "        infile = '_'.join([infile,str(scan_id+1)])\n",
    "\n",
    "    filenames = ['_'.join([infile,str(kk).zfill(6)]) for kk in range(Nfile)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify analysis protocols and run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_args = { 'calibration' : calibration, \n",
    "             'mask' : mask,\n",
    "             #'rot180' : False,\n",
    "             #'flip' : True, # PSCCD\n",
    "             }\n",
    "run_args = { 'verbosity' : 3,\n",
    "            #'save_results' : ['xml', 'plots', 'txt', 'hdf5'],\n",
    "            }\n",
    "\n",
    "process = Protocols.ProcessorXS(load_args=load_args, run_args=run_args)\n",
    "\n",
    "\n",
    "line_cir = []\n",
    "line_sector = []\n",
    "\n",
    "t0 = time.time()\n",
    "for ii, infile in enumerate(filenames):\n",
    "    if np.mod(ii, 200)==0:\n",
    "        print('[{:0.0f}%]'.format(ii/Nfile*100))\n",
    "    data = process.load(source_dir+infile+'_'+exp.det+'.tiff', calibration=calibration, mask=mask, run_args=run_args)\n",
    "\n",
    "    line_cir = data.circular_average_q_bin(error=False, bins_relative=1.0)\n",
    "    #line_sector.append(data.sector_average_q_bin(angle=60, dangle=5))\n",
    "\n",
    "    \n",
    "print('Done!')    \n",
    "print('Done! Took {:.0f}s'.format(time.time()-t0))\n",
    "\n",
    "\n",
    "### Put analysis results into the experiment dictionary (exp.dict) for downstream analysis/visualization\n",
    "if 0:\n",
    "    protocol = 'sector_average'\n",
    "    exp.dict['data'][protocol] = {}\n",
    "    for nn, line in enumerate(line_sector):\n",
    "        exp.dict['data'][protocol][str(nn)] = {}\n",
    "        exp.dict['data'][protocol][str(nn)]['q'] = line_sector[nn].x    \n",
    "        exp.dict['data'][protocol][str(nn)]['I(q)'] = line_sector[nn].y\n",
    "else:\n",
    "    protocol = 'circular_average'\n",
    "    exp.dict['data'][protocol] = {}\n",
    "    for nn, line in enumerate(line_sector):\n",
    "        exp.dict['data'][protocol][str(nn)] = {}\n",
    "        exp.dict['data'][protocol][str(nn)]['q'] = line_cir[nn].x    \n",
    "        exp.dict['data'][protocol][str(nn)]['I(q)'] = line_cir[nn].y\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
