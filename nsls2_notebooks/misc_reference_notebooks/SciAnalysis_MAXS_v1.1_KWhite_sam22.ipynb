{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data analysis with SciAnalysis\n",
    "\n",
    "last updated: 2023 May\n",
    "\n",
    "In this notebook, we can load the raw tiff, load or extract metedata, analysis the data, save the analysis results and metadata in .H5.\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    "*exp.dict*: The experiment dictionary. 'Experiment' is a series of measurements, e.g. in-situ thermal annealing measurements of a sample.\n",
    "\n",
    "*exp.dict.keys()*: ['analysis', 'corr', 'corrdata', 'data', 'detector', 'exp_protocol', 'expinfo', 'expname', 'folder', 'mdata_list', 'metadata']\n",
    "\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# &#9635; SciAnalysis for Experiment\n",
    "\n",
    "At home insitute, download SciAnalysis at: https://github.com/CFN-softbio/SciAnalysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%matplotlib nbagg\n",
    "# Imports\n",
    "########################################\n",
    "import sys, os, time, glob, imageio, datetime, pprint, math\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from silx.io.dictdump import dicttoh5, h5todict\n",
    "\n",
    "SciAnalysis_PATH='/nsls2/data/cms/legacy/xf11bm/software/SciAnalysis/' ### Specify this\n",
    "SciAnalysis_PATH in sys.path or sys.path.append(SciAnalysis_PATH)\n",
    "\n",
    "from SciAnalysis import tools\n",
    "from SciAnalysis.XSAnalysis.Data import *\n",
    "from SciAnalysis.XSAnalysis import Protocols\n",
    "\n",
    "from SciAnalysis.ExpAnalysis import Experiment\n",
    "from SciAnalysis.ExpAnalysis import Tools\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"{}\\n\".format(dt_string))\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Direct beam (if available)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calibration: Energy, beam center, SD distance__\n",
    "\n",
    "1. Specify wavelength \n",
    "2. Tweak beam center and SD distance to get the best match for the calibrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convert between q and angle__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for KWhite data in 2023C2\n",
    "\n",
    "### Use samplefolder and scanid to load the series_measure data `exp.defFiles_ScanID_ONLY`\n",
    "\n",
    "### The scanid is read from the terminal!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Specify sample folder and scanid of interest\n",
    "\n",
    "# samplefolder_load = 'sam98_3mai1pbi2_1dmf1dmso_1m_5scfh_Si_40uL_012'\n",
    "# scanid = 1116276\n",
    "\n",
    "# samplefolder_load = 'sam22_1mai1pbi2_dmso_1m_5scfh_Si_40uL_013'\n",
    "# scanid = 1116295 # read from the terminal\n",
    "\n",
    "\n",
    "# samplefolder_load = 'sam26_3mai1pbi2_dmso_1m_5scfh_Si_40uL_014'\n",
    "# scanid = 1116317 # read from the terminal\n",
    "\n",
    "# samplefolder_load = 'sam30_1mai1pbi2_dmf_0p5m_5scfh_Si_40uL_016'\n",
    "# scanid = 1116357 # read from the terminal\n",
    "\n",
    "samplefolder_load = 'sam22_1mai1pbi2_dmso_1m_5scfh_Si_40uL_013'\n",
    "scanid = 1116294 # read from the terminal\n",
    "\n",
    "\n",
    "\n",
    "# samplefolder_load = 'sam2_p3ht_toluene'\n",
    "# scanid = 1117012 # read from file\n",
    "\n",
    "\n",
    "# samplefolder_load = 'pm7_S1_95tol5cpme_14_100_18_85_75_009'\n",
    "# scanid = 1117624 # read from the file\n",
    "\n",
    "# samplefolder_load = 'pm7_S1_95tol5cpme_14_100_22p7_85_75_008'\n",
    "# scanid = 1117562\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 1: \n",
    "    # EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/' \n",
    "    # samplefolder_load = 'sam99_1mai1pbi2_1dmf1dmso_1m_5scfh_Si_40uL_011' # sam16_3mai1pbi2_dmf_1m_5scfh_Si_40uL_010\n",
    "#     # scanid = 1116248\n",
    "    \n",
    "#     samplefolder_load = 'sam98_3mai1pbi2_1dmf1dmso_1m_5scfh_Si_40uL_012' # sam16_3mai1pbi2_dmf_1m_5scfh_Si_40uL_010\n",
    "    # scanid = scanid - 1\n",
    "    # EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/'  + samplefolder_load + '/'\n",
    "    EXPR_DIR = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/'  + samplefolder_load + '/'\n",
    "    exp = Experiment.experiment(samplefolder_load, folder=EXPR_DIR, det='maxs', series_measure=True, beamline='cms') ##Experiment name: rbitrary or related to the sample name\n",
    "    exp.dict['expinfo']['fn_patterns'] = [f'{samplefolder_load}*']  \n",
    "\n",
    "\n",
    "### Load files\n",
    "try:\n",
    "    for pattern in exp.dict['expinfo']['fn_patterns']:\n",
    "        #exp.defFiles_query(fn='PBG', folder=EXPR_DIR, scanid = [900000, 1200000], verbose=1) \n",
    "        print(f'pattern = {pattern}')\n",
    "        # exp.defFiles(fn=pattern, verbose=1) \n",
    "        # exp.defFiles(fn=pattern, scanid = [750000, 900000], verbose=1)  \n",
    "        # infiles = exp.defFiles_ScanID_ONLY(fn=pattern, scanid = [1116002], verbose=1)  \n",
    "        infiles = exp.defFiles_ScanID_ONLY(fn=pattern, scanid = [scanid], verbose=1)  \n",
    "        \n",
    "    # infiles = exp.dict['rawinfo']['filename']\n",
    "    Nfiles = len(infiles)\n",
    "    \n",
    "except:\n",
    "    print('\\n!!! Databroker not working, loading files directly.')\n",
    "    #exp.dict['expinfo']['beamline'] = None\n",
    "    for pattern in exp.dict['expinfo']['fn_patterns']:\n",
    "        infiles = exp.defFiles_ScanID_ONLY(fn=pattern, scanid = [scanid], verbose=1)  \n",
    "    \n",
    "\n",
    "### Show some info   \n",
    "exp.show()\n",
    "exp.showFileInfo(idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Options: (1) load metadata from databroker at beamline. (2) load md from h5. (3) Extract info from filename\n",
    "md_load_option = 1\n",
    "\n",
    "## Clear all metadata\n",
    "exp.dict['metadata'] = {}\n",
    "\n",
    "\n",
    "## Load metadata\n",
    "if md_load_option==1: # Load md from databroker, this only works at beamline\n",
    "    exp.dict['mdata_list'] = ['scan_id'] # Specify metedata to load\n",
    "    exp.loadMetadata()\n",
    "    print(exp.dict['metadata'].keys())\n",
    "    \n",
    "elif md_load_option==2: # Load md from h5 (previously saved from databroker)\n",
    "    h5_path = EXPR_DIR+\"/data/\"\n",
    "    h5_file = 'B6_N3_metadata.h5'\n",
    "    exp.dict['metadata'] = h5todict(h5_path+h5_file)\n",
    "\n",
    "\n",
    "elif md_load_option==3: ## If databroker md is not available nor saved\n",
    "    infiles = exp.dict['rawinfo']['filename']\n",
    "    print('Number of files: {}'.format(len(infiles)))\n",
    "\n",
    "    Ts = []\n",
    "    sample_x = []\n",
    "    sample_y = []\n",
    "    scan_id = []\n",
    "    frames = []\n",
    "    for ii, infile in enumerate(infiles):\n",
    "        temp = infile.split('_')\n",
    "        if ii==0: print(temp)\n",
    "        \n",
    "        Ts.append(float(infile.split('Linkam')[1].split('C')[0]))\n",
    "        #sample_x.append(float(temp[-4][1:]))\n",
    "        #sample_y.append(float(temp[-3][1:]))\n",
    "        \n",
    "        #Ts.append(float(infile.split('RH')[1].split('_x')[0]))\n",
    "        #scan_id.append(int(temp[-1]))\n",
    "        #frames.append(int(temp[-1]))\n",
    "\n",
    "    exp.dict['metadata']['sample_temperature_D'] = Ts\n",
    "    #exp.dict['metadata']['sample_x'] = np.array(sample_x)\n",
    "    #exp.dict['metadata']['sample_y'] = np.array(sample_y)\n",
    "    #exp.dict['metadata']['frames'] = frames\n",
    "    \n",
    "    print(exp.dict['metadata'].keys())\n",
    "\n",
    "else:\n",
    "    print('No metadata loaded to the exp. dictionary!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Analysis\n",
    "\n",
    "We suspect that loading analysis results is slow, faster if processing raw data. However, going through the protocals is also slow; storing it to the exp.dict also takes a bit time.\n",
    "\n",
    "E.g. 3600 files, 1 protocol, saving to exp.dict: 5min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Specify beamline config (e.g. beam energy, center, det-sample distance)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 1: #WAXS, MAXS\n",
    "    #calibration = Calibration(wavelength_A=0.7293) # 17 keV\n",
    "    calibration = Calibration(wavelength_A=12.4/12.7) #12.7 keV\n",
    "    calibration.set_image_size(981, height=1043) # Pilatus1M\n",
    "    calibration.set_pixel_size(pixel_size_um=172.0)\n",
    "    \n",
    "    calibration.set_beam_position(577, 1043-389) # Pilatus 800k x=450 y=398 works in xi-cam, in scianalysis need y=1043-398=645\n",
    "    calibration.set_distance(0.234)\n",
    "\n",
    "    ## LRichter\n",
    "    if 0:\n",
    "        calibration.set_beam_position(543, 606) #LRichter\n",
    "        calibration.set_distance(0.2815)\n",
    "    \n",
    "    mask_dir = SciAnalysis_PATH + '/SciAnalysis/XSAnalysis/masks/'\n",
    "    mask = Mask(mask_dir+'Dectris/Pilatus800k2_gaps-mask.png')\n",
    "    mask.load('./Pilatus800k2_custom-mask.png')\n",
    "\n",
    "  \n",
    "    \n",
    "load_args = { 'calibration' : calibration, \n",
    "             'mask' : mask,\n",
    "             #'rot180' : False,\n",
    "             #'flip' : True, # PSCCD\n",
    "             }\n",
    "run_args = { 'verbosity' : 3,\n",
    "            #'save_results' : ['xml', 'plots', 'txt', 'hdf5'],\n",
    "            }\n",
    "process = Protocols.ProcessorXS(load_args=load_args, run_args=run_args)\n",
    "\n",
    "\n",
    "### Run analysis \n",
    "protocols = ['circular_average'] #['linecut_angle'] #['circular_average'] #, 'sector_average', 'linecut_qz']\n",
    "\n",
    "exp.dict['analysis']['cali'] = [calibration.wavelength_A, calibration.x0, calibration.y0, calibration.distance_m]\n",
    "#exp.dict['analysis'] = {} \n",
    "#for protocol in protocols:\n",
    "#    exp.dict['analysis'][protocol] = {}\n",
    "\n",
    "t0 = time.time()  \n",
    "    \n",
    "line_y_stack = []\n",
    "for protocol in protocols:\n",
    "    if 'circular_average' in protocol:\n",
    "        for ii, infile in enumerate(infiles):\n",
    "            if np.mod(ii+1, 50)==0: print('[{:.0f}%]'.format(ii/Nfiles*100))\n",
    "\n",
    "            det = exp.dict['expinfo']['det']\n",
    "            folder = exp.dict['expinfo']['folder']\n",
    "\n",
    "            # infile_fullpath = folder+'/'+det+'/raw/'+exp.dict['rawinfo']['filename'][ii]+'_'+det+'.tiff'\n",
    "            infile_fullpath = infile\n",
    "            # print(infile_fullpath)\n",
    "            data = process.load(infile_fullpath, calibration=calibration, mask=mask, run_args=run_args)\n",
    "\n",
    "            ### Run the protocol\n",
    "            line_output = data.circular_average_q_bin(error=False)\n",
    "            line_y_stack.append(line_output.y)\n",
    "\n",
    "            if 0:\n",
    "                exp.dict['analysis'][protocol][str(ii)] = {}\n",
    "                exp.dict['analysis'][protocol][str(ii)]['q'] = line_output.x\n",
    "                exp.dict['analysis'][protocol][str(ii)]['I(q)'] = line_output.y\n",
    "        \n",
    "        ### Save analysis to exp.dict\n",
    "        if 1:\n",
    "            exp.dict['analysis'][protocol] = {}\n",
    "            exp.dict['analysis'][protocol]['q'] = line_output.x\n",
    "            exp.dict['analysis'][protocol]['I_stack'] = line_y_stack   \n",
    "            #x = Protocols.thumbnails(name=None) \n",
    "            #x.run(data, output_dir)\n",
    "            \n",
    "    if 'linecut_qr' in protocol:\n",
    "        for ii, infile in enumerate(infiles):\n",
    "            if np.mod(ii+1, 50)==0: print('[{:.0f}%]'.format(ii/Nfiles*100))\n",
    "\n",
    "            det = exp.dict['expinfo']['det']\n",
    "            folder = exp.dict['expinfo']['folder']\n",
    "\n",
    "            infile_fullpath = folder+'/'+det+'/raw/'+exp.dict['rawinfo']['filename'][ii]+'_'+det+'.tiff'\n",
    "            data = process.load(infile_fullpath, calibration=calibration, mask=mask, run_args=run_args)\n",
    "\n",
    "            ### Run the protocol\n",
    "            line_output = data.linecut_qr(qz=0.03, dq=0.003)\n",
    "            line_y_stack.append(line_output.y)\n",
    "\n",
    "        ### Save analysis to exp.dict\n",
    "        if 1:\n",
    "            exp.dict['analysis'][protocol] = {}\n",
    "            exp.dict['analysis'][protocol]['q'] = line_output.x\n",
    "            exp.dict['analysis'][protocol]['I_stack'] = line_y_stack           \n",
    "        \n",
    "    #elif 'sector_average' in protocol: \n",
    "    #    line_output = data.sector_average_q_bin(angle=60, dangle=5)\n",
    "\n",
    "    #elif 'linecut_qz' in protocol:\n",
    "    #    line_output = data.linecut_qz(qr=0, dq=0.05)\n",
    "\n",
    "    #elif 'linecut_angle' in protocol:\n",
    "    #line_output = data.linecut_angle(q0=2.24, dq=0.01)\n",
    "            \n",
    "        \n",
    "print('Done! (Analysis took {:.0f}s)\\n'.format(time.time()-t0))\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "dt_string = now.strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "print(\"{}\\n\".format(dt_string))\n",
    "\n",
    "print(exp.dict['analysis'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save \n",
    "\n",
    "Save experiment dictionary (exp.dict) to h5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# h5_path = EXPR_DIR+\"/data/\"\n",
    "\n",
    "h5_path = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite5/'+\"/data/\"\n",
    "\n",
    "\n",
    "h5_file = str(exp.dict['expinfo']['expname']) + '_cms_exp.h5'\n",
    "output_file = h5_path+h5_file\n",
    "\n",
    "\n",
    "## Check if file exist, will not overwrite\n",
    "if False:\n",
    "    file_exist = os.path.isfile(output_file)\n",
    "    count = 1\n",
    "    while file_exist:\n",
    "        print('{} exists, using a new filename'.format(output_file))\n",
    "        h5_file = str(exp.dict['expname']) + '_exp_' + str(count) + '.h5'\n",
    "        output_file = h5_path+h5_file\n",
    "        file_exist = os.path.isfile(output_file)\n",
    "        count = count + 1\n",
    "\n",
    "        \n",
    "## Save\n",
    "dicttoh5(exp.dict, output_file)\n",
    "print('Experiment saved as {}'.format(output_file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Load H5__\n",
    "\n",
    "Load experiment dictionary and recover the object 'exp', allowing for subsequent data visualization/analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%matplotlib nbagg\n",
    "# Imports\n",
    "########################################\n",
    "import sys, os, time, glob, imageio, datetime, pprint\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from silx.io.dictdump import dicttoh5, h5todict\n",
    "SciAnalysis_PATH='/nsls2/data/cms/legacy/xf11bm/software/SciAnalysis/' ### Specify this\n",
    "SciAnalysis_PATH in sys.path or sys.path.append(SciAnalysis_PATH)\n",
    "from SciAnalysis import tools\n",
    "from SciAnalysis.XSAnalysis.Data import *\n",
    "from SciAnalysis.XSAnalysis import Protocols\n",
    "from SciAnalysis.ExpAnalysis import Experiment\n",
    "from SciAnalysis.ExpAnalysis import Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5file_load = 'sam26_3mai1pbi2_dmso_1m_5scfh_Si_40uL_014_cms_exp.h5'\n",
    "h5file_load = 'sam22_1mai1pbi2_dmso_1m_5scfh_Si_40uL_013_cms_exp.h5'\n",
    "# h5file_load = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Load experiment dict (previuosly analyzed data)\n",
    "if True:\n",
    "    \n",
    "    if h5file_load is None:\n",
    "        h5file_load = h5_file # use the one that is just saved\n",
    "    \n",
    "    exp_dict_h5 = '/nsls2/data/cms/legacy/xf11bm/data/2023_2/KWhite/data/' + h5file_load\n",
    "    \n",
    "    exp_dict_load = h5todict(exp_dict_h5)\n",
    "    #print(exp_dict_load.keys())\n",
    "    \n",
    "    exp = Experiment.experiment(exp_dict_load['expinfo']['expname'], folder=exp_dict_load['expinfo']['folder'], det=exp_dict_load['expinfo']['det'], beamline=exp_dict_load['expinfo']['beamline']) \n",
    "    exp.dict = exp_dict_load\n",
    "    \n",
    "    print(exp.dict.keys())\n",
    "    print('\\nExperiment loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __Overview of exp__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.show(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __(5.1) Data Trend__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#9642; __Plot curves__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - __Load one curve & find peaks__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Show one curve and find peaks\n",
    "\n",
    "#protocol = 'circular_average'\n",
    "protocol = list(exp.dict['analysis'].keys())[-1]\n",
    "print(protocol)\n",
    "print(exp.dict['rawinfo']['filename'][-1])\n",
    "\n",
    "## Pick a curve\n",
    "file_idx = -1\n",
    "line_plot = DataLine(x = exp.dict['analysis'][protocol]['q'], y = exp.dict['analysis'][protocol]['I_stack'][file_idx])  \n",
    "flag_log = 1\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib ipympl\n",
    "plt.figure(1, figsize=(12,5)); plt.clf()\n",
    "q_peaks = Tools.plot_peaks(line_plot, N_peaks_find = 5, fit_param=[0, 1, 0.001], flag_log=flag_log, line_color='k', label_color='r', verbose=1)  #Tools.rand_color(0.5, 0.8)\n",
    "\n",
    "# q_label = [0.1076]\n",
    "for q in q_label:\n",
    "    if flag_log:\n",
    "        y_range = [min(np.log(line_plot.y)), max(np.log(line_plot.y))]\n",
    "    else:\n",
    "        y_range = [min(line_plot.y), max(np.log(line_plot.y))]\n",
    "    plt.plot([q, q], y_range, 'g',  alpha=0.7)\n",
    "    plt.text(q, y_range[1]/2, str(q), color='g')\n",
    "\n",
    "plt.xlabel(r'$q$ $({\\rm \\AA}^{-1})$', size=20)\n",
    "plt.ylabel('Intensity', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - __Plot all curves as 2D image__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_label = q_peaks #[1.278, 1.88, 2.219, 2.564, 2.905]; # Label the lines\n",
    "flag_log = True\n",
    "\n",
    "#protocol = 'circular_average'\n",
    "protocol = list(exp.dict['analysis'].keys())[-1]\n",
    "\n",
    "\n",
    "x_axis = exp.dict['analysis'][protocol]['q'] \n",
    "I_stack = exp.dict['analysis'][protocol]['I_stack']\n",
    "# y_axis = exp.dict['metadata']['scan_id'] - exp.dict['metadata']['scan_id'][0]\n",
    "# y_axis = exp.dict['metadata']['sample_clock'] #- exp.dict['metadata']['sample_clock'][0]\n",
    "\n",
    "y_axis = np.arange(len(infiles))\n",
    "if flag_log:\n",
    "    I_stack = np.log10(I_stack)\n",
    "    \n",
    "%matplotlib inline\n",
    "plt.figure(2, figsize=(12,8)); plt.clf()\n",
    "# plt.imshow(I_stack, origin='lower', cmap='jet', extent = [np.min(x_axis), np.max(x_axis), scan_id[0], scan_id[-1]],  aspect='auto') #aspect='auto' 0.005\n",
    "# # plt.imshow(I_stack, origin='lower', cmap='jet', extent = [np.min(x_axis), np.max(x_axis), 0, I_stack.shape[0]],  aspect='auto') #aspect='auto' 0.005\n",
    "# cbar = plt.colorbar(fraction=0.02, pad=0.02, aspect=40) \n",
    "\n",
    "# y_axis = np.arange(0, I_stack.shape[0])\n",
    "X, Y = np.meshgrid(x_axis, y_axis)\n",
    "#dont know how to change the plotting range in pcolormesh\n",
    "# plt.pcolormesh(X,Y,I_stack,vmin=.3,vmax=2.8, cmap=mpl.cm.jet); plt.colorbar()\n",
    "plt.pcolormesh(X,Y,I_stack, cmap=mpl.cm.jet); plt.colorbar()\n",
    "plt.xlabel(r'$q$ $({\\rm \\AA}^{-1})$', size=20)\n",
    "plt.ylabel('index', size=20)\n",
    "# plt.ylabel('Time (s)')\n",
    "# plt.xlim(-.2, .2)\n",
    "plt.ylim(0, 2)\n",
    "plt.clim(0, 2.5)\n",
    "\n",
    "print('q_label = {}'.format(q_label))\n",
    "#for q in q_label:\n",
    "#    plt.plot([q, q], [0, I_stack.shape[0]], 'k',  alpha=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_label = q_peaks #[1.278, 1.88, 2.219, 2.564, 2.905]; # Label the lines\n",
    "flag_log = True\n",
    "\n",
    "#protocol = 'circular_average'\n",
    "protocol = list(exp.dict['analysis'].keys())[-1]\n",
    "\n",
    "\n",
    "x_axis = exp.dict['analysis'][protocol]['q'] \n",
    "I_stack = exp.dict['analysis'][protocol]['I_stack']\n",
    "# y_axis = exp.dict['metadata']['scan_id'] - exp.dict['metadata']['scan_id'][0]\n",
    "# y_axis = exp.dict['metadata']['sample_clock'] #- exp.dict['metadata']['sample_clock'][0]\n",
    "\n",
    "exposure_period = 0.5\n",
    "y_axis = np.arange(len(infiles))*exposure_period\n",
    "if flag_log:\n",
    "    I_stack = np.log10(I_stack)\n",
    "    \n",
    "%matplotlib inline\n",
    "plt.figure(2, figsize=(12,8)); plt.clf()\n",
    "# plt.imshow(I_stack, origin='lower', cmap='jet', extent = [np.min(x_axis), np.max(x_axis), scan_id[0], scan_id[-1]],  aspect='auto') #aspect='auto' 0.005\n",
    "# # plt.imshow(I_stack, origin='lower', cmap='jet', extent = [np.min(x_axis), np.max(x_axis), 0, I_stack.shape[0]],  aspect='auto') #aspect='auto' 0.005\n",
    "# cbar = plt.colorbar(fraction=0.02, pad=0.02, aspect=40) \n",
    "\n",
    "# y_axis = np.arange(0, I_stack.shape[0])\n",
    "X, Y = np.meshgrid( y_axis, x_axis)\n",
    "#dont know how to change the plotting range in pcolormesh\n",
    "# plt.pcolormesh(X,Y,I_stack,vmin=.3,vmax=2.8, cmap=mpl.cm.jet); plt.colorbar()\n",
    "plt.pcolormesh(X,Y,I_stack.T, cmap=mpl.cm.jet, \n",
    "               vmin=np.percentile(I_stack, 0),\n",
    "               vmax=np.percentile(I_stack, 100)) #, vmin=0.2,vmax=2.3); \n",
    "plt.colorbar()\n",
    "plt.ylabel(r'$q$ $({\\rm \\AA}^{-1})$', size=20)\n",
    "plt.xlabel('Time (s)', size=20)\n",
    "# plt.ylabel('Time (s)')\n",
    "# plt.xlim(-.2, .2)\n",
    "# plt.ylim(0.3, 3)\n",
    "plt.clim(0, 2)\n",
    "\n",
    "print('q_label = {}'.format(q_label))\n",
    "#for q in q_label:\n",
    "#    plt.plot([q, q], [0, I_stack.shape[0]], 'k',  alpha=0.2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#9642; __Plot curves__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - __Load one curve & find peaks__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Show one curve and find peaks\n",
    "\n",
    "#protocol = 'circular_average'\n",
    "protocol = list(exp.dict['analysis'].keys())[-1]\n",
    "print(protocol)\n",
    "print(exp.dict['rawinfo']['filename'][-1])\n",
    "\n",
    "## Pick a curve\n",
    "file_idx = -1\n",
    "line_plot = DataLine(x = exp.dict['analysis'][protocol]['q'], y = exp.dict['analysis'][protocol]['I_stack'][file_idx])  \n",
    "flag_log = 1\n",
    "\n",
    "%matplotlib inline\n",
    "#%matplotlib ipympl\n",
    "plt.figure(1, figsize=(12,5)); plt.clf()\n",
    "q_peaks = Tools.plot_peaks(line_plot, N_peaks_find = 5, fit_param=[0, 1, 0.001], flag_log=flag_log, line_color='k', label_color='r', verbose=1)  #Tools.rand_color(0.5, 0.8)\n",
    "\n",
    "# q_label = [0.1076]\n",
    "for q in q_label:\n",
    "    if flag_log:\n",
    "        y_range = [min(np.log(line_plot.y)), max(np.log(line_plot.y))]\n",
    "    else:\n",
    "        y_range = [min(line_plot.y), max(np.log(line_plot.y))]\n",
    "    plt.plot([q, q], y_range, 'g',  alpha=0.7)\n",
    "    plt.text(q, y_range[1]/2, str(q), color='g')\n",
    "\n",
    "plt.xlabel(r'$q$ $({\\rm \\AA}^{-1})$', size=20)\n",
    "plt.ylabel('Intensity', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "peak_num = 2\n",
    "\n",
    "x_axis = exp.dict['analysis'][protocol]['q'] \n",
    "I_stack = exp.dict['analysis'][protocol]['I_stack']\n",
    "\n",
    "I_peak = I_stack[:, np.where(x_axis == q_peaks[peak_num])[0]]\n",
    "idx = np.arange(len(I_peak))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(idx, I_peak, label = f'q = {q_peaks[peak_num]: .3} A^-1')\n",
    "ax.set_xlabel('index', size=20)\n",
    "ax.set_ylabel('Intensity', size=20)\n",
    "ax.set\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### &#9642; __Extract 0D feature & Plot 1D__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - __Load one curve for peak fitting__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Show one curve & do fitting\n",
    "protocol = 'circular_average'\n",
    "\n",
    "file_idx = -1\n",
    "line_plot = DataLine(x = exp.dict['analysis'][protocol]['q'], y = exp.dict['analysis'][protocol]['I_stack'][file_idx])  \n",
    "\n",
    "q0 = [0.646] #[2.64964595, 3.07210364] #[1.82, 1.86]\n",
    "fit_range =  [q0[0] -.05, q0[0] +0.05] #[2.5, 3.2] #[1.7, 1.95]\n",
    "\n",
    "# q0 = [0.381] #[2.64964595, 3.07210364] #[1.82, 1.86]\n",
    "# fit_range = [0.33, 0.45] #[2.5, 3.2] #[1.7, 1.95]\n",
    "\n",
    "flag_log = True\n",
    "if flag_log == 1:\n",
    "    line_plot.y = np.log(line_plot.y)\n",
    "\n",
    "## Fitting\n",
    "run_args = { 'verbosity' : 3,\n",
    "             #'fittype': 'voigt',\n",
    "            }\n",
    "results = {}\n",
    "protocol = Protocols.fit_peaks()\n",
    "lines = protocol._fit(line_plot, results, **run_args, q0=q0, num_curves=len(q0), fit_range=fit_range)\n",
    "\n",
    "plt.figure(10); plt.clf()\n",
    "for nn, line in enumerate(lines.lines):\n",
    "        \n",
    "    if nn==0: \n",
    "        plt.plot(line.x, line.y, 'k', linewidth=1, label=line.name)\n",
    "        plt.title(line.name)\n",
    "    elif nn==1:\n",
    "        plt.plot(line.x, line.y, 'g', linewidth=2, label=line.name)\n",
    "    else:\n",
    "        plt.plot(line.x, line.y, 'r', linewidth=1, label=line.name)\n",
    "        \n",
    "    plt.grid()\n",
    "\n",
    "    # plt.legend()\n",
    "pprint.pprint(lines.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - __Apply fitting for all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "protocol = 'circular_average'\n",
    "q0 = [0.646, 2] #[2.64964595, 3.07210364] #[1.82, 1.86]\n",
    "fit_range = [0.60, 0.70, 1.8, 2.2] #[1.7, 1.95]\n",
    "\n",
    "\n",
    "## Fitting\n",
    "run_args = { 'verbosity' : 3,\n",
    "             #'fittype': 'voigt',\n",
    "            }\n",
    "p = Protocols.fit_peaks()\n",
    "    \n",
    "\n",
    "## Fitting all curves\n",
    "#0.646, 2\n",
    "peak_x1 = []\n",
    "peak_x2 = []\n",
    "peak_pre1 = []\n",
    "peak_y = []\n",
    "t0 = time.time()\n",
    "plt.figure(10); plt.clf()\n",
    "\n",
    "for ii in np.arange(Nfiles):\n",
    "    line_plot = DataLine(x = exp.dict['analysis'][protocol]['q'], y = exp.dict['analysis'][protocol]['I_stack'][ii])  \n",
    "    \n",
    "    lines = p._fit(line_plot, results={}, **run_args, q0=q0, num_curves=len(q0), fit_range=fit_range)\n",
    "\n",
    "    peak_x1.append(lines.results['fit_peaks_x_center1']['value'])\n",
    "    #peak_x2.append(lines.results['fit_peaks_x_center2']['value'])\n",
    "    peak_pre1.append(lines.results['fit_peaks_prefactor1']['value'])\n",
    "    peak_y.append(lines.lines[1].target_y_max()[1])\n",
    "    peak_x2.append(lines.results['fit_peaks_x_center2']['value'])\n",
    "\n",
    "print('Fitting took {:.0f}s\\n'.format(time.time()-t0))\n",
    "\n",
    "plt.show()\n",
    "#Ts = exp.dict['metadata']['sample_temperature_D']\n",
    "#scan_ids = exp.dict['rawinfo']['scan_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(y_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### - __Plot peak position and peak intensity from fitting__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(y_axis*.5, peak_x1, '.-b')\n",
    "ax.set_ylabel('Q (A-1)', color = 'b', size=20)\n",
    "ax.set_xlabel('Time (s)', size=20)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(y_axis*.5, peak_y, 'r-o')\n",
    "ax2.set_ylabel('Peak intensity', color = 'r', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Get the q with max intensity within this range\n",
    "\n",
    "target_q = [0.5, 0.646, 2]\n",
    "\n",
    "Fig,ax = plt.subplots()\n",
    "\n",
    "for q in target_q:\n",
    "    closest_index = np.argmin(np.abs(x_axis-q))\n",
    "    target_I = I_stack.T[closest_index]\n",
    "\n",
    "    ax.plot(y_axis*.5, target_I, label='q={}'.format(q))\n",
    "    ax.legend()#, size=20)\n",
    "    \n",
    "ax.set_ylabel('Peak Intensity', size=20)\n",
    "ax.set_xlabel('Time (s)', size=20)\n",
    "\n",
    "# y_axis = line_x\n",
    "\n",
    "# q_peakmax_list = []\n",
    "# data_show = []\n",
    "# for ii in np.arange(len(y)):\n",
    "#     line_y = y[ii]\n",
    "#     line_y_crop = line_y[idx_min:idx_max]\n",
    "#     line_x_crop = x_axis[idx_min:idx_max]\n",
    "#     q_peakmax = line_x_crop[np.argmax(line_y_crop)]\n",
    "#     q_peakmax_list.append(q_peakmax)\n",
    "#     data_show.append([Ts[ii], scan_ids[ii], q_peakmax])\n",
    "\n",
    "# df_line_s = pd.DataFrame(q_peakmax_list, columns=['I'])\n",
    "# df_show = pd.DataFrame(data_show, columns = ['RH', 'scan_id', 'q_peakmax'])\n",
    "\n",
    "# print(q_peakmax_list[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(peak_xx, '.-b')\n",
    "ax.set_ylabel('Peak position', color = 'b', size=20)\n",
    "ax.set_xlabel('Index')\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(peak_y, 'r-o')\n",
    "ax2.set_ylabel('Peak intensity', color = 'r', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.dict['analysis']['circular_average']['fit_peaks_x_center1'] = peak_x1\n",
    "# #exp.dict['analysis']['circular_average']['fit_peaks_x_center2'] = peak_x2\n",
    "# exp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Convert list or dict to dataframe:\n",
    "# df_list = pd.DataFrame(peak_x1, columns=['peak_x1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
