{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eabf6442-7d0e-4f3a-b3e5-485f1da931b7",
   "metadata": {},
   "source": [
    "# Notebook for slicing and plotting pre-reduced/reshaped GIWAXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908d046-9052-4bfd-aeff-5e709f107031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import pathlib, json, lmfit\n",
    "from lmfit.models import PseudoVoigtModel, LinearModel, ExponentialModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa78d920-3e84-4e13-97c4-f5e03528bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions / misc:\n",
    "def plot_reduced_image(sample='S1', log=True, save=False):\n",
    "    \"\"\"\n",
    "    For quickly plotting reshaped GIWAXS from GIXSGUI-exported tif files\n",
    "    \"\"\"\n",
    "    data = plt.imread(list(reducedPath.glob(f'*{sample}*'))[0])  # importantly, this uses global variable reducedPath\n",
    "    data = data[:,:,0].copy()\n",
    "    data.shape\n",
    "\n",
    "    with np.errstate(divide='ignore'):\n",
    "        data_log = np.log(data)\n",
    "\n",
    "    # replace -inf's with zeros\n",
    "    data_log[(data_log == -np.inf)] = 0\n",
    "\n",
    "    if log:\n",
    "        plt.imshow(data_log, origin='lower', extent=[-1.5,0.5,0,2])\n",
    "    else:\n",
    "        plt.imshow(data, origin='lower', extent=[-1.5,0.5,0,2])\n",
    "    \n",
    "    plt.title(f'{sample}_{sample_dict[sample]}')\n",
    "    plt.xlabel('Qxy [1/A]')\n",
    "    plt.ylabel('Qz [1/A]')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    if save==True:\n",
    "        plt.savefig(savePath.joinpath(f'{sample_dict[sample]}_reduced.svg'))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def linecut_plotter(dict1, dict2, sample, sample_dict, save=False, bot=1, cmap='cool'):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    fig.set(size_inches=(15,5))\n",
    "    fig.suptitle(f'{sample}: {sample_dict[sample]} linecuts', size=16)\n",
    "    \n",
    "    # Choose specified color map, uses exec() to easily input the cmap chosen\n",
    "    c = {}\n",
    "    exec(f'c1 = plt.cm.{cmap}(np.linspace(0,1,len(IP_OOP_dict)))', None, c)\n",
    "    exec(f'c2 = plt.cm.{cmap}(np.linspace(0,1,len(data_dict)))', None, c)\n",
    "    c1, c2 = c['c1'], c['c2']\n",
    "\n",
    "    for i, key in enumerate(dict1):\n",
    "        q = dict1[key][:,0]\n",
    "        I = dict1[key][:,1]\n",
    "        ax1.plot(q, I, label=key, c=c1[i])\n",
    "\n",
    "        # print(data_dict[key])\n",
    "\n",
    "    for i, key in enumerate(dict2):\n",
    "        q = dict2[key][:,0]\n",
    "        I = dict2[key][:,1]\n",
    "        ax2.plot(q, I, label=key, c=c2[i])\n",
    "\n",
    "    for ax in (ax1,ax2):\n",
    "        ax.set(yscale='log', ylim=(3))\n",
    "        ax.legend()\n",
    "\n",
    "    ax1.set_ylim(bottom=bot)\n",
    "    ax2.set_ylim(bottom=bot)\n",
    "\n",
    "    ax1.set(xlabel='Q [1/A]', ylabel='Intensity')\n",
    "    ax2.set(xlabel='Q [1/A]', ylabel='Intensity')\n",
    "    \n",
    "    if save==True:\n",
    "        plt.savefig(savePath.joinpath(f'{sample_dict[sample]}.svg'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def intensity_at(q_norm):\n",
    "    print(f'Intensities at q={round(q_norm,5)}')\n",
    "    for key in data_dict:\n",
    "        q = data_dict[key][:,0]\n",
    "        I = data_dict[key][:,1]\n",
    "        try:\n",
    "            norm_ind = np.where(np.abs(q-q_norm)<1e-2)[0][1]\n",
    "            print(f'{key}: {I[norm_ind]}')\n",
    "        except IndexError:\n",
    "            norm_ind = 'out of bound'\n",
    "            print(f'{key}: {norm_ind}')\n",
    "    print()\n",
    "    return None\n",
    "\n",
    "def avg_intensity(q_norm):\n",
    "    intensities = []\n",
    "    for key in data_dict:\n",
    "        q = data_dict[key][:,0]\n",
    "        I = data_dict[key][:,1]\n",
    "        try:\n",
    "            norm_ind = np.where(np.abs(q-q_norm)<1e-2)[0][1]\n",
    "            # print(f'{key}: {I[norm_ind]}')\n",
    "            intensities.append(I[norm_ind])\n",
    "        except IndexError:\n",
    "            norm_ind = 'out of bound'\n",
    "            # print(f'{key}: {norm_ind}')\n",
    "    return sum(intensities)/len(intensities)\n",
    "\n",
    "def linecut_data(cut='IP', q_max_setpoint=None):\n",
    "    \"\"\" \n",
    "    Input: cut = 'IP' (default) or 'OOP'\n",
    "    Outputs: (q, I) for chosen linecut\n",
    "    \"\"\"\n",
    "    if cut=='IP':\n",
    "        chi_slice = '-90to-75'\n",
    "    elif cut=='OOP':\n",
    "        chi_slice = '-15to0'\n",
    "    data = normed_IP_OOP_dict[f'{sample}_masked_chi_{chi_slice}']\n",
    "    q = data[:,0]\n",
    "    I = data[:,1]\n",
    "    \n",
    "    if q_max_setpoint:\n",
    "        q_max_index = np.where(np.abs(q-q_max_setpoint)<1e-2)[0][0]\n",
    "        q = q[:q_max_index]\n",
    "        I = I[:q_max_index]\n",
    "    \n",
    "    return q, I\n",
    "\n",
    "def fit_plotter(q, I, out, top=5, save_plot=False, save_data=False, save_peaks=False):\n",
    "    \"\"\"\n",
    "    Plots a figure with 2 axes, the full fit on a log scale on the left and the components in normal scale on the right\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    fig.set(size_inches=(12,4))\n",
    "    fig.suptitle(f'{sample}_{sample_dict[sample]}_{sector}_curve_fitting')\n",
    "\n",
    "    ax1.plot(q, I, label='data')\n",
    "    ax1.plot(q, out.best_fit, label='full_fit')\n",
    "    ax1.set(yscale='log', xlabel='Q [1/A]', ylabel='Intensity')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(q, I, label='data')\n",
    "    ax2.plot(q, out.best_fit, label='full_fit')\n",
    "    for key in out.eval_components():\n",
    "        ax2.plot(q, out.eval_components()[key], label=f'{key}')\n",
    "    ax2.set(ylim=(-0.1, top), xlabel='Q [1/A]', ylabel='Intensity')\n",
    "    ax2.legend()\n",
    "    \n",
    "    if save_plot:\n",
    "        plt.savefig(savePath.joinpath(f'{sample}_{sample_dict[sample]}_{sector}_fitted_plot.svg'))\n",
    "        \n",
    "    if save_data:\n",
    "        columns = ['q', 'I', 'full_fit']\n",
    "        for key in out.eval_components():\n",
    "            columns.append(key)\n",
    "        \n",
    "        output_data = {}\n",
    "        \n",
    "        for column in columns:\n",
    "            if column == 'q':\n",
    "                output_data[column] = q\n",
    "            elif column == 'I':\n",
    "                output_data[column] = I\n",
    "            elif column == 'full_fit':\n",
    "                output_data[column] = out.best_fit\n",
    "            else:\n",
    "                output_data[column] = out.eval_components()[column]\n",
    "        \n",
    "        df = pd.DataFrame(output_data)\n",
    "        df.to_csv(savePath.joinpath(f'{sample}_{sample_dict[sample]}_{sector}_fitted_plot_data.csv'), index=False)\n",
    "        \n",
    "    if save_peaks:\n",
    "        with savePath.joinpath(f'{sample}_{sample_dict[sample]}_{sector}_fitted_plot_peak_values.json').open('w') as outfile:\n",
    "            json.dump(out.best_values, outfile)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a53ef-d74a-448a-aebd-c5d32e5af2f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define paths:\n",
    "notebookPath = pathlib.Path.cwd()  # Define current notebook and where data is relative to it\n",
    "rootPath = notebookPath.parent.parent  # What I call the rootpath, where all data can be accessed from\n",
    "dataPath = rootPath.joinpath('beamline_data', 'APS-GIWAXS-Feb2022', 'data')  # Where all the raw data is\n",
    "reducedPath = dataPath.joinpath('reshaped')  # Where the exported reshaped data is\n",
    "linecutPath = dataPath.joinpath('linecuts')  # Where the linecuts are\n",
    "savePath = notebookPath.joinpath('export_data', 'ptb7_ieico_15deg_masked')\n",
    "\n",
    "# List data present in reduced path:\n",
    "print('### Reduced data files:')\n",
    "for file in reducedPath.glob('*'):\n",
    "    print(file.name)\n",
    "    \n",
    "# # List data present in linecut path:\n",
    "# sample = 'S1'  # optionally choose a specific sample name\n",
    "# print('')\n",
    "# print('### Linecut files:')\n",
    "# for file in linecutPath.glob(f'{sample}*'):\n",
    "#     print(file.name)\n",
    "\n",
    "sample_dict = {\n",
    "    'S1':'PTB7-Th_dark',\n",
    "    'S2':'PTB7-Th_aged',\n",
    "    'S3':'blend_dark',\n",
    "    'S4':'blend_aged_500sp',\n",
    "    'S5':'blend_aged_full',\n",
    "    'S6':'blend_aged_850lp',\n",
    "    'S7':'IEICO-4F_dark',\n",
    "    'S8':'IEICO-4F_aged'\n",
    "}\n",
    "\n",
    "print()\n",
    "print('Sample Guide:')\n",
    "for key in sample_dict:\n",
    "    print(f'{key}: {sample_dict[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a448ad-5b93-407b-bb9e-7f5b298694ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose and show reduced image of sample:\n",
    "sample = 'S3'\n",
    "plot_reduced_image(sample, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761a83df-8585-46eb-8dd7-2a29aca5eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show linecuts for sample in folder\n",
    "data_list = sorted(linecutPath.glob(f'*{sample}_masked_*'))\n",
    "\n",
    "# Print files name\n",
    "for i, file in enumerate(data_list):\n",
    "    print(i, file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f11969-3c0d-49f5-a0a8-2985a314f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_list[-1].name)\n",
    "norm_slice = np.loadtxt(data_list[-1])\n",
    "norm_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3477312e-53e0-4598-9444-9ba10b057ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plotting all 90-deg un-normalized and normalized plots together\n",
    "\n",
    "# Show linecuts for sample in folder\n",
    "samples = ['S1', 'S3', 'S7']\n",
    "data_list = []\n",
    "for sample in samples:\n",
    "    data_list.append(sorted(linecutPath.glob(f'*{sample}_masked_*-90to0*'))[0])\n",
    "\n",
    "# # Print files name\n",
    "# for i, file in enumerate(data_list):\n",
    "#     print(i, file.name[:2])\n",
    "\n",
    "    \n",
    "# Load data into data_dictionary:\n",
    "data_dict = {}\n",
    "for data in data_list:\n",
    "    name = data.name[:2]\n",
    "    vars().__setitem__(name, np.loadtxt(data))\n",
    "    data_dict[name] = vars()[name]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2)    \n",
    "fig.suptitle('90 degree linecuts for normalization', size=14)\n",
    "fig.set(size_inches=(12,4))\n",
    "\n",
    "for sample in samples:\n",
    "    q = data_dict[sample][:,0]\n",
    "    I = data_dict[sample][:,1]\n",
    "    \n",
    "    norm_index = np.where(np.abs(q - 2.5) < 0.01)[0][-2]\n",
    "    q_norm = q[norm_index]\n",
    "    avgI = I[norm_index]\n",
    "    I_normed = I/avgI\n",
    "    \n",
    "    \n",
    "    ax1.plot(q, I, label=f'{sample}_{sample_dict[sample]}')\n",
    "    ax1.set(title='Raw data', yscale='log', ylabel='Intensity [arb. units]', xlabel='Q [1/A]')\n",
    "    \n",
    "    ax2.plot(q, I_normed, label=f'{sample}_{sample_dict[sample]}')\n",
    "    ax2.set(title='Normalized data', yscale='log', ylabel='Intensity [arb. units]', xlabel='Q [1/A]')\n",
    "    \n",
    "plt.legend()\n",
    "plt.savefig(savePath.joinpath('90deg_cuts_raw_to_normalized.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf001a54-6544-4a50-b63e-4dd2206e3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice data list as needed for files you want to plot:\n",
    "data_list = data_list[:-1]\n",
    "\n",
    "# Print files name\n",
    "for i, file in enumerate(data_list):\n",
    "    print(i, file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2364179-dd85-41ad-8b89-45fefa772bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import linecut data into 2 dictionaries (1 containing all data and 1 containing just most IP and OOP scans)\n",
    "data_dict = {}\n",
    "IP_OOP_dict = {}\n",
    "\n",
    "for data in data_list:\n",
    "    name = data.name[:-19]\n",
    "    vars().__setitem__(name, np.loadtxt(data))\n",
    "    data_dict[name] = vars()[name]\n",
    "    if name[9:] == '_chi_-15to0' or name[9:] == '_chi_-90to-75':  # choose your most IP and OOP scans \n",
    "        IP_OOP_dict[name] = vars()[name]\n",
    "\n",
    "display(data_dict.keys())\n",
    "display(IP_OOP_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e338b8a-443c-4cc5-8513-039ba0e354ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "linecut_plotter(IP_OOP_dict, data_dict, sample, sample_dict, bot=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da67a286-1039-48ef-8922-2bddb6605aad",
   "metadata": {},
   "source": [
    "### Normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e44a31f-2bba-48bd-a4ae-e50e23833ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_q = norm_slice[:, 0]\n",
    "norm_I = norm_slice[:, 1]\n",
    "plt.semilogy(norm_q, norm_I)\n",
    "plt.xlabel('Q [1/A]')\n",
    "plt.ylabel('Intensity [arb. units]')\n",
    "# plt.ylim(bottom=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b20cf-0dcb-4891-b801-f5dd539e9976",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_index = np.where(np.abs(norm_q - 2.5) < 0.01)[0][-2]\n",
    "q_norm = norm_q[norm_index]\n",
    "avgI = norm_I[norm_index]\n",
    "print(f'Intensity: {avgI}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705c13f5-e854-4b13-b4c9-91244914d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize: Create new normalized data dictionaries\n",
    "normed_data_dict = {}\n",
    "normed_IP_OOP_dict = {}\n",
    "\n",
    "for key in data_dict:\n",
    "    q = data_dict[key][:,0]\n",
    "    I = data_dict[key][:,1]\n",
    "    I_normed = I/avgI\n",
    "    \n",
    "    normed_data_dict[key] = np.vstack((q,I_normed)).T\n",
    "    \n",
    "    if key == f'{sample}_masked_chi_-15to0' or key == f'{sample}_masked_chi_-90to-75':\n",
    "        normed_IP_OOP_dict[key] = np.vstack((q,I_normed)).T\n",
    "\n",
    "# plot to check\n",
    "linecut_plotter(dict1=normed_IP_OOP_dict, dict2=normed_data_dict, sample=sample, sample_dict=sample_dict, save=False, bot=6e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1297c83e-f56d-4261-80f1-9b4e73975cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PTB7-Th IP linecut\n",
    "sector = 'IP'\n",
    "q_max = 2.2\n",
    "q, I = linecut_data(sector, q_max)\n",
    "\n",
    "# Set slope and intercept of background by drawing line through minimum point and where the data was normed\n",
    "I_min = I.min()\n",
    "q_min = q[np.where(I==I_min)[0][0]]\n",
    "m = (1-I_min)/(q_norm-q_min)\n",
    "intercept = I_min - m*q_min\n",
    "\n",
    "# Define all models to include in fitting\n",
    "# bkg_mod = LinearModel(prefix='bkg_')\n",
    "# pars = bkg_mod.make_params(intercept=intercept, slope=m)\n",
    "bkg_mod = LinearModel(prefix='bkg_')\n",
    "pars = bkg_mod.make_params(intercept=0.5, slope=0)\n",
    "pars['bkg_intercept'].set(vary=False)\n",
    "pars['bkg_slope'].set(vary=False)\n",
    "\n",
    "pk1_mod = PseudoVoigtModel(prefix='pk1_')\n",
    "pars += pk1_mod.guess(I, q, center=.25)\n",
    "\n",
    "pk2_mod = PseudoVoigtModel(prefix='pk2_')\n",
    "pars += pk2_mod.guess(I, q, center=0.9)\n",
    "\n",
    "pk3_mod = PseudoVoigtModel(prefix='pk3_')\n",
    "pars += pk3_mod.guess(I, q, center=1.4)\n",
    "\n",
    "pk4_mod = PseudoVoigtModel(prefix='pk4_')\n",
    "pars += pk4_mod.guess(I, q, center=1.7)\n",
    "\n",
    "\n",
    "# Combine into full model\n",
    "mod = bkg_mod + pk1_mod + pk2_mod + pk3_mod + pk4_mod # + pk5_mod + pk6_mod\n",
    "\n",
    "\n",
    "# Run fit and store all info in a ModelResult object\n",
    "out = mod.fit(I, pars, x=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88155af7-ad59-4b60-bd58-a353f2233407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PTB7-Th OOP linecut\n",
    "sector = 'OOP'\n",
    "q, I = linecut_data(sector)\n",
    "\n",
    "# Set slope and intercept of background by drawing line through minimum point and where the data was normed\n",
    "I_min = I.min()\n",
    "q_min = q[np.where(I==I_min)[0][0]]\n",
    "m = (1-I_min)/(q_norm-q_min)\n",
    "intercept = I_min - m*q_min\n",
    "\n",
    "# Define all models to include in fitting\n",
    "# bkg_mod = LinearModel(prefix='bkg_')\n",
    "# pars = bkg_mod.make_params(intercept=intercept, slope=m)\n",
    "bkg_mod = LinearModel(prefix='bkg_')\n",
    "pars = bkg_mod.make_params(intercept=0.5, slope=0)\n",
    "pars['bkg_intercept'].set(vary=False)\n",
    "pars['bkg_slope'].set(vary=False)\n",
    "\n",
    "pk1_mod = PseudoVoigtModel(prefix='pk1_')\n",
    "pars += pk1_mod.guess(I, q, center=.4)\n",
    "\n",
    "pk2_mod = PseudoVoigtModel(prefix='pk2_')\n",
    "pars += pk2_mod.guess(I, q, center=1.5)\n",
    "pars['pk2_center'].set(min=1.4, max=1.6)\n",
    "pars['pk2_sigma'].set(max=1)\n",
    "\n",
    "pk3_mod = PseudoVoigtModel(prefix='pk3_')\n",
    "pars += pk3_mod.guess(I, q, center=1.7)\n",
    "pars['pk3_center'].set(min=1.62, max=1.75)\n",
    "pars['pk3_sigma'].set(max=1)\n",
    "\n",
    "\n",
    "# pk4_mod = PseudoVoigtModel(prefix='pk4_')\n",
    "# pars += pk4_mod.guess(I, q, center=1.7)\n",
    "\n",
    "# pk5_mod = PseudoVoigtModel(prefix='pk5_')\n",
    "# pars += pk5_mod.guess(I, q, center=1.6)\n",
    "\n",
    "# pk6_mod = PseudoVoigtModel(prefix='pk6_')\n",
    "# pars += pk6_mod.guess(I, q, center=2.25)\n",
    "\n",
    "\n",
    "# Combine into full model\n",
    "mod = bkg_mod + pk1_mod + pk2_mod + pk3_mod #+ pk4_mod # + pk5_mod + pk6_mod\n",
    "\n",
    "\n",
    "# Run fit and store all info in a ModelResult object\n",
    "out = mod.fit(I, pars, x=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24006708-b14c-433f-8f5f-41b207693a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# S3 Blend IP linecut\n",
    "sector = 'IP'\n",
    "q_max = 2.1\n",
    "q, I = linecut_data(sector, q_max)\n",
    "\n",
    "# # Set slope and intercept of background by drawing line through minimum point and where the data was normed\n",
    "# I_min = I.min()\n",
    "# q_min = q[np.where(I==I_min)[0][0]]\n",
    "# m = (1-I_min)/(q_norm-q_min)\n",
    "# intercept = I_min - m*q_min\n",
    "\n",
    "\n",
    "# Really just want straight line from norm point to *local* minimum around q=0.55?\n",
    "I_min = I[np.where(np.abs(q-0.55)<2e-1)[0]].min()\n",
    "q_min = q[np.where(I==I_min)[0][0]]\n",
    "m = (1-I_min)/(q_norm-q_min)\n",
    "intercept = I_min - m*q_min\n",
    "\n",
    "# Define all models to include in fitting\n",
    "bkg_mod = LinearModel(prefix='bkg_')\n",
    "pars = bkg_mod.make_params(intercept=0.5, slope=0)\n",
    "pars['bkg_intercept'].set(vary=False)\n",
    "pars['bkg_slope'].set(vary=False)\n",
    "\n",
    "pk1_mod = PseudoVoigtModel(prefix='pk1_')\n",
    "pars += pk1_mod.guess(I, q, center=.28)\n",
    "pars['pk1_amplitude'].set(min=0.5)\n",
    "\n",
    "pk2_mod = PseudoVoigtModel(prefix='pk2_')\n",
    "pars += pk2_mod.guess(I, q, center=.35)\n",
    "# pars['pk2_center'].set(max = 0.62, min = 0.58)\n",
    "# pars['pk2_sigma'].set(max = 0.03)\n",
    "pars['pk2_amplitude'].set(min=0.5)\n",
    "\n",
    "pk3_mod = PseudoVoigtModel(prefix='pk3_')\n",
    "pars += pk3_mod.guess(I, q, center=0.7)\n",
    "# pars['pk3_center'].set(min=1.3, max=1.4)\n",
    "# pars['pk3_sigma'].set(max=0.5)\n",
    "pars['pk3_amplitude'].set(min=1e-2)\n",
    "\n",
    "pk4_mod = PseudoVoigtModel(prefix='pk4_')\n",
    "pars += pk4_mod.guess(I, q, center=0.9)\n",
    "pars['pk4_amplitude'].set(min=1e-2)\n",
    "# pars['pk4_center'].set(max=1.72)\n",
    "\n",
    "pk5_mod = PseudoVoigtModel(prefix='pk5_')\n",
    "pars += pk5_mod.guess(I, q, center=1.35)\n",
    "pars['pk5_amplitude'].set(min=1e-2)\n",
    "\n",
    "pk6_mod = PseudoVoigtModel(prefix='pk6_')\n",
    "pars += pk6_mod.guess(I, q, center=1.7)\n",
    "pars['pk6_amplitude'].set(min=1e-2)\n",
    "pars['pk6_sigma'].set(max=0.5)\n",
    "\n",
    "# pka_mod = PseudoVoigtModel(prefix='pka_')\n",
    "# pars += pka_mod.guess(I, q, center=0.8)\n",
    "# pars['pka_center'].set(min=0.78)\n",
    "\n",
    "# Combine into full model\n",
    "mod = bkg_mod + pk1_mod + pk2_mod + pk3_mod + pk4_mod + pk5_mod + pk6_mod\n",
    "\n",
    "\n",
    "# Run fit and store all info in a ModelResult object\n",
    "out = mod.fit(I, pars, x=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b750a-12d4-4f5d-b586-9fa2e116a56b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# S3 Blend OOP linecut\n",
    "sector = 'OOP'\n",
    "q_max = 2.6\n",
    "q, I = linecut_data(sector, q_max)\n",
    "\n",
    "# Set slope and intercept of background by drawing line through minimum point and where the data was normed\n",
    "I_min = I.min()\n",
    "q_min = q[np.where(I==I_min)[0][0]]\n",
    "m = (1-I_min)/(q_norm-q_min)\n",
    "intercept = I_min - m*q_min\n",
    "\n",
    "# Define all models to include in fitting\n",
    "# bkg_mod = LinearModel(prefix='bkg_')\n",
    "# pars = bkg_mod.make_params(intercept=intercept, slope=m)\n",
    "bkg_mod = LinearModel(prefix='bkg_')\n",
    "pars = bkg_mod.make_params(intercept=0.5, slope=0)\n",
    "pars['bkg_intercept'].set(vary=False)\n",
    "pars['bkg_slope'].set(vary=False)\n",
    "\n",
    "pk1_mod = PseudoVoigtModel(prefix='pk1_')\n",
    "pars += pk1_mod.guess(I, q, center=.4)\n",
    "pars['pk1_amplitude'].set(min=1e-2)\n",
    "pars['pk1_center'].set(min=0.25,max=0.42)\n",
    "pars['pk1_sigma'].set(max=1)\n",
    "\n",
    "# pk2_mod = PseudoVoigtModel(prefix='pk2_')\n",
    "# pars += pk2_mod.guess(I, q, center=0.45)\n",
    "# pars['pk2_amplitude'].set(min=2e-2)\n",
    "# pars['pk2_center'].set(min=0.4, max=0.5)\n",
    "# pars['pk2_sigma'].set(max=0.7)\n",
    "# # pars['pk2_center'].set(min=1.4, max=1.6)\n",
    "# # pars['pk2_sigma'].set(max=1)\n",
    "\n",
    "pk2_mod = PseudoVoigtModel(prefix='pk2_')\n",
    "pars += pk2_mod.guess(I, q, center=1.5)\n",
    "pars['pk2_amplitude'].set(min=1e-2)\n",
    "pars['pk2_center'].set(min=1.3, max=1.6)\n",
    "pars['pk2_sigma'].set(max=1)\n",
    "# pars['pk2_center'].set(min=1.62, max=1.75)\n",
    "# pars['pk2_sigma'].set(max=1)\n",
    "\n",
    "\n",
    "pk3_mod = PseudoVoigtModel(prefix='pk3_')\n",
    "pars += pk3_mod.guess(I, q, center=1.8)\n",
    "pars['pk3_amplitude'].set(min=1e-2)\n",
    "pars['pk3_center'].set(min=1.62, max=1.9)\n",
    "pars['pk3_sigma'].set(max=1)\n",
    "\n",
    "# pk5_mod = PseudoVoigtModel(prefix='pk5_')\n",
    "# pars += pk5_mod.guess(I, q, center=1.6)\n",
    "\n",
    "# pk6_mod = PseudoVoigtModel(prefix='pk6_')\n",
    "# pars += pk6_mod.guess(I, q, center=2.25)\n",
    "\n",
    "\n",
    "# Combine into full model\n",
    "mod = bkg_mod + pk1_mod + pk2_mod + pk3_mod # + pk5_mod + pk6_mod\n",
    "\n",
    "\n",
    "# Run fit and store all info in a ModelResult object\n",
    "out = mod.fit(I, pars, x=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c33d4-c112-4781-b36c-cabd1d7f2f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IEICO-4F IP linecut\n",
    "sector = 'IP'\n",
    "q_max = 2\n",
    "q, I = linecut_data(sector, q_max)\n",
    "\n",
    "# # Set slope and intercept of background by drawing line through minimum point and where the data was normed\n",
    "# I_min = I.min()\n",
    "# q_min = q[np.where(I==I_min)[0][0]]\n",
    "# m = (1-I_min)/(q_norm-q_min)\n",
    "# intercept = I_min - m*q_min\n",
    "\n",
    "\n",
    "# Really just want straight line from norm point to *local* minimum around q=0.55?\n",
    "I_min = I[np.where(np.abs(q-0.55)<2e-1)[0]].min()\n",
    "q_min = q[np.where(I==I_min)[0][0]]\n",
    "m = (1-I_min)/(q_norm-q_min)\n",
    "intercept = I_min - m*q_min\n",
    "\n",
    "# Define all models to include in fitting\n",
    "bkg_mod = LinearModel(prefix='bkg_')\n",
    "pars = bkg_mod.make_params(intercept=0.5, slope=0)\n",
    "pars['bkg_intercept'].set(vary=False)\n",
    "pars['bkg_slope'].set(vary=False)\n",
    "\n",
    "pk1_mod = PseudoVoigtModel(prefix='pk1_')\n",
    "pars += pk1_mod.guess(I, q, center=.4)\n",
    "\n",
    "pk2_mod = PseudoVoigtModel(prefix='pk2_')\n",
    "pars += pk2_mod.guess(I, q, center=.6)\n",
    "pars['pk2_center'].set(max = 0.62, min = 0.58)\n",
    "pars['pk2_sigma'].set(max = 0.03)\n",
    "pars['pk2_amplitude'].set(min=2e-2)\n",
    "\n",
    "pka_mod = PseudoVoigtModel(prefix='pka_')\n",
    "pars += pka_mod.guess(I, q, center=0.8)\n",
    "pars['pka_center'].set(min=0.78)\n",
    "\n",
    "pk3_mod = PseudoVoigtModel(prefix='pk3_')\n",
    "pars += pk3_mod.guess(I, q, center=1.35)\n",
    "# pars['pk3_center'].set(min=1.3, max=1.4)\n",
    "# pars['pk3_sigma'].set(max=0.5)\n",
    "pars['pk3_amplitude'].set(min=1e-2)\n",
    "\n",
    "pk4_mod = PseudoVoigtModel(prefix='pk4_')\n",
    "pars += pk4_mod.guess(I, q, center=1.7)\n",
    "pars['pk4_amplitude'].set(min=1e-2)\n",
    "# pars['pk4_center'].set(max=1.72)\n",
    "\n",
    "# Combine into full model\n",
    "mod = bkg_mod + pk1_mod + pk2_mod + pk3_mod + pk4_mod + pka_mod\n",
    "\n",
    "\n",
    "# Run fit and store all info in a ModelResult object\n",
    "out = mod.fit(I, pars, x=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669366b7-6015-408c-91d4-ace14a1a84a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IEICO-4F OOP linecut\n",
    "sector = 'OOP'\n",
    "q, I = linecut_data(sector)\n",
    "\n",
    "# Set slope and intercept of background by drawing line through minimum point and where the data was normed\n",
    "I_min = I.min()\n",
    "q_min = q[np.where(I==I_min)[0][0]]\n",
    "m = (1-I_min)/(q_norm-q_min)\n",
    "intercept = I_min - m*q_min\n",
    "\n",
    "# Define all models to include in fitting\n",
    "# bkg_mod = LinearModel(prefix='bkg_')\n",
    "# pars = bkg_mod.make_params(intercept=intercept, slope=m)\n",
    "\n",
    "bkg_mod = LinearModel(prefix='bkg_')\n",
    "pars = bkg_mod.make_params(intercept=0.5, slope=0)\n",
    "pars['bkg_intercept'].set(vary=False)\n",
    "pars['bkg_slope'].set(vary=False)\n",
    "\n",
    "exp_mod = ExponentialModel(prefix='exp_')\n",
    "pars += exp_mod.guess(I[:60], q[:60])\n",
    "\n",
    "pk1_mod = PseudoVoigtModel(prefix='pk1_')\n",
    "pars += pk1_mod.guess(I, q, center=1.5)\n",
    "\n",
    "pk2_mod = PseudoVoigtModel(prefix='pk2_')\n",
    "pars += pk2_mod.guess(I, q, center=1.9)\n",
    "\n",
    "\n",
    "# Combine into full model\n",
    "mod = bkg_mod + exp_mod + pk1_mod + pk2_mod # + pk3_mod + pk4_mod # + pk5_mod + pk6_mod\n",
    "\n",
    "\n",
    "# Run fit and store all info in a ModelResult object\n",
    "out = mod.fit(I, pars, x=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d453d3b-b80e-4e71-982b-8bf7f0fd7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_plotter(q, I, out, top=15)\n",
    "display(out.best_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1fb150-1619-41c2-8615-3a05cb3e1ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_plotter(q, I, out, top=12, save_plot=True, save_data=True, save_peaks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328238e-acd1-4d20-8717-4b68309319b6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# <examples/doc_builtinmodels_stepmodel.py>\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from lmfit.models import LinearModel, StepModel\n",
    "\n",
    "x = np.linspace(0, 10, 201)\n",
    "y = np.ones_like(x)\n",
    "y[:48] = 0.0\n",
    "y[48:77] = np.arange(77-48)/(77.0-48)\n",
    "np.random.seed(0)\n",
    "y = 110.2 * (y + 9e-3*np.random.randn(len(x))) + 12.0 + 2.22*x\n",
    "\n",
    "step_mod = StepModel(form='erf', prefix='step_')\n",
    "line_mod = LinearModel(prefix='line_')\n",
    "\n",
    "pars = line_mod.make_params(intercept=y.min(), slope=0)\n",
    "pars += step_mod.guess(y, x=x, center=2.5)\n",
    "\n",
    "mod = step_mod + line_mod\n",
    "out = mod.fit(y, pars, x=x)\n",
    "\n",
    "print(out.fit_report())\n",
    "\n",
    "plt.plot(x, y, 'b')\n",
    "plt.plot(x, out.init_fit, 'k--')\n",
    "plt.plot(x, out.best_fit, 'r-')\n",
    "plt.show()\n",
    "# <end examples/doc_builtinmodels_stepmodel.py>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aaa11b-d20d-4569-9559-02607dea2f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def run_fit(*pks, **kwargs):\n",
    "#     \"\"\"\n",
    "#     pks entered as tuples: (center, center_range, min_amp, max_sigma)\n",
    "#     kwargs: must include q, I, and bkg_height\n",
    "#     \"\"\"\n",
    "#     # for pk in pks:\n",
    "#     #     print(pk)\n",
    "#     # print(kwargs['bkg_height'])\n",
    "    \n",
    "#     q = kwargs['q']\n",
    "#     I = kwargs['I']\n",
    "#     b = kwargs['bkg_height']\n",
    "    \n",
    "    \n",
    "#     bkg_mod = LinearModel(prefix='bkg_')\n",
    "#     pars = bkg_mod.make_params(intercept=b, slope=0)\n",
    "#     pars['bkg_intercept'].set(vary=False)\n",
    "#     pars['bkg_slope'].set(vary=False)\n",
    "    \n",
    "#     for i, pk in enumerate(pks):\n",
    "#         pk_mod = PseudoVoigtModel(prefix=f'pk{i+1}_')\n",
    "#         pars += pk_mod.guess(I, q, center=pk[0])\n",
    "#         if len(pk) >= 2:\n",
    "#             pars[f'pk{i+1}_center'].set(max=pk[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # print(pks[0][0])\n",
    "#     return pars\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cced1ce-3a86-4a0c-9736-0d526cabae6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pk1 = (0.4,)\n",
    "# pk2 = (0.6, 0.02, 2e-2, 0.03)\n",
    "# pk3 = (1.35, 0.1, 1e-2)\n",
    "# pk4 = (1.7, 0.02, 1e-2)\n",
    "\n",
    "# run_fit(pk1, pk2, pk3, q=q, I=I, bkg_height=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f6cf0-b785-488e-96d3-49deaa11fa60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
