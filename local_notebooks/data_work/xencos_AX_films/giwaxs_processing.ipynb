{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c13da0-ce45-4653-9fb2-5f71078d5a36",
   "metadata": {},
   "source": [
    "# Ex situ GIWAXS processing\n",
    "\n",
    "# GIWAXS raw data processing & exporting notebook\n",
    "In this notebook you output xr.DataSets stored as .zarr stores containing all your raw,\n",
    "remeshed (reciprocal space), and caked CMS GIWAXS data. Saving as a zarr automatically converts the array to a dask array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96625ca6-7ec2-4690-bf01-72b422801f76",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd667c0e-baba-4a5d-857a-ca8bd5ce1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports:\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import xarray as xr\n",
    "import PyHyperScattering as phs\n",
    "import fabio\n",
    "import gc\n",
    "from tqdm.auto import tqdm  # progress bar loader!\n",
    "\n",
    "print(f\"Don't worry about the above warnings/errors... using PyHyperScattering version: {phs.__version__}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dffa6de-0360-4fcb-b0bf-f320927837d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Defining some objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b6f6c-4643-46b3-9784-9a6071c754ba",
   "metadata": {},
   "source": [
    "### Define & check paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db0fc93-6739-457a-a7fe-ba695bb41716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I like pathlib for its readability & checkability, it's also necessary for the loadSeries function later on\n",
    "# Replace the paths with the ones relevant to your data, you can use the \".exists()\" method to make sure you defined a path correctly\n",
    "suitePath = pathlib.Path('/Users/andrew/Library/CloudStorage/OneDrive-UCB-O365/research/data_analysis/giwaxs_suite')\n",
    "xenocsPath = suitePath.joinpath('raw_data/xenocs')\n",
    "rawPath = xenocsPath.joinpath('AX_films_01_2024-05-09')\n",
    "outPath = suitePath.joinpath('processed_data/xenocs')\n",
    "\n",
    "# Select poni & mask filepaths\n",
    "# poniFile = xenocsPath.joinpath('xenocs_100sdd.poni')\n",
    "poniFile = xenocsPath.joinpath('xenocs_120sdd.poni')\n",
    "\n",
    "# Colormap\n",
    "cmap = plt.cm.turbo.copy()\n",
    "cmap.set_bad('black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7ba44-ea07-487f-975b-443821081be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pilatus1m = 0.000172  # cms detector \n",
    "eiger2_1m = 0.000075  # xenocs xeuss 3.0 detector\n",
    "\n",
    "def poni_centers(poniFile, pix_size=eiger2_1m):\n",
    "    \"\"\"\n",
    "    Returns poni center value and the corresponding pixel position. Default pixel size is 172 microns (Pilatus 1M)\n",
    "    \n",
    "    Inputs: poniFile as pathlib path object to the poni file\n",
    "    Outputs: ((poni1, y_center), (poni2, x_center))\n",
    "    \"\"\"\n",
    "    \n",
    "    with poniFile.open('r') as f:\n",
    "        lines = list(f.readlines())\n",
    "    poni1_str = lines[6]\n",
    "    poni2_str = lines[7]\n",
    "\n",
    "    poni1 = float(poni1_str.split(' ')[1])\n",
    "    poni2 = float(poni2_str.split(' ')[1])\n",
    "\n",
    "    y_center = poni1 / pix_size\n",
    "    x_center = poni2 / pix_size\n",
    "        \n",
    "    return ((poni1, y_center), (poni2, x_center))\n",
    "\n",
    "display(poni_centers(poniFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b7e5f-b3b2-4d94-a552-107aa5cd6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f.name for f in rawPath.glob('*')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1840638-1577-4dea-8819-ffb69d6f80b8",
   "metadata": {},
   "source": [
    "### Define metadata naming scheme & initialize loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407056a-8eb3-4023-b6c8-fd5e4f224bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_folders = sorted(rawPath.glob('A*'))\n",
    "\n",
    "display(sample_folders)\n",
    "display([f.name for f in sorted(sample_folders[0].glob('*edf'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd31494-d2e4-43d7-adce-d31098c55edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ex situ metadata filename naming schemes:\n",
    "# md_naming_scheme = ['material', 'solvent', 'misc', 'stitched', 'scan_ids']\n",
    "md_naming_scheme = ['film', 'film_number', 'misc', 'scan_id']\n",
    "\n",
    "\n",
    "# Initalize CMSGIWAXSLoader objects with the above naming schemes\n",
    "loader = phs.load.CMSGIWAXSLoader(md_naming_scheme=md_naming_scheme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907b4357-1e98-4f19-80f7-066b2940794b",
   "metadata": {},
   "source": [
    "## Load & process raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7f3d9-f0f1-41aa-afa5-62869026d8fe",
   "metadata": {},
   "source": [
    "### Load Xenocs data into list(s) of DataArrays, set your incident_angle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5861bf-5ce7-457c-8996-b43b88a2e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xenocs_folders(sample_folders, files_to_load, incident_angle, phs_loader):\n",
    "    \"\"\"\n",
    "    Loader for Xenocs Xeuss 3.0 GIWAXS output (Eiger2 1M detector)\n",
    "\n",
    "    Inputs:\n",
    "    - sample_folders (pathlib.path): A directory that contains all the xenocs data you want to load together (must all be same incident angle)\n",
    "    - files_to_load (list): List of strings, chosen files to load for xenocs up to ['hi', 'lo', 'vd']\n",
    "                            Do ['hi'] if you only took single images in the default detection\n",
    "                            Do ['hi', 'lo'] or ['hi', 'lo', 'vd'] if you want to use stitching \n",
    "                            Note: 'vd' is the default stitched output for the xenocs, which is good but doesnt averate the two images together\n",
    "    - incident_angle (float): Your incident angle, important for later transformations\n",
    "    - phs_loader (phs.load.CMSGIWAXSLoader): PyHyperScattering CMSGIWAXSLoader object, with a metadata naming scheme ideally!\n",
    "\n",
    "    Outputs:\n",
    "    - loaded_DAs: dictionary with the xenocs 'files_to_load' type as keys for a list of corresponding DataArrays\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data in each Xenocs sample folder\n",
    "    # Just uncomment corresponding lines if you don't want/have all the data files to load\n",
    "    \n",
    "    # Create dictionary with empty lists of each xenocs type to append to\n",
    "    loaded_DAs = {}\n",
    "    for file_to_load in files_to_load:\n",
    "        loaded_DAs[file_to_load] = []\n",
    "    \n",
    "    # Load data into dictionary lists\n",
    "    for sample_folder in sample_folders:\n",
    "        for file_to_load in files_to_load:\n",
    "            if file_to_load == 'hi':\n",
    "                file = sorted(sample_folder.glob('*_00000.edf'))[0]\n",
    "            elif file_to_load == 'lo':\n",
    "                file = sorted(sample_folder.glob('*_00001.edf'))[0]\n",
    "            elif file_to_load == 'vd':\n",
    "                file = sorted(sample_folder.glob('*-00001.edf'))[0]\n",
    "            else:\n",
    "                print(\"invalide xenocs file_to_load option: ['hi', 'lo', 'vd']\")\n",
    "        \n",
    "            DA = loader.loadSingleImage(file)\n",
    "        \n",
    "            DA.attrs['incident_angle'] = incident_angle\n",
    "        \n",
    "            DA = DA.where(DA!=-1)\n",
    "        \n",
    "            loaded_DAs[file_to_load].append(DA)\n",
    "\n",
    "    return loaded_DAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaa2f2f-120e-4137-b2dc-79e51929824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "incident_angle = 0.15  # Set your incident angle you used for this data!\n",
    "files_to_load = ['hi', 'lo', 'vd']  # Choose types of xenocs images to load\n",
    "\n",
    "loaded_DAs = load_xenocs_folders(sample_folders, files_to_load, incident_angle, loader)\n",
    "loaded_DAs\n",
    "\n",
    "hi_DAs = loaded_DAs['hi']\n",
    "lo_DAs = loaded_DAs['lo']\n",
    "vd_DAs = loaded_DAs['vd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71705fd1-50e6-4e53-af48-472328ce9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally check the lists\n",
    "display(hi_DAs)\n",
    "display(len(hi_DAs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c722758-a8a7-4692-b52f-32d57251be12",
   "metadata": {},
   "source": [
    "### Combine two Xenocs Xeuss 3.0 detector images (stitch gap & average counts)\n",
    "Benefit here versus the default 'vd' images from Xenocs: **average overlapping data!**\n",
    "\n",
    "Xenocs Xeuss 3.0 'line eraser' moves det0xvd (0.75) and det0zvd (-4.125), corresponding to pixel shifts:\n",
    "\n",
    "'lo_DA' (_00001.edf') compared to 'hi_DA' (_00000.edf): Detector moves 10 pixels to the right, 55 pixels down. \n",
    "\n",
    "As currently written, this code maintains the original hi_DA shape. The extra 55 pixels at the bottom and the extra 10 pixels to the right are thrown out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc2e18-de98-47d4-ba0f-cdefe336f8b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Checking original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782f3aa-f477-4534-b4fe-25a4122c499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fab_img = fabio.open(hi_file)\n",
    "# fab_img.header\n",
    "# (0.75e-3) / eiger2_1m  # use det0xvd shift: so a 10 pixel shift for the hi-lo gap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d2ca7b-d6c8-45b2-9b69-b056f735067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# cmin = lo_DA.quantile(0.01)\n",
    "# cmax = lo_DA.quantile(0.99)\n",
    "# lo_DA.plot.imshow(cmap=plt.cm.turbo, norm=plt.Normalize(cmin,cmax), origin='upper')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc2140b-c944-41ec-b2e6-a10604b7361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# cmin = hi_DA.quantile(0.01)\n",
    "# cmax = hi_DA.quantile(0.99)\n",
    "# hi_DA.plot.imshow(cmap=plt.cm.turbo, norm=plt.Normalize(cmin,cmax), origin='upper')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da17b24-0779-4478-b61b-281a67a444e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # confirm that vd stitched file is NOT what we want \n",
    "\n",
    "# plt.close('all')\n",
    "# fig, ax = plt.subplots()\n",
    "# hi_DA.sel(pix_x=slice(10, 80), pix_y=slice(30, 605)).sum('pix_x').plot.line(ax=ax)\n",
    "# vd_DA.sel(pix_x=slice(10, 80), pix_y=slice(30, 605)).sum('pix_x').plot.line(ax=ax, linestyle='--')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d3bbd-0683-4f91-b827-fc15117d8668",
   "metadata": {},
   "source": [
    "#### Combine images & check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a624b9f-580d-42a9-9f73-ac3df815b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mask & hi_lo shift:\n",
    "# Below are the correct values the xenocs xeuss 3.0 shift\n",
    "y_shift = 55 \n",
    "x_shift = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7267ba-bb9a-4245-88ec-59df9d67c6ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stitch & average the two images\n",
    "stitched_DAs = []\n",
    "for tup in zip(lo_DAs, hi_DAs):\n",
    "    lo_DA = tup[0].copy()\n",
    "    hi_DA = tup[1].copy()\n",
    "    \n",
    "    # Shift lo DA to match hi da\n",
    "    shifted_lo_DA = lo_DA.shift(pix_x=x_shift, pix_y=y_shift)\n",
    "\n",
    "    # Stich missing data in hi_DA from shifted lo_DA:\n",
    "    filled_hi_DA = hi_DA.combine_first(shifted_lo_DA)\n",
    "\n",
    "    # Average data that is in both images:\n",
    "    # Make boolean mask; true where there is overlap between images, false where there isn't\n",
    "    overlap_mask = hi_DA.notnull() & shifted_lo_DA.notnull()  \n",
    "    # Keep original combined data where there isn't overlap, average with shifted lo_DA otherwise\n",
    "    stitched_DA = filled_hi_DA.where(~overlap_mask, (filled_hi_DA + shifted_lo_DA) / 2)   \n",
    "\n",
    "    # Mask area below horizon, this will be above pix_y ~ 895:    \n",
    "    stitched_DA = stitched_DA.where(stitched_DA.pix_y<895)\n",
    "    \n",
    "    # Record stitched DAs if good:\n",
    "    stitched_DAs.append(stitched_DA)\n",
    "\n",
    "\n",
    "    \n",
    "# # If you want to double check where the overlap\n",
    "# # It may likely be evident in the actual data too, where it appears smoother vs not\n",
    "# overlap_mask.plot.imshow()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b2be18-8226-4632-8c16-99c11c2f8f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d666b2-4456-4d8c-96e1-404654b2f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap.set_bad('black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772dd3e-afb7-46a0-be53-36587e957ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "# Plot check stitched DAs\n",
    "for stitched_DA in stitched_DAs[:]:\n",
    "    cmin = stitched_DA.quantile(0.3)\n",
    "    cmax = stitched_DA.quantile(0.99)\n",
    "    ax = stitched_DA.plot.imshow(norm=plt.Normalize(cmin,cmax), origin='upper', cmap=cmap, interpolation='antialiased')\n",
    "    ax.axes.set_title(f'{stitched_DA.film}')    \n",
    "    plt.show()\n",
    "    plt.close('all') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2beb7e4-cd19-479b-98a1-54648ed526b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Apply rotation corrections if necessary\n",
    "Not very refined yet. Requires defining a dictionary of bottom_line_points for each image to rotate. e.g. {'DataArray_identifier': [(x1,y1), (x2, y2)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db4a54-eb10-4f14-9700-5cda96a34be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0725b90-6455-4713-bcf9-a9e69ae0948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Interactively plot data of selected sample to identify point coordinates\n",
    "# plt.close('all')\n",
    "# DA = stitched_DAs[0].copy()\n",
    "\n",
    "# cmin=DA.quantile(0.2)\n",
    "# cmax=DA.quantile(0.98)\n",
    "# ax = DA.plot.imshow(norm=plt.Normalize(cmin,cmax), origin='upper', cmap=cmap)\n",
    "# ax.axes.set_title(f'{DA.film}')    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f362b-cbdd-4e43-a840-9ed4bfe9d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dictionary containing points which define line by which to calculate amount to rotate from\n",
    "# bottom_line_points - {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5980e-6c1c-4f03-beca-37034d1f3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_poni = (713, 1251)\n",
    "# def rotateImage(img, angle, pivot):\n",
    "#     padX = [img.shape[1] - pivot[0], pivot[0]]\n",
    "#     padY = [img.shape[0] - pivot[1], pivot[1]]\n",
    "#     imgP = np.pad(img, [padY, padX], 'constant')\n",
    "#     imgR = ndimage.rotate(imgP, angle, reshape=False)\n",
    "#     return imgR[padY[0] : -padY[1], padX[0] : -padX[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc40927-08ff-4e38-b171-ce5eea756f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Apply rotation corrections based on lines drawn between points\n",
    "\n",
    "# rot_corr_DAs = []\n",
    "# for DA in tqdm(stitched_DAs, desc='Rotating...'):  \n",
    "#     # Get line points from dictionary\n",
    "#     p1, p2 = bottom_line_points[f'{DA.sample_id}_{DA.exposure_time}']\n",
    "\n",
    "#     # Calculate the angle from points\n",
    "#     dx = p2[0] - p1[0]\n",
    "#     dy = p2[1] - p1[1]\n",
    "#     angle_radians = np.arctan2(dy, dx)\n",
    "#     angle_degrees = np.degrees(angle_radians)\n",
    "\n",
    "#     # Rotate image & save into list\n",
    "#     rot_corr_DA = xr.apply_ufunc(rotateImage, DA, angle_degrees, pivot_poni)\n",
    "#     # rot_corr_DA = xr.apply_ufunc(ndimage.rotate, DA, angle_degrees, (1, 0), False, None, 3, 'constant')\n",
    "#     # rot_corr_DA = xr.apply_ufunc(ndimage.rotate, DA, 0, (1, 0), False)\n",
    "#     rot_corr_DA.attrs = DA.attrs\n",
    "#     rot_corr_DAs.append(rot_corr_DA)\n",
    "    \n",
    "# # Plot check\n",
    "# for rot_corr_DA in rot_corr_DAs:\n",
    "#     cmin = rot_corr_DA.quantile(0.2)\n",
    "#     cmax = rot_corr_DA.quantile(0.99)\n",
    "#     rot_corr_DA.plot.imshow(norm=plt.Normalize(cmin,cmax), origin='upper', cmap=cmap)\n",
    "#     plt.show()\n",
    "#     plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4027a072-0908-4d18-9c67-96856fa70b1d",
   "metadata": {},
   "source": [
    "### pygix-backed transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc5a69-db82-4855-809e-f21471d4d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize integrators\n",
    "# Don't forget to ensure the correct incident angle is set\n",
    "incident_angle = stitched_DAs[0].incident_angle\n",
    "recip_integrator = phs.integrate.PGGeneralIntegrator(geomethod = 'ponifile',\n",
    "                                                     ponifile = poniFile,\n",
    "                                                     output_space = 'recip',\n",
    "                                                     incident_angle = incident_angle)\n",
    "caked_integrator = phs.integrate.PGGeneralIntegrator(geomethod = 'ponifile',\n",
    "                                                     ponifile = poniFile,\n",
    "                                                     output_space = 'caked',\n",
    "                                                     incident_angle = incident_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b834814-3f0a-419d-83ff-e254b4ce83f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use integrators to fill list of integrated DataArrays\n",
    "\n",
    "recip_DAs = []\n",
    "caked_DAs = []\n",
    "for DA in tqdm(stitched_DAs, desc='Transforming to reciprocal space'):   \n",
    "    # Integrate single image\n",
    "    recip_DA = recip_integrator.integrateSingleImage(DA)\n",
    "    caked_DA = caked_integrator.integrateSingleImage(DA)\n",
    "\n",
    "    # Append to corresponding list\n",
    "    recip_DAs.append(recip_DA)\n",
    "    caked_DAs.append(caked_DA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3c06e-1227-4f0b-9605-24f6c959c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce20c73-4d56-4f58-bcc0-9137d1a2c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "DA = caked_DAs[0].copy()\n",
    "\n",
    "cmin = DA.sel(qr=slice(0.25,None)).quantile(0.01)\n",
    "cmax = DA.sel(qr=slice(0.25,None)).quantile(0.995)\n",
    "DA.plot.imshow(norm=plt.Normalize(cmin,cmax), cmap=cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf97271-a223-4ba3-a1d6-98e68712464c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot check recip DAs\n",
    "\n",
    "# Set q bounds\n",
    "qxy_min = -0.65\n",
    "qxy_max = 2\n",
    "qz_min = 0\n",
    "qz_max = 2\n",
    "\n",
    "for DA in recip_DAs:\n",
    "# for DA in recip_DS.data_vars.values():\n",
    "    sliced_DA = DA.sel(q_xy=slice(qxy_min, qxy_max), q_z=slice(qz_min,qz_max))\n",
    "    \n",
    "    cmin = sliced_DA.quantile(0.1)\n",
    "    cmax = sliced_DA.quantile(0.993)\n",
    "    ax = sliced_DA.plot.imshow(norm=plt.Normalize(cmin,cmax), cmap=cmap, figsize=(5,3.5), interpolation='antialiased')\n",
    "    ax.axes.set_title(f'{sliced_DA.film}')   \n",
    "    ax.axes.set(aspect='equal', xlabel='$Q_{xy}$ $[\\\\AA^{-1}]$', ylabel='$Q_{z}$ $[\\\\AA^{-1}]$')\n",
    "    ax.axes.xaxis.set_minor_locator(plt.MultipleLocator(0.1))\n",
    "    ax.axes.yaxis.set_minor_locator(plt.MultipleLocator(0.1))\n",
    "    ax.colorbar.set_label('Intensity [arb. units]', rotation=270, labelpad=15)\n",
    "    ax.figure.set(dpi=150)\n",
    "    \n",
    "    # # Save\n",
    "    # savePath = outPath.joinpath('recip_images')\n",
    "    # savePath.mkdir(exist_ok=True)\n",
    "    # ax.figure.savefig(savePath.joinpath(f'{sliced_DA.material}_{sliced_DA.solvent}'), dpi=120)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close('all') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cd7166-cd28-4918-b233-defa9b2e327a",
   "metadata": {},
   "source": [
    "## Save / export processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4e246-a10c-4d2b-a891-1fb8177ec301",
   "metadata": {},
   "source": [
    "### Save zarrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcee6fb-8997-4795-9f7c-c85d9ca433b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack data into a Datasets first:\n",
    "raw_DS = xr.Dataset({DA.attrs['film']: DA for DA in stitched_DAs})\n",
    "recip_DS = xr.Dataset({DA.attrs['film']: DA for DA in recip_DAs})\n",
    "caked_DS = xr.Dataset({DA.attrs['film']: DA for DA in caked_DAs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ebfcb-9689-4ed9-af6f-1fc2be56445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d44c45-633a-4595-8bf5-7d796eabbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check savePath\n",
    "savePath = outPath.joinpath('AX_films_01/zarrs')\n",
    "savePath.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456ff9c-f24b-4451-88a1-6ad8efb57f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save zarrs\n",
    "recip_DS.to_zarr(savePath.joinpath('recip.zarr'), mode='w')\n",
    "raw_DS.to_zarr(savePath.joinpath('raw.zarr'), mode='w')\n",
    "caked_DS.to_zarr(savePath.joinpath('caked.zarr'), mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509bcfb0-adc9-4630-882d-509bdbb26566",
   "metadata": {},
   "source": [
    "### Numpy binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905c1b4-364d-4a1b-ae73-d5e9e39032ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliced_recip_DA = recip_DA.sel(q_xy=slice(qxy_min, qxy_max), q_z=slice(qz_min,qz_max))\n",
    "\n",
    "# display(sliced_recip_DA.data.shape)\n",
    "# display(sliced_recip_DA.q_xy.data.shape)\n",
    "# display(sliced_recip_DA.q_z.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c44b2-33d3-4817-8671-d23e40c70899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# npysPath = outPath.joinpath('npys')\n",
    "# savePath = npysPath.joinpath(f'{sample_name}')\n",
    "# savePath.mkdir(exist_ok=True)\n",
    "\n",
    "# np.save(savePath.joinpath(f'data_{sample_name}.npy'), sliced_recip_DA.data)\n",
    "# np.save(savePath.joinpath(f'qxy_{sample_name}.npy'), sliced_recip_DA.q_xy.data)\n",
    "# np.save(savePath.joinpath(f'qz_{sample_name}.npy'), sliced_recip_DA.q_z.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce744598-aec2-4346-a4f2-06be913a424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.load(savePath.joinpath(f'data_{sample_name}.npy'))\n",
    "# plt.imshow(data, norm=plt.Normalize(cmin,cmax), origin='lower')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeafc062-40b5-455f-aec5-b89b688abf1a",
   "metadata": {},
   "source": [
    "### CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5bbfeb-4a16-444a-8cd4-abd7f37d71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A way to save data as csv files\n",
    "# for DA in tqdm(DS.data_vars.values()):\n",
    "#     # qxy columns, qz rows\n",
    "#     DA.to_pandas().to_csv(outPath.joinpath('PM6-Y6_waxs', f'cartesian-2D_{DA.polymer}-{DA.weight_percent}_{DA.incident_angle}_{DA.scan_id}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545ca5ba-ff39-4f42-80e1-6e4f57133452",
   "metadata": {},
   "source": [
    "## Misc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c0c38b-ddf4-454e-b5b4-3439be569cab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Yoneda check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd43835-2e0e-4cd9-b900-3c9fefa726d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qz(wavelength, alpha_crit, alpha_incidents):\n",
    "    qz_inv_meters = ((4 * np.pi) / (wavelength)) * (np.sin(np.deg2rad((alpha_incidents + alpha_crit)/2)))\n",
    "    # qz_inv_meters = ((4 * np.pi) / (wavelength)) * (np.sin(np.deg2rad(alpha_crit)) + np.sin(np.deg2rad(alpha_incidents)))\n",
    "    qz_inv_angstroms = qz_inv_meters / 1e10\n",
    "    return qz_inv_angstroms\n",
    "\n",
    "wavelength = 1.5420919527363186e-10  # 8.04 keV\n",
    "# wavelength = 9.762535309700809e-11  # 12.7 keV\n",
    "# wavelength = 1.2398419843320025e-10  # 10 keV\n",
    "\n",
    "alpha_crit = 0.11  # organic film critical angle\n",
    "alpha_incidents = np.array([0.15])\n",
    "\n",
    "yoneda_angles = alpha_incidents + alpha_crit\n",
    "\n",
    "qz(wavelength, alpha_crit, alpha_incidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a648aa-2d36-4224-b541-e087a2a986f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73961d3d-467b-4a57-9cd9-f026f7acda69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = recip_DS['sam6_2s'].plot.imshow(norm=plt.Normalize(cmin,cmax), cmap=cmap)\n",
    "# ax.axes.set_title(f'{sliced_DA.sample_id}: {sliced_DA.exposure_time}')   \n",
    "# ax.axes.set(aspect='equal')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d64c56-1910-4a5b-a2c3-2426bcc38fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def select_attrs(data_arrays_iterable, selected_attrs_dict):\n",
    "#     \"\"\"\n",
    "#     Selects data arrays whose attributes match the specified values.\n",
    "\n",
    "#     Parameters:\n",
    "#     data_arrays_iterable: Iterable of xarray.DataArray objects.\n",
    "#     selected_attrs_dict: Dictionary where keys are attribute names and \n",
    "#                          values are the attributes' desired values.\n",
    "\n",
    "#     Returns:\n",
    "#     List of xarray.DataArray objects that match the specified attributes.\n",
    "#     \"\"\"    \n",
    "#     sublist = list(data_arrays_iterable)\n",
    "    \n",
    "#     for attr_name, attr_values in selected_attrs_dict.items():\n",
    "#         sublist = [da for da in sublist if da.attrs[attr_name] in attr_values]\n",
    "                \n",
    "#     return sublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62260f97-d8e3-4dd2-8f11-1dea84dda9da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Yoneda peak linecut check\n",
    "# qxy_min = 0.22\n",
    "# qxy_max = 2\n",
    "# qz_min = -0.02\n",
    "# qz_max = 0.06\n",
    "\n",
    "# selected_DAs = select_attrs(fixed_recip_DS.data_vars.values(), selected_attrs_dict)\n",
    "# for DA in tqdm(selected_DAs):\n",
    "#     # Slice data for selected q ranges (will need to rename q_xy if dimensions are differently named)\n",
    "#     sliced_DA = DA.sel(q_xy=slice(qxy_min, qxy_max), q_z=slice(qz_min, qz_max))\n",
    "#     qz_integrated_DA = sliced_DA.sum('q_xy')\n",
    "    \n",
    "#     # Plot\n",
    "#     qz_integrated_DA.plot.line(label=DA.incident_angle)\n",
    "    \n",
    "# plt.legend()\n",
    "# plt.grid(visible=True, which='major', axis='x')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c33b02-daf7-48b6-9471-4c701ee53f10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
